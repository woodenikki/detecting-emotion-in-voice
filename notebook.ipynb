{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b468e18",
   "metadata": {},
   "source": [
    "# MoodWave: Voice-Driven Emotion Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1c8267",
   "metadata": {},
   "source": [
    "## Data Guidelines\n",
    "\n",
    "Your dataset must be:\n",
    "\n",
    "- Appropriate for classification. It should have a categorical outcome or the data needed to engineer one.\n",
    "\n",
    "- Usable to solve a specific business problem. This solution must rely on your classification model.\n",
    "\n",
    "- Somewhat complex. It should contain a minimum of 1000 rows and 10 features.\n",
    "\n",
    "- Unfamiliar. It can't be one we've already worked with during the course or that is commonly used for demonstration purposes (e.g. Titanic).\n",
    "\n",
    "- Manageable. Stick to datasets that you can model using the techniques introduced in Phase 3.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952f987e",
   "metadata": {},
   "source": [
    "### Phase 3 Concepts used in this project:\n",
    "\n",
    "- Logistic Regression:\n",
    "\n",
    "> Logistic regression is a fundamental classification algorithm that's well-suited for binary and multiclass classification tasks. It's a good choice if your dataset has clear decision boundaries.\n",
    "\n",
    "- Decision Trees:\n",
    "\n",
    "> Decision trees are versatile and interpretable models that can handle both categorical and continuous data. They are particularly useful when you want to understand the decision-making process of your model.\n",
    "\n",
    "- Evaluation Metrics (Confusion Matrices, ROC Curves, AUC):\n",
    "\n",
    "> These metrics are essential for assessing the performance of your classification model. They will help you understand how well your model distinguishes between different emotional states.\n",
    "\n",
    "- Hyperparameter Tuning and Pruning:\n",
    "\n",
    "> When using decision trees, tuning hyperparameters and pruning are important to avoid overfitting and to ensure your model generalizes well to new data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d881ba0",
   "metadata": {},
   "source": [
    "## Data Preperation\n",
    "\n",
    "Here 4 most popular datasets in English: Crema, Ravdess, Savee and Tess. Each of them contains audio in .wav format with some main labels.\n",
    "\n",
    "Because our data isn't inherinantly in a csv / dataframe format, we will have to create it from scratch!\n",
    "\n",
    "First, we will pull all data into their own dataframe, making note of *where* the file is, so we can pull our features from each audio file:\n",
    "\n",
    "- Mel-frequency cepstral coefficients (MFCCs)\n",
    "- Spectral centroid\n",
    "- Chroma features\n",
    "- Zero-crossing rate\n",
    "- RMS energy\n",
    "- Pitch\n",
    "\n",
    "And then of course, our target feature: **Emotion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "218c583c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import zipfile\n",
    "import librosa\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1873963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data is zipped, and stored in folders for which dataset they came from:\n",
    "\n",
    "# Define the path to the zipped dataset\n",
    "zip_file_path = 'dataset.zip'\n",
    "extracted_folder_path = 'dataset'\n",
    "\n",
    "# Unzip the dataset\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extracted_folder_path)\n",
    "\n",
    "# Crema\n",
    "# Ravdess\n",
    "# Savee\n",
    "# Tess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73438c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              filename  emotion           path\n",
      "0  1001_DFA_ANG_XX.wav    angry  dataset\\Crema\n",
      "1  1001_DFA_DIS_XX.wav  disgust  dataset\\Crema\n",
      "2  1001_DFA_FEA_XX.wav     fear  dataset\\Crema\n",
      "3  1001_DFA_HAP_XX.wav    happy  dataset\\Crema\n",
      "4  1001_DFA_NEU_XX.wav  neutral  dataset\\Crema\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the Crema folder\n",
    "crema_folder_path = os.path.join(extracted_folder_path, 'Crema')\n",
    "\n",
    "# Verify that we can access the files and extract emotion labels\n",
    "data = []\n",
    "\n",
    "# Loop through each file in the Crema folder\n",
    "for file_name in os.listdir(crema_folder_path):\n",
    "    if file_name.endswith('.wav'):\n",
    "        # Extract the emotion label from the filename\n",
    "        parts = file_name.split('_')\n",
    "        emotion_code = parts[2]\n",
    "        \n",
    "        # Map the emotion code to the actual emotion label\n",
    "        emotion_map = {\n",
    "            'SAD': 'sadness',\n",
    "            'ANG': 'angry',\n",
    "            'DIS': 'disgust',\n",
    "            'FEA': 'fear',\n",
    "            'HAP': 'happy',\n",
    "            'NEU': 'neutral'\n",
    "        }\n",
    "        emotion_label = emotion_map.get(emotion_code, 'unknown')\n",
    "        \n",
    "        # Store the data with the directory path minus the filename\n",
    "        data.append({'filename': file_name, 'emotion': emotion_label, 'path': crema_folder_path})\n",
    "\n",
    "# Convert the data into a DataFrame for easy access\n",
    "df_crema = pd.DataFrame(data)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(df_crema.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88b4d4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             filename emotion                    path\n",
      "0  OAF_back_angry.wav   angry  dataset\\Tess\\OAF_angry\n",
      "1   OAF_bar_angry.wav   angry  dataset\\Tess\\OAF_angry\n",
      "2  OAF_base_angry.wav   angry  dataset\\Tess\\OAF_angry\n",
      "3  OAF_bath_angry.wav   angry  dataset\\Tess\\OAF_angry\n",
      "4  OAF_bean_angry.wav   angry  dataset\\Tess\\OAF_angry\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the Tess folder\n",
    "tess_folder_path = os.path.join(extracted_folder_path, 'Tess')\n",
    "\n",
    "# Prepare to store the data\n",
    "data = []\n",
    "\n",
    "# Loop through each emotion folder in the Tess directory\n",
    "for emotion_folder in os.listdir(tess_folder_path):\n",
    "    # Get the full path to the emotion folder\n",
    "    emotion_folder_path = os.path.join(tess_folder_path, emotion_folder)\n",
    "    \n",
    "    # Extract the emotion from the folder name (e.g., \"OAF_angry\" -> \"angry\")\n",
    "    emotion_label = emotion_folder.split('_')[1]\n",
    "    \n",
    "    # Loop through each file in the emotion folder\n",
    "    for file_name in os.listdir(emotion_folder_path):\n",
    "        if file_name.endswith('.wav'):\n",
    "            # Store the data with the directory path minus the filename\n",
    "            data.append({\n",
    "                'filename': file_name, \n",
    "                'emotion': emotion_label, \n",
    "                'path': emotion_folder_path\n",
    "            })\n",
    "\n",
    "# Convert the data into a DataFrame for easy access\n",
    "df_tess = pd.DataFrame(data)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(df_tess.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7bb69fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     filename  emotion           path\n",
      "0  DC_a01.wav  unknown  dataset\\Savee\n",
      "1  DC_a02.wav  unknown  dataset\\Savee\n",
      "2  DC_a03.wav  unknown  dataset\\Savee\n",
      "3  DC_a04.wav  unknown  dataset\\Savee\n",
      "4  DC_a05.wav  unknown  dataset\\Savee\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the Savee folder\n",
    "savee_folder_path = os.path.join(extracted_folder_path, 'Savee')\n",
    "\n",
    "# Prepare to store the data\n",
    "data = []\n",
    "\n",
    "# Define the emotion mapping based on the prefixes\n",
    "emotion_map = {\n",
    "    'a': 'anger',\n",
    "    'd': 'disgust',\n",
    "    'f': 'fear',\n",
    "    'h': 'happiness',\n",
    "    'n': 'neutral',\n",
    "    'sa': 'sadness',\n",
    "    'su': 'surprise'\n",
    "}\n",
    "\n",
    "# Loop through each file in the Savee folder\n",
    "for file_name in os.listdir(savee_folder_path):\n",
    "    if file_name.endswith('.wav'):\n",
    "        # Extract the prefix from the filename to determine the emotion\n",
    "        prefix = file_name.split('_')[1][:2]\n",
    "        \n",
    "        # Map the prefix to the corresponding emotion\n",
    "        emotion_label = emotion_map.get(prefix, 'unknown')\n",
    "        \n",
    "        # Store the data with the directory path minus the filename\n",
    "        data.append({\n",
    "            'filename': file_name, \n",
    "            'emotion': emotion_label, \n",
    "            'path': savee_folder_path\n",
    "        })\n",
    "\n",
    "# Convert the data into a DataFrame for easy access\n",
    "df_savee = pd.DataFrame(data)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(df_savee.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55e0b664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   filename  emotion  \\\n",
      "0  03-01-01-01-01-01-01.wav  neutral   \n",
      "1  03-01-01-01-01-02-01.wav  neutral   \n",
      "2  03-01-01-01-02-01-01.wav  neutral   \n",
      "3  03-01-01-01-02-02-01.wav  neutral   \n",
      "4  03-01-02-01-01-01-01.wav     calm   \n",
      "\n",
      "                                                path  \n",
      "0  dataset\\Ravdess\\audio_speech_actors_01-24\\Acto...  \n",
      "1  dataset\\Ravdess\\audio_speech_actors_01-24\\Acto...  \n",
      "2  dataset\\Ravdess\\audio_speech_actors_01-24\\Acto...  \n",
      "3  dataset\\Ravdess\\audio_speech_actors_01-24\\Acto...  \n",
      "4  dataset\\Ravdess\\audio_speech_actors_01-24\\Acto...  \n"
     ]
    }
   ],
   "source": [
    "# Define the path to the Ravdess folder\n",
    "ravdess_folder_path = os.path.join(extracted_folder_path, 'Ravdess', 'audio_speech_actors_01-24')\n",
    "\n",
    "# Prepare to store the data\n",
    "data = []\n",
    "\n",
    "# Define the emotion mapping based on the third component in the filename\n",
    "emotion_map = {\n",
    "    '01': 'neutral',\n",
    "    '02': 'calm',\n",
    "    '03': 'happy',\n",
    "    '04': 'sad',\n",
    "    '05': 'angry',\n",
    "    '06': 'fearful',\n",
    "    '07': 'disgust',\n",
    "    '08': 'surprised'\n",
    "}\n",
    "\n",
    "# Loop through each actor's folder in the Ravdess directory\n",
    "for actor_folder in os.listdir(ravdess_folder_path):\n",
    "    actor_folder_path = os.path.join(ravdess_folder_path, actor_folder)\n",
    "    \n",
    "    # Loop through each file in the actor's folder\n",
    "    for file_name in os.listdir(actor_folder_path):\n",
    "        if file_name.endswith('.wav'):\n",
    "            # Extract the third component from the filename to determine the emotion\n",
    "            emotion_code = file_name.split('-')[2]\n",
    "            \n",
    "            # Map the emotion code to the corresponding emotion label\n",
    "            emotion_label = emotion_map.get(emotion_code, 'unknown')\n",
    "            \n",
    "            # Store the data with the directory path minus the filename\n",
    "            data.append({\n",
    "                'filename': file_name, \n",
    "                'emotion': emotion_label, \n",
    "                'path': actor_folder_path\n",
    "            })\n",
    "\n",
    "# Convert the data into a DataFrame for easy access\n",
    "df_ravdess = pd.DataFrame(data)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(df_ravdess.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89364f2a",
   "metadata": {},
   "source": [
    "### combining datasets \n",
    "\n",
    "We will merge the datsets into one dataframe, and assign unique identifiers\n",
    "- Concatenate the DataFrames for each dataset.\n",
    "- Assign a unique ID to each entry based on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07904761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id             filename  emotion           path\n",
      "0  c_0001  1001_DFA_ANG_XX.wav    angry  dataset\\Crema\n",
      "1  c_0002  1001_DFA_DIS_XX.wav  disgust  dataset\\Crema\n",
      "2  c_0003  1001_DFA_FEA_XX.wav     fear  dataset\\Crema\n",
      "3  c_0004  1001_DFA_HAP_XX.wav    happy  dataset\\Crema\n",
      "4  c_0005  1001_DFA_NEU_XX.wav  neutral  dataset\\Crema\n"
     ]
    }
   ],
   "source": [
    "# Add a unique ID column to each dataset\n",
    "df_crema['id'] = ['c_{:04d}'.format(i + 1) for i in range(len(df_crema))]\n",
    "df_tess['id'] = ['t_{:04d}'.format(i + 1) for i in range(len(df_tess))]\n",
    "df_savee['id'] = ['s_{:04d}'.format(i + 1) for i in range(len(df_savee))]\n",
    "df_ravdess['id'] = ['r_{:04d}'.format(i + 1) for i in range(len(df_ravdess))]\n",
    "\n",
    "# Merge the datasets into a single DataFrame\n",
    "merged_data = pd.concat([df_crema, df_tess, df_savee, df_ravdess], ignore_index=True)\n",
    "\n",
    "# Reorder columns to have 'id' as the first column\n",
    "merged_data = merged_data[['id', 'filename', 'emotion', 'path']]\n",
    "\n",
    "# Display the first few rows of the combined DataFrame\n",
    "print(merged_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b69b4f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in dataset: 12162\n"
     ]
    }
   ],
   "source": [
    "# remember, we need at least 1000 rows to meet our requirements. \n",
    "print(f\"Total rows in dataset: {merged_data.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88863e96",
   "metadata": {},
   "source": [
    "### Extracting Features\n",
    "\n",
    "Again, these are the features we will extract:\n",
    "\n",
    "- **Mel-frequency cepstral coefficients (MFCCs):** Represents the short-term power spectrum of sound, commonly used in speech and audio processing to capture the timbral texture of audio.\n",
    "- **Spectral centroid:** Indicates the \"center of mass\" of the spectrum and is often associated with the perceived brightness of a sound.\n",
    "- **Chroma features:** Represents the 12 different pitch classes and captures harmonic and melodic characteristics of music / voice.\n",
    "- **Zero-crossing rate:** Measures the rate at which the signal changes sign, giving insight into the noisiness or percussiveness of the sound.\n",
    "- **RMS energy:** Reflects the root mean square of the audio signal and indicates the energy or loudness of the sound.\n",
    "- **Pitch:** Refers to the perceived frequency of a sound, determining how high or low a sound is.\n",
    "\n",
    "We will be using the `librosa` package to process these audio features. [Here](https://librosa.org/doc/latest/index.html) is a link to the librosa documentation.\n",
    "\n",
    "**Note**: adding suppression for *UserWarning: Trying to estimate tuning from empty frequency set*. This is likely do to either:* **silence / low energy** (too quiet to perform reliable pitch estimation), or the file had **too short of a duration**. This warning shows up even when setting the pitch to 0 in this case.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "99d84ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_path):\n",
    "    # Load the audio file\n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "\n",
    "    # Check if the audio file is empty\n",
    "    if len(y) == 0:\n",
    "        print(f\"Warning: The file {file_path} is empty.\")\n",
    "        return (np.nan, np.nan, np.nan, np.nan, np.nan, np.nan)  # Return NaN for all features\n",
    "\n",
    "    # Extract features\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    mfccs_mean = np.mean(mfccs.T, axis=0)\n",
    "\n",
    "    spectral_centroid = np.mean(librosa.feature.spectral_centroid(y=y, sr=sr).T, axis=0)\n",
    "    chroma = np.mean(librosa.feature.chroma_stft(y=y, sr=sr).T, axis=0)\n",
    "    zero_crossing_rate = np.mean(librosa.feature.zero_crossing_rate(y).T, axis=0)\n",
    "    rms = np.mean(librosa.feature.rms(y=y).T, axis=0)\n",
    "\n",
    "    pitches, magnitudes = librosa.piptrack(y=y, sr=sr)\n",
    "    pitch = np.mean(pitches[pitches > 0]) if np.any(pitches > 0) else np.nan  # Handle case where pitch extraction fails\n",
    "\n",
    "    # Return features as a tuple\n",
    "    return (mfccs_mean, spectral_centroid, chroma, zero_crossing_rate, rms, pitch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9a3cea53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCCs Mean: [-306.0274       92.670235      8.491312     23.965403      7.4779935\n",
      "   -5.759455    -11.883088     -9.676736     -3.9967465   -13.352565\n",
      "    0.40819725   -9.709486     -6.1271243 ]\n",
      "Spectral Centroid: [1584.99307033]\n",
      "Chroma Features: [0.37491405 0.37949282 0.41722107 0.39018238 0.4148401  0.2977837\n",
      " 0.28898865 0.3575554  0.35190624 0.42918485 0.6879576  0.5454907 ]\n",
      "Zero-Crossing Rate: [0.10186768]\n",
      "RMS Energy: [0.04198619]\n",
      "Pitch: 1211.9507\n"
     ]
    }
   ],
   "source": [
    "# testing our extract_features function:\n",
    "first_row = merged_data.iloc[0]\n",
    "file_path = os.path.join(first_row['path'], first_row['filename'])\n",
    "\n",
    "# Extract features\n",
    "features = extract_features(file_path)\n",
    "\n",
    "# Print out each feature with its corresponding values\n",
    "print(\"MFCCs Mean:\", features[0])  # Changed to MFCCs Mean\n",
    "print(\"Spectral Centroid:\", features[1])\n",
    "print(\"Chroma Features:\", features[2])\n",
    "print(\"Zero-Crossing Rate:\", features[3])\n",
    "print(\"RMS Energy:\", features[4])\n",
    "print(\"Pitch:\", features[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793edea3",
   "metadata": {},
   "source": [
    "### Validating the Values:\n",
    "\n",
    "- **MFCCs:** Typically, MFCC values range from -400 to 400, depending on the scale of the input signal.\n",
    "> All values: **pass**\n",
    "\n",
    "- **Spectral Centroid:** This value represents the \"center of mass\" of the spectrum and typically ranges between 0 and the - Nyquist frequency (half the sampling rate).\n",
    "> 1584.99: **pass**\n",
    "\n",
    "- **Chroma Features:** These represent the energy distribution across 12 pitch classes. They are normalized, so values between 0 and 1 are expected.\n",
    "> All values: **pass**\n",
    "\n",
    "- **Zero-Crossing Rate:** This rate indicates how frequently the signal changes sign. It ranges from 0 to 1. \n",
    "> 0.1018: **pass**\n",
    "\n",
    "- **RMS Energy:** This value should be within the range of 0 to 1 for normalized signals.\n",
    "> 0.0419: **pass**\n",
    "\n",
    "- **Pitch:** Pitch values are measured in Hz, and depends on the type of audio.\n",
    "> 1211.95: **pass**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ab3206",
   "metadata": {},
   "source": [
    "Now that we've validated our extract_features function, we can apply it to the rest of our dataframe.\n",
    "\n",
    "**Notes**: \n",
    "- This cell can take a while to run! About 5 minutes\n",
    "- suppressed UserWarning: Trying to estimate tuning from empty frequency set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5d2f4af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                    0\n",
      "filename              0\n",
      "emotion               0\n",
      "path                  0\n",
      "mfccs                 0\n",
      "spectral_centroid     0\n",
      "chroma                0\n",
      "zero_crossing_rate    0\n",
      "rms                   0\n",
      "pitch                 1\n",
      "mfccs_mean            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Empty lists to store features\n",
    "mfccs_mean_list = []\n",
    "spectral_centroid_list = []\n",
    "chroma_list = []\n",
    "zero_crossing_rate_list = []\n",
    "rms_list = []\n",
    "pitch_list = []\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for index, row in merged_data.iterrows():\n",
    "    file_path = os.path.join(row['path'], row['filename'])\n",
    "    features = extract_features(file_path)\n",
    "    \n",
    "    # Append the features to their respective lists\n",
    "    mfccs_mean_list.append(features[0])\n",
    "    spectral_centroid_list.append(features[1])\n",
    "    chroma_list.append(features[2])\n",
    "    zero_crossing_rate_list.append(features[3])\n",
    "    rms_list.append(features[4])\n",
    "    pitch_list.append(features[5])\n",
    "\n",
    "# Add the features to the DataFrame\n",
    "merged_data['mfccs_mean'] = mfccs_mean_list\n",
    "merged_data['spectral_centroid'] = spectral_centroid_list\n",
    "merged_data['chroma'] = chroma_list\n",
    "merged_data['zero_crossing_rate'] = zero_crossing_rate_list\n",
    "merged_data['rms'] = rms_list\n",
    "merged_data['pitch'] = pitch_list\n",
    "\n",
    "# Check for any NaN values in the DataFrame\n",
    "print(merged_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "914500ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>filename</th>\n",
       "      <th>emotion</th>\n",
       "      <th>path</th>\n",
       "      <th>mfccs</th>\n",
       "      <th>spectral_centroid</th>\n",
       "      <th>chroma</th>\n",
       "      <th>zero_crossing_rate</th>\n",
       "      <th>rms</th>\n",
       "      <th>pitch</th>\n",
       "      <th>mfccs_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c_0001</td>\n",
       "      <td>1001_DFA_ANG_XX.wav</td>\n",
       "      <td>angry</td>\n",
       "      <td>dataset\\Crema</td>\n",
       "      <td>[-306.0274, 92.670235, 8.491312, 23.965403, 7....</td>\n",
       "      <td>[1584.9930703294388]</td>\n",
       "      <td>[0.37491405, 0.37949282, 0.41722107, 0.3901823...</td>\n",
       "      <td>[0.10186767578125]</td>\n",
       "      <td>[0.041986194]</td>\n",
       "      <td>1211.950684</td>\n",
       "      <td>[-306.0274, 92.670235, 8.491312, 23.965403, 7....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c_0002</td>\n",
       "      <td>1001_DFA_DIS_XX.wav</td>\n",
       "      <td>disgust</td>\n",
       "      <td>dataset\\Crema</td>\n",
       "      <td>[-346.39963, 95.83912, 10.516282, 31.619215, 1...</td>\n",
       "      <td>[1531.650486749737]</td>\n",
       "      <td>[0.47289878, 0.4768195, 0.33598945, 0.34610763...</td>\n",
       "      <td>[0.09306105522260275]</td>\n",
       "      <td>[0.015996357]</td>\n",
       "      <td>1256.617188</td>\n",
       "      <td>[-346.39963, 95.83912, 10.516282, 31.619215, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c_0003</td>\n",
       "      <td>1001_DFA_FEA_XX.wav</td>\n",
       "      <td>fear</td>\n",
       "      <td>dataset\\Crema</td>\n",
       "      <td>[-321.42026, 94.76091, 8.155397, 23.323242, 11...</td>\n",
       "      <td>[1489.0888388536061]</td>\n",
       "      <td>[0.3272673, 0.39935032, 0.35215598, 0.38248017...</td>\n",
       "      <td>[0.08428596047794118]</td>\n",
       "      <td>[0.045776337]</td>\n",
       "      <td>992.574402</td>\n",
       "      <td>[-321.42026, 94.76091, 8.155397, 23.323242, 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c_0004</td>\n",
       "      <td>1001_DFA_HAP_XX.wav</td>\n",
       "      <td>happy</td>\n",
       "      <td>dataset\\Crema</td>\n",
       "      <td>[-303.30374, 92.52889, 4.231231, 27.970133, 10...</td>\n",
       "      <td>[1555.37603547111]</td>\n",
       "      <td>[0.3150873, 0.31478375, 0.30918238, 0.3423785,...</td>\n",
       "      <td>[0.0848781779661017]</td>\n",
       "      <td>[0.042300183]</td>\n",
       "      <td>1102.953003</td>\n",
       "      <td>[-303.30374, 92.52889, 4.231231, 27.970133, 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c_0005</td>\n",
       "      <td>1001_DFA_NEU_XX.wav</td>\n",
       "      <td>neutral</td>\n",
       "      <td>dataset\\Crema</td>\n",
       "      <td>[-335.4959, 100.39331, 9.384935, 30.160904, 11...</td>\n",
       "      <td>[1495.3949968411737]</td>\n",
       "      <td>[0.4112704, 0.36269408, 0.3349767, 0.32547352,...</td>\n",
       "      <td>[0.08203125]</td>\n",
       "      <td>[0.020449637]</td>\n",
       "      <td>1041.093628</td>\n",
       "      <td>[-335.4959, 100.39331, 9.384935, 30.160904, 11...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id             filename  emotion           path  \\\n",
       "0  c_0001  1001_DFA_ANG_XX.wav    angry  dataset\\Crema   \n",
       "1  c_0002  1001_DFA_DIS_XX.wav  disgust  dataset\\Crema   \n",
       "2  c_0003  1001_DFA_FEA_XX.wav     fear  dataset\\Crema   \n",
       "3  c_0004  1001_DFA_HAP_XX.wav    happy  dataset\\Crema   \n",
       "4  c_0005  1001_DFA_NEU_XX.wav  neutral  dataset\\Crema   \n",
       "\n",
       "                                               mfccs     spectral_centroid  \\\n",
       "0  [-306.0274, 92.670235, 8.491312, 23.965403, 7....  [1584.9930703294388]   \n",
       "1  [-346.39963, 95.83912, 10.516282, 31.619215, 1...   [1531.650486749737]   \n",
       "2  [-321.42026, 94.76091, 8.155397, 23.323242, 11...  [1489.0888388536061]   \n",
       "3  [-303.30374, 92.52889, 4.231231, 27.970133, 10...    [1555.37603547111]   \n",
       "4  [-335.4959, 100.39331, 9.384935, 30.160904, 11...  [1495.3949968411737]   \n",
       "\n",
       "                                              chroma     zero_crossing_rate  \\\n",
       "0  [0.37491405, 0.37949282, 0.41722107, 0.3901823...     [0.10186767578125]   \n",
       "1  [0.47289878, 0.4768195, 0.33598945, 0.34610763...  [0.09306105522260275]   \n",
       "2  [0.3272673, 0.39935032, 0.35215598, 0.38248017...  [0.08428596047794118]   \n",
       "3  [0.3150873, 0.31478375, 0.30918238, 0.3423785,...   [0.0848781779661017]   \n",
       "4  [0.4112704, 0.36269408, 0.3349767, 0.32547352,...           [0.08203125]   \n",
       "\n",
       "             rms        pitch  \\\n",
       "0  [0.041986194]  1211.950684   \n",
       "1  [0.015996357]  1256.617188   \n",
       "2  [0.045776337]   992.574402   \n",
       "3  [0.042300183]  1102.953003   \n",
       "4  [0.020449637]  1041.093628   \n",
       "\n",
       "                                          mfccs_mean  \n",
       "0  [-306.0274, 92.670235, 8.491312, 23.965403, 7....  \n",
       "1  [-346.39963, 95.83912, 10.516282, 31.619215, 1...  \n",
       "2  [-321.42026, 94.76091, 8.155397, 23.323242, 11...  \n",
       "3  [-303.30374, 92.52889, 4.231231, 27.970133, 10...  \n",
       "4  [-335.4959, 100.39331, 9.384935, 30.160904, 11...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data['pitch'] = merged_data['pitch'].fillna(0)\n",
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18313e3",
   "metadata": {},
   "source": [
    "We won't be able to work with arrays - we will need to extract a meaningful metric and save them in a new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c2603f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mfccs_mean  spectral_centroid    chroma  zero_crossing_rate       rms  \\\n",
      "0  -17.963037        1584.993070  0.411293            0.101868  0.041986   \n",
      "1  -18.657297        1531.650487  0.423961            0.093061  0.015996   \n",
      "2  -18.552622        1489.088839  0.413398            0.084286  0.045776   \n",
      "3  -18.460817        1555.376035  0.394820            0.084878  0.042300   \n",
      "4  -18.111607        1495.394997  0.401279            0.082031  0.020450   \n",
      "\n",
      "         pitch  emotion  \n",
      "0  1211.950684    angry  \n",
      "1  1256.617188  disgust  \n",
      "2   992.574402     fear  \n",
      "3  1102.953003    happy  \n",
      "4  1041.093628  neutral  \n"
     ]
    }
   ],
   "source": [
    "# Create a new DataFrame for the cleaned features\n",
    "clean_data = pd.DataFrame()\n",
    "\n",
    "# Store the mean of array values and existing values for non-array columns\n",
    "clean_data['mfccs_mean'] = merged_data['mfccs'].apply(lambda x: np.mean(x) if isinstance(x, (list, np.ndarray)) and len(x) > 0 else np.nan)\n",
    "clean_data['spectral_centroid'] = merged_data['spectral_centroid'].apply(lambda x: np.mean(x) if isinstance(x, (list, np.ndarray)) and len(x) > 0 else np.nan)\n",
    "clean_data['chroma'] = merged_data['chroma'].apply(lambda x: np.mean(x) if isinstance(x, (list, np.ndarray)) and len(x) > 0 else np.nan)\n",
    "clean_data['zero_crossing_rate'] = merged_data['zero_crossing_rate'].apply(lambda x: x[0] if isinstance(x, (list, np.ndarray)) and len(x) > 0 else np.nan)\n",
    "clean_data['rms'] = merged_data['rms'].apply(lambda x: x[0] if isinstance(x, (list, np.ndarray)) and len(x) > 0 else np.nan)\n",
    "clean_data['pitch'] = merged_data['pitch']  # Directly store the existing value\n",
    "\n",
    "# Add the emotion column\n",
    "clean_data['emotion'] = merged_data['emotion']\n",
    "\n",
    "# Display the new DataFrame\n",
    "print(clean_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5cd5d279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mfccs_mean            0\n",
      "spectral_centroid     0\n",
      "chroma                0\n",
      "zero_crossing_rate    0\n",
      "rms                   0\n",
      "pitch                 0\n",
      "emotion               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for any NaN values in the DataFrame\n",
    "print(clean_data.isnull().sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
