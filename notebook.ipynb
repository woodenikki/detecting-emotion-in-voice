{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "677ee134",
   "metadata": {},
   "source": [
    "# MoodWave: Voice-Driven Emotion Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a17ee2a",
   "metadata": {},
   "source": [
    "## Data Guidelines\n",
    "\n",
    "Your dataset must be:\n",
    "\n",
    "- Appropriate for classification. It should have a categorical outcome or the data needed to engineer one.\n",
    "\n",
    "- Usable to solve a specific business problem. This solution must rely on your classification model.\n",
    "\n",
    "- Somewhat complex. It should contain a minimum of 1000 rows and 10 features.\n",
    "\n",
    "- Unfamiliar. It can't be one we've already worked with during the course or that is commonly used for demonstration purposes (e.g. Titanic).\n",
    "\n",
    "- Manageable. Stick to datasets that you can model using the techniques introduced in Phase 3.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e19b96e",
   "metadata": {},
   "source": [
    "### Phase 3 Concepts used in this project:\n",
    "\n",
    "- Logistic Regression:\n",
    "\n",
    "> Logistic regression is a fundamental classification algorithm that's well-suited for binary and multiclass classification tasks. It's a good choice if your dataset has clear decision boundaries.\n",
    "\n",
    "- Decision Trees:\n",
    "\n",
    "> Decision trees are versatile and interpretable models that can handle both categorical and continuous data. They are particularly useful when you want to understand the decision-making process of your model.\n",
    "\n",
    "- Evaluation Metrics (Confusion Matrices, ROC Curves, AUC):\n",
    "\n",
    "> These metrics are essential for assessing the performance of your classification model. They will help you understand how well your model distinguishes between different emotional states.\n",
    "\n",
    "- Hyperparameter Tuning and Pruning:\n",
    "\n",
    "> When using decision trees, tuning hyperparameters and pruning are important to avoid overfitting and to ensure your model generalizes well to new data.\n",
    "\n",
    "- Binary Classification\n",
    "\n",
    "> When audio augmentation did not prove (too) effective, ... [TODO]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d983581",
   "metadata": {},
   "source": [
    "## Data Understanding\n",
    "\n",
    "In this project, we are dealing with four datasets containing audio recordings in the .wav format. Each audio recording is labeled with an emotion that the speaker is evoking in their statement. Our goal is to build a model that can successfully map an emotion to a given voice clip of someone speaking.\n",
    "\n",
    "To achieve this, we will extract various features from the audio recordings that are relevant for analyzing speech and emotion. Here are the features we will be working with and their significance:\n",
    "\n",
    "1. **Mel-frequency Cepstral Coefficients (MFCCs):** MFCCs are a compact representation of the short-term power spectrum of a sound. They are widely used in speech recognition and audio analysis tasks because they capture the essential characteristics of the audio signal while being robust to noise and other variabilities. MFCCs are particularly useful for identifying the phonetic content of speech, which can be helpful in determining the emotional state of the speaker.\n",
    "\n",
    "2. **Spectral Centroid:** The spectral centroid is a measure of the brightness or sharpness of a sound. It represents the weighted mean frequency of the spectrum and can be used to distinguish between different types of sounds or emotions. For example, a bright, harsh sound might have a higher spectral centroid than a mellow, soft sound.\n",
    "\n",
    "3. **Chroma Features:** Chroma features describe the distribution of energy across different pitch classes (notes) in the audio signal. They are useful for capturing tonal information, which can be relevant for identifying emotions in speech, particularly those related to intonation patterns and stress.\n",
    "\n",
    "4. **Zero-Crossing Rate:** The zero-crossing rate is a measure of the number of times the audio signal crosses the zero amplitude axis within a given time frame. It can be used to distinguish between different types of sounds, such as voiced and unvoiced speech, and can provide insights into the energy distribution of the audio signal.\n",
    "RMS Energy: The Root Mean Square (RMS) energy is a measure of the overall energy or loudness of an audio signal. It can be useful for detecting variations in volume or intensity, which can be indicative of certain emotions, such as anger or excitement.\n",
    "\n",
    "5. **Pitch:** The pitch feature represents the fundamental frequency of the audio signal. It is closely related to the perception of tone and can be useful for analyzing the intonation patterns and stress levels in speech, which can be indicators of different emotional states.\n",
    "\n",
    "---\n",
    "\n",
    "By extracting and analyzing these features, we can capture various acoustic characteristics of the speech signal that may be relevant for distinguishing between different emotions. This multi-faceted approach can provide a more comprehensive representation of the audio data, potentially leading to better performance in the emotion classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0187a9c3",
   "metadata": {},
   "source": [
    "## Data Preperation\n",
    "\n",
    "Here 4 most popular datasets in English: Crema, Ravdess, Savee and Tess. Each of them contains audio in .wav format with some main labels.\n",
    "\n",
    "Because our data isn't inherinantly in a csv / dataframe format, we will have to create it from scratch!\n",
    "\n",
    "First, we will pull all data into their own dataframe, making note of *where* the file is, so we can later pull our features from each audio file. \n",
    "\n",
    "After each dataset has been imported into its own dataframe, we will merge them all into one dataframe. Then, we can extract our desired audio features:\n",
    "\n",
    "- Mel-frequency cepstral coefficients (MFCCs)\n",
    "- Spectral centroid\n",
    "- Chroma features\n",
    "- Zero-crossing rate\n",
    "- RMS energy\n",
    "- Pitch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e562f872",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import zipfile\n",
    "import librosa\n",
    "import random\n",
    "import os\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import resample\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from scipy.stats import skew, kurtosis\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2b03239a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data is zipped, and stored in folders for which dataset they came from:\n",
    "\n",
    "# Define the path to the zipped dataset\n",
    "zip_file_path = 'dataset.zip'\n",
    "extracted_folder_path = 'dataset'\n",
    "\n",
    "# Unzip the dataset\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extracted_folder_path)\n",
    "\n",
    "# Crema\n",
    "# Ravdess\n",
    "# Savee\n",
    "# Tess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "81898bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              filename  emotion           path\n",
      "0  1001_DFA_ANG_XX.wav    angry  dataset\\Crema\n",
      "1  1001_DFA_DIS_XX.wav  disgust  dataset\\Crema\n",
      "2  1001_DFA_FEA_XX.wav     fear  dataset\\Crema\n",
      "3  1001_DFA_HAP_XX.wav    happy  dataset\\Crema\n",
      "4  1001_DFA_NEU_XX.wav  neutral  dataset\\Crema\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the Crema folder\n",
    "crema_folder_path = os.path.join(extracted_folder_path, 'Crema')\n",
    "\n",
    "# Verify that we can access the files and extract emotion labels\n",
    "data = []\n",
    "\n",
    "# Loop through each file in the Crema folder\n",
    "for file_name in os.listdir(crema_folder_path):\n",
    "    if file_name.endswith('.wav'):\n",
    "        # Extract the emotion label from the filename\n",
    "        parts = file_name.split('_')\n",
    "        emotion_code = parts[2]\n",
    "        \n",
    "        # Map the emotion code to the actual emotion label\n",
    "        emotion_map = {\n",
    "            'SAD': 'sadness',\n",
    "            'ANG': 'angry',\n",
    "            'DIS': 'disgust',\n",
    "            'FEA': 'fear',\n",
    "            'HAP': 'happy',\n",
    "            'NEU': 'neutral'\n",
    "        }\n",
    "        emotion_label = emotion_map.get(emotion_code, 'unknown')\n",
    "        \n",
    "        # Store the data with the directory path minus the filename\n",
    "        data.append({'filename': file_name, 'emotion': emotion_label, 'path': crema_folder_path})\n",
    "\n",
    "# Convert the data into a DataFrame for easy access\n",
    "df_crema = pd.DataFrame(data)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(df_crema.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "249ec78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             filename emotion                    path\n",
      "0  OAF_back_angry.wav   angry  dataset\\Tess\\OAF_angry\n",
      "1   OAF_bar_angry.wav   angry  dataset\\Tess\\OAF_angry\n",
      "2  OAF_base_angry.wav   angry  dataset\\Tess\\OAF_angry\n",
      "3  OAF_bath_angry.wav   angry  dataset\\Tess\\OAF_angry\n",
      "4  OAF_bean_angry.wav   angry  dataset\\Tess\\OAF_angry\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the Tess folder\n",
    "tess_folder_path = os.path.join(extracted_folder_path, 'Tess')\n",
    "\n",
    "# Prepare to store the data\n",
    "data = []\n",
    "\n",
    "# Loop through each emotion folder in the Tess directory\n",
    "for emotion_folder in os.listdir(tess_folder_path):\n",
    "    # Get the full path to the emotion folder\n",
    "    emotion_folder_path = os.path.join(tess_folder_path, emotion_folder)\n",
    "    \n",
    "    # Extract the emotion from the folder name (e.g., \"OAF_angry\" -> \"angry\")\n",
    "    emotion_label = emotion_folder.split('_')[1]\n",
    "    \n",
    "    # Loop through each file in the emotion folder\n",
    "    for file_name in os.listdir(emotion_folder_path):\n",
    "        if file_name.endswith('.wav'):\n",
    "            # Store the data with the directory path minus the filename\n",
    "            data.append({\n",
    "                'filename': file_name, \n",
    "                'emotion': emotion_label, \n",
    "                'path': emotion_folder_path\n",
    "            })\n",
    "\n",
    "# Convert the data into a DataFrame for easy access\n",
    "df_tess = pd.DataFrame(data)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(df_tess.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8950b7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     filename  emotion           path\n",
      "0  DC_a01.wav  unknown  dataset\\Savee\n",
      "1  DC_a02.wav  unknown  dataset\\Savee\n",
      "2  DC_a03.wav  unknown  dataset\\Savee\n",
      "3  DC_a04.wav  unknown  dataset\\Savee\n",
      "4  DC_a05.wav  unknown  dataset\\Savee\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the Savee folder\n",
    "savee_folder_path = os.path.join(extracted_folder_path, 'Savee')\n",
    "\n",
    "# Prepare to store the data\n",
    "data = []\n",
    "\n",
    "# Define the emotion mapping based on the prefixes\n",
    "emotion_map = {\n",
    "    'a': 'anger',\n",
    "    'd': 'disgust',\n",
    "    'f': 'fear',\n",
    "    'h': 'happiness',\n",
    "    'n': 'neutral',\n",
    "    'sa': 'sadness',\n",
    "    'su': 'surprise'\n",
    "}\n",
    "\n",
    "# Loop through each file in the Savee folder\n",
    "for file_name in os.listdir(savee_folder_path):\n",
    "    if file_name.endswith('.wav'):\n",
    "        # Extract the prefix from the filename to determine the emotion\n",
    "        prefix = file_name.split('_')[1][:2]\n",
    "        \n",
    "        # Map the prefix to the corresponding emotion\n",
    "        emotion_label = emotion_map.get(prefix, 'unknown')\n",
    "        \n",
    "        # Store the data with the directory path minus the filename\n",
    "        data.append({\n",
    "            'filename': file_name, \n",
    "            'emotion': emotion_label, \n",
    "            'path': savee_folder_path\n",
    "        })\n",
    "\n",
    "# Convert the data into a DataFrame for easy access\n",
    "df_savee = pd.DataFrame(data)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(df_savee.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b48984d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   filename  emotion  \\\n",
      "0  03-01-01-01-01-01-01.wav  neutral   \n",
      "1  03-01-01-01-01-02-01.wav  neutral   \n",
      "2  03-01-01-01-02-01-01.wav  neutral   \n",
      "3  03-01-01-01-02-02-01.wav  neutral   \n",
      "4  03-01-02-01-01-01-01.wav     calm   \n",
      "\n",
      "                                                path  \n",
      "0  dataset\\Ravdess\\audio_speech_actors_01-24\\Acto...  \n",
      "1  dataset\\Ravdess\\audio_speech_actors_01-24\\Acto...  \n",
      "2  dataset\\Ravdess\\audio_speech_actors_01-24\\Acto...  \n",
      "3  dataset\\Ravdess\\audio_speech_actors_01-24\\Acto...  \n",
      "4  dataset\\Ravdess\\audio_speech_actors_01-24\\Acto...  \n"
     ]
    }
   ],
   "source": [
    "# Define the path to the Ravdess folder\n",
    "ravdess_folder_path = os.path.join(extracted_folder_path, 'Ravdess', 'audio_speech_actors_01-24')\n",
    "\n",
    "# Prepare to store the data\n",
    "data = []\n",
    "\n",
    "# Define the emotion mapping based on the third component in the filename\n",
    "emotion_map = {\n",
    "    '01': 'neutral',\n",
    "    '02': 'calm',\n",
    "    '03': 'happy',\n",
    "    '04': 'sad',\n",
    "    '05': 'angry',\n",
    "    '06': 'fearful',\n",
    "    '07': 'disgust',\n",
    "    '08': 'surprised'\n",
    "}\n",
    "\n",
    "# Loop through each actor's folder in the Ravdess directory\n",
    "for actor_folder in os.listdir(ravdess_folder_path):\n",
    "    actor_folder_path = os.path.join(ravdess_folder_path, actor_folder)\n",
    "    \n",
    "    # Loop through each file in the actor's folder\n",
    "    for file_name in os.listdir(actor_folder_path):\n",
    "        if file_name.endswith('.wav'):\n",
    "            # Extract the third component from the filename to determine the emotion\n",
    "            emotion_code = file_name.split('-')[2]\n",
    "            \n",
    "            # Map the emotion code to the corresponding emotion label\n",
    "            emotion_label = emotion_map.get(emotion_code, 'unknown')\n",
    "            \n",
    "            # Store the data with the directory path minus the filename\n",
    "            data.append({\n",
    "                'filename': file_name, \n",
    "                'emotion': emotion_label, \n",
    "                'path': actor_folder_path\n",
    "            })\n",
    "\n",
    "# Convert the data into a DataFrame for easy access\n",
    "df_ravdess = pd.DataFrame(data)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(df_ravdess.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc8963e",
   "metadata": {},
   "source": [
    "### Combining datasets \n",
    "\n",
    "We will merge the datsets into one dataframe, and assign unique identifiers\n",
    "- Concatenate the DataFrames for each dataset.\n",
    "- Assign a unique ID to each entry based on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "04d7118e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id             filename  emotion           path\n",
      "0  c_0001  1001_DFA_ANG_XX.wav    angry  dataset\\Crema\n",
      "1  c_0002  1001_DFA_DIS_XX.wav  disgust  dataset\\Crema\n",
      "2  c_0003  1001_DFA_FEA_XX.wav     fear  dataset\\Crema\n",
      "3  c_0004  1001_DFA_HAP_XX.wav    happy  dataset\\Crema\n",
      "4  c_0005  1001_DFA_NEU_XX.wav  neutral  dataset\\Crema\n"
     ]
    }
   ],
   "source": [
    "# Add a unique ID column to each dataset\n",
    "df_crema['id'] = ['c_{:04d}'.format(i + 1) for i in range(len(df_crema))]\n",
    "df_tess['id'] = ['t_{:04d}'.format(i + 1) for i in range(len(df_tess))]\n",
    "df_savee['id'] = ['s_{:04d}'.format(i + 1) for i in range(len(df_savee))]\n",
    "df_ravdess['id'] = ['r_{:04d}'.format(i + 1) for i in range(len(df_ravdess))]\n",
    "\n",
    "# Merge the datasets into a single DataFrame\n",
    "merged_data = pd.concat([df_crema, df_tess, df_savee, df_ravdess], ignore_index=True)\n",
    "\n",
    "# Reorder columns to have 'id' as the first column\n",
    "merged_data = merged_data[['id', 'filename', 'emotion', 'path']]\n",
    "\n",
    "# Display the first few rows of the combined DataFrame\n",
    "print(merged_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7db3421b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in dataset: 12162\n"
     ]
    }
   ],
   "source": [
    "# remember, we need at least 1000 rows to meet our requirements. \n",
    "print(f\"Total rows in dataset: {merged_data.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bfd835",
   "metadata": {},
   "source": [
    "### Extracting Features\n",
    "\n",
    "Again, these are the features we will extract:\n",
    "\n",
    "- **Mel-frequency cepstral coefficients (MFCCs):** Represents the short-term power spectrum of sound, commonly used in speech and audio processing to capture the timbral texture of audio. We extract the **mean**, **standard deviation**, **skewness**, and **kurtosis** of the MFCCs.\n",
    "\n",
    "- **Spectral centroid:** Indicates the \"center of mass\" of the spectrum and is often associated with the perceived brightness of a sound. We extract the **mean**, **standard deviation**, **skewness**, and **kurtosis** of the spectral centroid.\n",
    "\n",
    "- **Chroma features:** Represents the 12 different pitch classes and captures harmonic and melodic characteristics of music or voice. We extract the **mean** and **standard deviation** of the chroma features.\n",
    "\n",
    "- **Zero-crossing rate (ZCR):** Measures the rate at which the signal changes sign, giving insight into the noisiness or percussiveness of the sound. We extract the **mean** and **standard deviation** of the zero-crossing rate.\n",
    "\n",
    "- **RMS energy:** Reflects the root mean square of the audio signal and indicates the energy or loudness of the sound. We extract the **mean** and **standard deviation** of the RMS energy.\n",
    "\n",
    "- **Spectral bandwidth:** Measures the width of the frequency band, providing information about the range of frequencies present in the sound. We extract the **mean** and **standard deviation** of the spectral bandwidth.\n",
    "\n",
    "- **Spectral rolloff:** Represents the frequency below which a certain percentage (typically 85%) of the total spectral energy is contained. We extract the **mean** and **standard deviation** of the spectral rolloff.\n",
    "\n",
    "- **Tonnetz:** Represents the tonal centroids, which capture harmonic relationships in audio. We extract the **mean** and **standard deviation** of the tonal centroids.\n",
    "\n",
    "- **Pitch:** Refers to the perceived frequency of a sound, determining how high or low a sound is. We extract the **mean** and **standard deviation** of the pitch.\n",
    "\n",
    "We will be using the `librosa` package to process these audio features. [Here](https://librosa.org/doc/latest/index.html) is a link to the librosa documentation.\n",
    "\n",
    "**Note**: adding suppression for *UserWarning: Trying to estimate tuning from empty frequency set*. This is likely do to either:* **silence / low energy** (too quiet to perform reliable pitch estimation), or the file had **too short of a duration**. This warning shows up even when setting the pitch to 0 in this case.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "450a16fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(data, sr=None, from_file=True):\n",
    "    if from_file:\n",
    "        y, sr = librosa.load(data, sr=sr)\n",
    "    else:\n",
    "        y = data\n",
    "\n",
    "    if len(y) == 0:\n",
    "        print(f\"Warning: The file {data} is empty.\")\n",
    "        return (np.zeros(13), np.zeros(4), np.zeros(12), 0, 0, 0, 0)\n",
    "\n",
    "    # Extract MFCCs and compute statistics\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    mfccs_mean = mfccs.mean(axis=1)\n",
    "    mfccs_std = mfccs.std(axis=1)\n",
    "    mfccs_skewness = np.apply_along_axis(lambda x: np.mean((x - np.mean(x))**3) / (np.std(x)**3 + 1e-6), axis=1, arr=mfccs)\n",
    "    mfccs_kurtosis = np.apply_along_axis(lambda x: np.mean((x - np.mean(x))**4) / (np.std(x)**4 + 1e-6), axis=1, arr=mfccs)\n",
    "\n",
    "    # Extract spectral centroid and compute statistics\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    spectral_centroid_mean = np.mean(spectral_centroid)\n",
    "    spectral_centroid_std = np.std(spectral_centroid)\n",
    "    spectral_centroid_skewness = np.mean((spectral_centroid - spectral_centroid_mean)**3) / (spectral_centroid_std**3 + 1e-6)\n",
    "    spectral_centroid_kurtosis = np.mean((spectral_centroid - spectral_centroid_mean)**4) / (spectral_centroid_std**4 + 1e-6)\n",
    "\n",
    "    # Extract other features\n",
    "    chroma = np.mean(librosa.feature.chroma_stft(y=y, sr=sr).T, axis=0)\n",
    "    zero_crossing_rate = np.mean(librosa.feature.zero_crossing_rate(y).T, axis=0)\n",
    "    rms = np.mean(librosa.feature.rms(y=y).T, axis=0)\n",
    "\n",
    "    # Extract pitch using the piptrack function\n",
    "    pitches, magnitudes = librosa.piptrack(y=y, sr=sr)\n",
    "    pitch = np.mean(pitches[pitches > 0]) if np.any(pitches > 0) else 0\n",
    "\n",
    "    # Return all the features in a tuple\n",
    "    return (\n",
    "        mfccs_mean,\n",
    "        mfccs_std,   \n",
    "        mfccs_skewness,  \n",
    "        mfccs_kurtosis,  \n",
    "        [spectral_centroid_mean, spectral_centroid_std, spectral_centroid_skewness, spectral_centroid_kurtosis],  \n",
    "        chroma,  \n",
    "        zero_crossing_rate,  \n",
    "        rms,  \n",
    "        pitch\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c185a3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCCs Mean: [-306.0274       92.670235      8.491312     23.965403      7.4779935\n",
      "   -5.759455    -11.883088     -9.676736     -3.9967465   -13.352565\n",
      "    0.40819725   -9.709486     -6.1271243 ]\n",
      "MFCCs Std: [159.39034    28.411352   32.853794   18.576996   17.579239   18.029716\n",
      "  15.681951   16.126402    6.8317485   7.5677075   7.519526    7.9452553\n",
      "   6.322871 ]\n",
      "MFCCs Skewness: [ 0.20764599 -1.66643656 -0.66651808 -0.82776392 -1.87041241 -0.37326772\n",
      " -0.65912122 -0.56676317  0.46111047 -0.57118155  0.52761803 -0.61640204\n",
      " -0.07975197]\n",
      "MFCCs Kurtosis: [1.53089086 6.25596779 2.06268014 4.3404881  6.86903528 1.79147207\n",
      " 1.89175263 2.70528984 3.21104205 2.8317225  2.31720692 3.37706481\n",
      " 4.10525129]\n",
      "Spectral Centroid (Mean, Std, Skewness, Kurtosis): [1584.9930703294388, 600.4107533810885, 1.645967919033302, 5.91406452763243]\n",
      "Chroma Features (Mean): [0.37491405 0.37949282 0.41722107 0.39018238 0.4148401  0.2977837\n",
      " 0.28898865 0.3575554  0.35190624 0.42918485 0.6879576  0.5454907 ]\n",
      "Zero-Crossing Rate (Mean): [0.10186768]\n",
      "RMS Energy (Mean): [0.04198619]\n",
      "Pitch (Mean): 1211.9507\n"
     ]
    }
   ],
   "source": [
    "# testing our extract_features function:\n",
    "first_row = merged_data.iloc[0]\n",
    "file_path = os.path.join(first_row['path'], first_row['filename'])\n",
    "\n",
    "# Extract features directly from the file path\n",
    "features = extract_features(file_path)\n",
    "\n",
    "# Print out each feature with its corresponding values\n",
    "print(\"MFCCs Mean:\", features[0])\n",
    "print(\"MFCCs Std:\", features[1])\n",
    "print(\"MFCCs Skewness:\", features[2])\n",
    "print(\"MFCCs Kurtosis:\", features[3])\n",
    "print(\"Spectral Centroid (Mean, Std, Skewness, Kurtosis):\", features[4])\n",
    "print(\"Chroma Features (Mean):\", features[5])\n",
    "print(\"Zero-Crossing Rate (Mean):\", features[6])\n",
    "print(\"RMS Energy (Mean):\", features[7])\n",
    "print(\"Pitch (Mean):\", features[8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220208d6",
   "metadata": {},
   "source": [
    "### Validating the Values:\n",
    "\n",
    "- **MFCCs:** Typically, MFCC values range from -400 to 400, depending on the scale of the input signal.\n",
    "> All values: **pass**\n",
    "\n",
    "- **Spectral Centroid:** This value represents the \"center of mass\" of the spectrum and typically ranges between 0 and the - Nyquist frequency (half the sampling rate).\n",
    "> 1584.99: **pass**\n",
    "\n",
    "- **Chroma Features:** These represent the energy distribution across 12 pitch classes. They are normalized, so values between 0 and 1 are expected.\n",
    "> All values: **pass**\n",
    "\n",
    "- **Zero-Crossing Rate:** This rate indicates how frequently the signal changes sign. It ranges from 0 to 1. \n",
    "> 0.1018: **pass**\n",
    "\n",
    "- **RMS Energy:** This value should be within the range of 0 to 1 for normalized signals.\n",
    "> 0.0419: **pass**\n",
    "\n",
    "- **Pitch:** Pitch values are measured in Hz, and depends on the type of audio.\n",
    "> 1211.95: **pass**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a058d2c2",
   "metadata": {},
   "source": [
    "Now that we've validated our extract_features function, we can apply it to the rest of our dataframe.\n",
    "\n",
    "**Notes**: \n",
    "- This cell can take a while to run! About 5 minutes\n",
    "- suppressed UserWarning: Trying to estimate tuning from empty frequency set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b932aed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                            0\n",
      "filename                      0\n",
      "emotion                       0\n",
      "path                          0\n",
      "mfccs_mean                    0\n",
      "mfccs_std                     0\n",
      "mfccs_skewness                0\n",
      "mfccs_kurtosis                0\n",
      "spectral_centroid             0\n",
      "spectral_centroid_std         0\n",
      "spectral_centroid_skewness    0\n",
      "spectral_centroid_kurtosis    0\n",
      "chroma                        0\n",
      "zero_crossing_rate            0\n",
      "rms                           0\n",
      "pitch                         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Empty lists to store features\n",
    "mfccs_mean_list = []\n",
    "mfccs_std_list = []\n",
    "mfccs_skewness_list = []\n",
    "mfccs_kurtosis_list = []\n",
    "\n",
    "spectral_centroid_list = []\n",
    "spectral_centroid_std_list = []\n",
    "spectral_centroid_skewness_list = []\n",
    "spectral_centroid_kurtosis_list = []\n",
    "\n",
    "chroma_list = []\n",
    "zero_crossing_rate_list = []\n",
    "rms_list = []\n",
    "pitch_list = []\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for index, row in merged_data.iterrows():\n",
    "    file_path = os.path.join(row['path'], row['filename'])  # Construct the file path\n",
    "    \n",
    "    # Extract features directly from the file path\n",
    "    features = extract_features(file_path)\n",
    "    \n",
    "    # Extract MFCCs (mean, std, skewness, kurtosis)\n",
    "    mfccs_mean_list.append(features[0])  # MFCC mean\n",
    "    mfccs_std_list.append(features[1])   # MFCC std\n",
    "    mfccs_skewness_list.append(features[2])  # MFCC skewness\n",
    "    mfccs_kurtosis_list.append(features[3])  # MFCC kurtosis\n",
    "    \n",
    "    # Extract Spectral Centroid (mean, std, skewness, kurtosis)\n",
    "    spectral_centroid_list.append(features[4][0])  # Spectral centroid mean\n",
    "    spectral_centroid_std_list.append(features[4][1])  # Spectral centroid std\n",
    "    spectral_centroid_skewness_list.append(features[4][2])  # Spectral centroid skewness\n",
    "    spectral_centroid_kurtosis_list.append(features[4][3])  # Spectral centroid kurtosis\n",
    "\n",
    "    # Extract other features\n",
    "    chroma_list.append(features[5])  # Chroma feature\n",
    "    zero_crossing_rate_list.append(features[6])  # Zero-crossing rate\n",
    "    rms_list.append(features[7])  # RMS energy\n",
    "    pitch_list.append(features[8])  # Pitch\n",
    "\n",
    "# Add the features to the DataFrame\n",
    "merged_data['mfccs_mean'] = mfccs_mean_list\n",
    "merged_data['mfccs_std'] = mfccs_std_list\n",
    "merged_data['mfccs_skewness'] = mfccs_skewness_list\n",
    "merged_data['mfccs_kurtosis'] = mfccs_kurtosis_list\n",
    "\n",
    "merged_data['spectral_centroid'] = spectral_centroid_list\n",
    "merged_data['spectral_centroid_std'] = spectral_centroid_std_list\n",
    "merged_data['spectral_centroid_skewness'] = spectral_centroid_skewness_list\n",
    "merged_data['spectral_centroid_kurtosis'] = spectral_centroid_kurtosis_list\n",
    "\n",
    "merged_data['chroma'] = chroma_list\n",
    "merged_data['zero_crossing_rate'] = zero_crossing_rate_list\n",
    "merged_data['rms'] = rms_list\n",
    "merged_data['pitch'] = pitch_list\n",
    "\n",
    "# Check for any NaN values in the DataFrame\n",
    "print(merged_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "813544ce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>filename</th>\n",
       "      <th>emotion</th>\n",
       "      <th>path</th>\n",
       "      <th>mfccs_mean</th>\n",
       "      <th>mfccs_std</th>\n",
       "      <th>mfccs_skewness</th>\n",
       "      <th>mfccs_kurtosis</th>\n",
       "      <th>spectral_centroid</th>\n",
       "      <th>spectral_centroid_std</th>\n",
       "      <th>spectral_centroid_skewness</th>\n",
       "      <th>spectral_centroid_kurtosis</th>\n",
       "      <th>chroma</th>\n",
       "      <th>zero_crossing_rate</th>\n",
       "      <th>rms</th>\n",
       "      <th>pitch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c_0001</td>\n",
       "      <td>1001_DFA_ANG_XX.wav</td>\n",
       "      <td>angry</td>\n",
       "      <td>dataset\\Crema</td>\n",
       "      <td>[-306.0274, 92.670235, 8.491312, 23.965403, 7....</td>\n",
       "      <td>[159.39034, 28.411352, 32.853794, 18.576996, 1...</td>\n",
       "      <td>[0.20764598536041903, -1.6664365561045553, -0....</td>\n",
       "      <td>[1.5308908609098486, 6.255967790558195, 2.0626...</td>\n",
       "      <td>1584.993070</td>\n",
       "      <td>600.410753</td>\n",
       "      <td>1.645968</td>\n",
       "      <td>5.914065</td>\n",
       "      <td>[0.37491405, 0.37949282, 0.41722107, 0.3901823...</td>\n",
       "      <td>[0.10186767578125]</td>\n",
       "      <td>[0.041986194]</td>\n",
       "      <td>1211.950684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c_0002</td>\n",
       "      <td>1001_DFA_DIS_XX.wav</td>\n",
       "      <td>disgust</td>\n",
       "      <td>dataset\\Crema</td>\n",
       "      <td>[-346.39963, 95.83912, 10.516282, 31.619215, 1...</td>\n",
       "      <td>[119.25175, 25.675545, 28.204397, 14.32062, 12...</td>\n",
       "      <td>[0.429815467495218, -2.4152754162967365, -0.64...</td>\n",
       "      <td>[1.5432605835209392, 9.754570690624716, 2.0697...</td>\n",
       "      <td>1531.650487</td>\n",
       "      <td>590.708457</td>\n",
       "      <td>2.221739</td>\n",
       "      <td>8.718056</td>\n",
       "      <td>[0.47289878, 0.4768195, 0.33598945, 0.34610763...</td>\n",
       "      <td>[0.09306105522260275]</td>\n",
       "      <td>[0.015996357]</td>\n",
       "      <td>1256.617188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c_0003</td>\n",
       "      <td>1001_DFA_FEA_XX.wav</td>\n",
       "      <td>fear</td>\n",
       "      <td>dataset\\Crema</td>\n",
       "      <td>[-321.42026, 94.76091, 8.155397, 23.323242, 11...</td>\n",
       "      <td>[164.98051, 22.249113, 32.150303, 17.628511, 1...</td>\n",
       "      <td>[0.6107179404412114, -2.090810028400443, -0.84...</td>\n",
       "      <td>[1.5561389714635474, 8.554004454745545, 2.3571...</td>\n",
       "      <td>1489.088839</td>\n",
       "      <td>521.794373</td>\n",
       "      <td>2.785179</td>\n",
       "      <td>13.443495</td>\n",
       "      <td>[0.3272673, 0.39935032, 0.35215598, 0.38248017...</td>\n",
       "      <td>[0.08428596047794118]</td>\n",
       "      <td>[0.045776337]</td>\n",
       "      <td>992.574402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c_0004</td>\n",
       "      <td>1001_DFA_HAP_XX.wav</td>\n",
       "      <td>happy</td>\n",
       "      <td>dataset\\Crema</td>\n",
       "      <td>[-303.30374, 92.52889, 4.231231, 27.970133, 10...</td>\n",
       "      <td>[155.75238, 22.153809, 28.1528, 16.787258, 18....</td>\n",
       "      <td>[0.37104695571340607, -2.0804384199805708, -0....</td>\n",
       "      <td>[1.4136846749281942, 8.323046695071024, 2.7117...</td>\n",
       "      <td>1555.376035</td>\n",
       "      <td>476.260688</td>\n",
       "      <td>2.604170</td>\n",
       "      <td>11.342148</td>\n",
       "      <td>[0.3150873, 0.31478375, 0.30918238, 0.3423785,...</td>\n",
       "      <td>[0.0848781779661017]</td>\n",
       "      <td>[0.042300183]</td>\n",
       "      <td>1102.953003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c_0005</td>\n",
       "      <td>1001_DFA_NEU_XX.wav</td>\n",
       "      <td>neutral</td>\n",
       "      <td>dataset\\Crema</td>\n",
       "      <td>[-335.4959, 100.39331, 9.384935, 30.160904, 11...</td>\n",
       "      <td>[107.47099, 25.01471, 24.072784, 13.558439, 15...</td>\n",
       "      <td>[0.373707114329708, -1.1863656699536622, -0.30...</td>\n",
       "      <td>[1.723965808082716, 4.669149222064396, 1.75616...</td>\n",
       "      <td>1495.394997</td>\n",
       "      <td>492.130906</td>\n",
       "      <td>1.597144</td>\n",
       "      <td>6.070896</td>\n",
       "      <td>[0.4112704, 0.36269408, 0.3349767, 0.32547352,...</td>\n",
       "      <td>[0.08203125]</td>\n",
       "      <td>[0.020449637]</td>\n",
       "      <td>1041.093628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id             filename  emotion           path  \\\n",
       "0  c_0001  1001_DFA_ANG_XX.wav    angry  dataset\\Crema   \n",
       "1  c_0002  1001_DFA_DIS_XX.wav  disgust  dataset\\Crema   \n",
       "2  c_0003  1001_DFA_FEA_XX.wav     fear  dataset\\Crema   \n",
       "3  c_0004  1001_DFA_HAP_XX.wav    happy  dataset\\Crema   \n",
       "4  c_0005  1001_DFA_NEU_XX.wav  neutral  dataset\\Crema   \n",
       "\n",
       "                                          mfccs_mean  \\\n",
       "0  [-306.0274, 92.670235, 8.491312, 23.965403, 7....   \n",
       "1  [-346.39963, 95.83912, 10.516282, 31.619215, 1...   \n",
       "2  [-321.42026, 94.76091, 8.155397, 23.323242, 11...   \n",
       "3  [-303.30374, 92.52889, 4.231231, 27.970133, 10...   \n",
       "4  [-335.4959, 100.39331, 9.384935, 30.160904, 11...   \n",
       "\n",
       "                                           mfccs_std  \\\n",
       "0  [159.39034, 28.411352, 32.853794, 18.576996, 1...   \n",
       "1  [119.25175, 25.675545, 28.204397, 14.32062, 12...   \n",
       "2  [164.98051, 22.249113, 32.150303, 17.628511, 1...   \n",
       "3  [155.75238, 22.153809, 28.1528, 16.787258, 18....   \n",
       "4  [107.47099, 25.01471, 24.072784, 13.558439, 15...   \n",
       "\n",
       "                                      mfccs_skewness  \\\n",
       "0  [0.20764598536041903, -1.6664365561045553, -0....   \n",
       "1  [0.429815467495218, -2.4152754162967365, -0.64...   \n",
       "2  [0.6107179404412114, -2.090810028400443, -0.84...   \n",
       "3  [0.37104695571340607, -2.0804384199805708, -0....   \n",
       "4  [0.373707114329708, -1.1863656699536622, -0.30...   \n",
       "\n",
       "                                      mfccs_kurtosis  spectral_centroid  \\\n",
       "0  [1.5308908609098486, 6.255967790558195, 2.0626...        1584.993070   \n",
       "1  [1.5432605835209392, 9.754570690624716, 2.0697...        1531.650487   \n",
       "2  [1.5561389714635474, 8.554004454745545, 2.3571...        1489.088839   \n",
       "3  [1.4136846749281942, 8.323046695071024, 2.7117...        1555.376035   \n",
       "4  [1.723965808082716, 4.669149222064396, 1.75616...        1495.394997   \n",
       "\n",
       "   spectral_centroid_std  spectral_centroid_skewness  \\\n",
       "0             600.410753                    1.645968   \n",
       "1             590.708457                    2.221739   \n",
       "2             521.794373                    2.785179   \n",
       "3             476.260688                    2.604170   \n",
       "4             492.130906                    1.597144   \n",
       "\n",
       "   spectral_centroid_kurtosis  \\\n",
       "0                    5.914065   \n",
       "1                    8.718056   \n",
       "2                   13.443495   \n",
       "3                   11.342148   \n",
       "4                    6.070896   \n",
       "\n",
       "                                              chroma     zero_crossing_rate  \\\n",
       "0  [0.37491405, 0.37949282, 0.41722107, 0.3901823...     [0.10186767578125]   \n",
       "1  [0.47289878, 0.4768195, 0.33598945, 0.34610763...  [0.09306105522260275]   \n",
       "2  [0.3272673, 0.39935032, 0.35215598, 0.38248017...  [0.08428596047794118]   \n",
       "3  [0.3150873, 0.31478375, 0.30918238, 0.3423785,...   [0.0848781779661017]   \n",
       "4  [0.4112704, 0.36269408, 0.3349767, 0.32547352,...           [0.08203125]   \n",
       "\n",
       "             rms        pitch  \n",
       "0  [0.041986194]  1211.950684  \n",
       "1  [0.015996357]  1256.617188  \n",
       "2  [0.045776337]   992.574402  \n",
       "3  [0.042300183]  1102.953003  \n",
       "4  [0.020449637]  1041.093628  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data['pitch'] = merged_data['pitch'].fillna(0)\n",
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91917164",
   "metadata": {},
   "source": [
    "We won't be able to work with arrays - we will need to extract a meaningful metric and save them in a new column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7771f3b5",
   "metadata": {},
   "source": [
    "### Cleaning the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "70901a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mfccs_mean  mfccs_std  mfccs_skewness  mfccs_kurtosis  \\\n",
      "0  -17.963037  26.372070       -0.515480        3.329990   \n",
      "1  -18.657297  21.019888       -0.498601        3.982956   \n",
      "2  -18.552622  25.241508       -0.602645        4.156697   \n",
      "3  -18.460817  24.993519       -0.653859        3.327673   \n",
      "4  -18.111607  20.893410       -0.480883        3.167808   \n",
      "\n",
      "   spectral_centroid_mean  spectral_centroid_std  spectral_centroid_skewness  \\\n",
      "0             1584.993070             600.410753                    1.645968   \n",
      "1             1531.650487             590.708457                    2.221739   \n",
      "2             1489.088839             521.794373                    2.785179   \n",
      "3             1555.376035             476.260688                    2.604170   \n",
      "4             1495.394997             492.130906                    1.597144   \n",
      "\n",
      "   spectral_centroid_kurtosis    chroma  zero_crossing_rate       rms  \\\n",
      "0                    5.914065  0.411293            0.101868  0.041986   \n",
      "1                    8.718056  0.423961            0.093061  0.015996   \n",
      "2                   13.443495  0.413398            0.084286  0.045776   \n",
      "3                   11.342148  0.394820            0.084878  0.042300   \n",
      "4                    6.070896  0.401279            0.082031  0.020450   \n",
      "\n",
      "         pitch           path             filename  emotion  \n",
      "0  1211.950684  dataset\\Crema  1001_DFA_ANG_XX.wav    angry  \n",
      "1  1256.617188  dataset\\Crema  1001_DFA_DIS_XX.wav  disgust  \n",
      "2   992.574402  dataset\\Crema  1001_DFA_FEA_XX.wav     fear  \n",
      "3  1102.953003  dataset\\Crema  1001_DFA_HAP_XX.wav    happy  \n",
      "4  1041.093628  dataset\\Crema  1001_DFA_NEU_XX.wav  neutral  \n"
     ]
    }
   ],
   "source": [
    "# Create a new DataFrame for the cleaned features\n",
    "clean_data = pd.DataFrame()\n",
    "\n",
    "# Store the mean of MFCC components\n",
    "clean_data['mfccs_mean'] = merged_data['mfccs_mean'].apply(lambda x: np.mean(x) if isinstance(x, (list, np.ndarray)) and len(x) > 0 else np.nan)\n",
    "clean_data['mfccs_std'] = merged_data['mfccs_std'].apply(lambda x: np.mean(x) if isinstance(x, (list, np.ndarray)) and len(x) > 0 else np.nan)\n",
    "clean_data['mfccs_skewness'] = merged_data['mfccs_skewness'].apply(lambda x: np.mean(x) if isinstance(x, (list, np.ndarray)) and len(x) > 0 else np.nan)\n",
    "clean_data['mfccs_kurtosis'] = merged_data['mfccs_kurtosis'].apply(lambda x: np.mean(x) if isinstance(x, (list, np.ndarray)) and len(x) > 0 else np.nan)\n",
    "\n",
    "# Store the statistics for Spectral Centroid\n",
    "clean_data['spectral_centroid_mean'] = merged_data['spectral_centroid'].apply(lambda x: x if isinstance(x, (float, int)) else np.nan)\n",
    "clean_data['spectral_centroid_std'] = merged_data['spectral_centroid_std'].apply(lambda x: x if isinstance(x, (float, int)) else np.nan)\n",
    "clean_data['spectral_centroid_skewness'] = merged_data['spectral_centroid_skewness'].apply(lambda x: x if isinstance(x, (float, int)) else np.nan)\n",
    "clean_data['spectral_centroid_kurtosis'] = merged_data['spectral_centroid_kurtosis'].apply(lambda x: x if isinstance(x, (float, int)) else np.nan)\n",
    "\n",
    "# Store the mean of Chroma features\n",
    "clean_data['chroma'] = merged_data['chroma'].apply(lambda x: np.mean(x) if isinstance(x, (list, np.ndarray)) and len(x) > 0 else np.nan)\n",
    "\n",
    "# Store Zero-Crossing Rate and RMS (first element of the list)\n",
    "clean_data['zero_crossing_rate'] = merged_data['zero_crossing_rate'].apply(lambda x: x[0] if isinstance(x, (list, np.ndarray)) and len(x) > 0 else np.nan)\n",
    "clean_data['rms'] = merged_data['rms'].apply(lambda x: x[0] if isinstance(x, (list, np.ndarray)) and len(x) > 0 else np.nan)\n",
    "\n",
    "# Directly store the existing pitch and other metadata\n",
    "clean_data['pitch'] = merged_data['pitch']  # Directly store the existing value\n",
    "clean_data['path'] = merged_data['path']\n",
    "clean_data['filename'] = merged_data['filename']\n",
    "\n",
    "# Add the emotion column\n",
    "clean_data['emotion'] = merged_data['emotion']\n",
    "\n",
    "# Display the new DataFrame\n",
    "print(clean_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1e24caa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mfccs_mean                    0\n",
      "mfccs_std                     0\n",
      "mfccs_skewness                0\n",
      "mfccs_kurtosis                0\n",
      "spectral_centroid_mean        0\n",
      "spectral_centroid_std         0\n",
      "spectral_centroid_skewness    0\n",
      "spectral_centroid_kurtosis    0\n",
      "chroma                        0\n",
      "zero_crossing_rate            0\n",
      "rms                           0\n",
      "pitch                         0\n",
      "path                          0\n",
      "filename                      0\n",
      "emotion                       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for any NaN values in the DataFrame\n",
    "print(clean_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c53dfd7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# distribution of emotions\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=clean_data, x='emotion', order=clean_data['emotion'].value_counts().index)\n",
    "plt.title('Distribution of Emotions')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# this chart shows some a significant imbalance in the dataset. lets do some resampling\n",
    "# Lets try using the SMOTE technique (Synthetic Minority Over-sampling):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "42042637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['angry' 'disgust' 'fear' 'happy' 'neutral' 'sad' 'pleasant' 'unknown'\n",
      " 'surprise' 'calm']\n"
     ]
    }
   ],
   "source": [
    "# Lets combine columns that should be the same, such as 'Sad', 'sad', and 'sadness':\n",
    "\n",
    "clean_data['emotion'] = clean_data['emotion'].str.lower()  # Convert to lowercase\n",
    "\n",
    "# Replace specific values\n",
    "clean_data['emotion'] = clean_data['emotion'].replace({\n",
    "    'surprised': 'surprise',  # Change 'surprised' to 'surprise'\n",
    "    'sadness': 'sad',          # Combine 'sadness', 'sad', 'Sad' to 'sad'\n",
    "    'sad': 'sad',\n",
    "    'sadness': 'sad',\n",
    "    'pleasant': 'pleasant',\n",
    "    'fear': 'fear',\n",
    "    'fearful': 'fear',\n",
    "})\n",
    "\n",
    "# Check unique values after standardization\n",
    "unique_emotions = clean_data['emotion'].unique()\n",
    "print(unique_emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4cbb29b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmoAAAGgCAYAAAAaSUswAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAAsTAAALEwEAmpwYAAA3eklEQVR4nO3de7y19Zz/8de7ckgHUremo5JCQnTLmUg6SNGgQieHGGWcTWFonMZoMr8wzGSkAypnIUMOwxyc7kxUDiMJd1IROiAdPr8/vt9dy3bfte/73nuva+1ez8djPfZa17rWWt9rr73Xel/fY6oKSZIkDc9q4y6AJEmSls2gJkmSNFAGNUmSpIEyqEmSJA2UQU2SJGmgDGqSJEkDZVCTtMKS/EuSv52l59o8yVVJVu+3/yPJs2fjufvzfSbJQbP1fCvwum9I8sskv5jv174l/fd9t3GXQ9ItM6hJ+hNJLkzy+yRXJvlNkv9J8rwkN35eVNXzqur1M3yux97cPlX106pau6qun4WyH5XkfdOef/eqOnFVn3sFy7E58FJg26r6i2Xcv1OSG3pgGr08ZA7K8mfBt/++L5jt15I0+9YYdwEkDdITqurzSe4IPAo4FngQcMhsvkiSNarqutl8zoHYHPhVVV16M/v8vKo2na8CSZpM1qhJWq6q+m1VnQ7sCxyUZDuAJCckeUO/vkGST/Xat8uT/GeS1ZKcTAssn+y1Ra9IskWSSvKsJD8FvjiybfTEcask30hyRZJPJLlzf62dkiwdLeNUrV2S3YBXAvv21/t2v//GGqVerlcn+UmSS5Oc1MMoI+U4KMlPe7Plq5b3u0lyx/74y/rzvbo//2OBM4GNezlOWNHfey/zG3pt5lVJPplk/STv77+TbybZYmT/h/Ztv+0/H9q3vxF4BPCO/jzv6Nsryd1v7jj6fQcn+a8k/5jk10l+nGT3kdc9OMkFvfb1x0mevqLHKunmGdQk3aKq+gawlPalP91L+32LgA1pYamq6gDgp7TaubWr6i0jj3kUcC9g1+W85IHAM4GNgOuAt82gjP8OvAk4rb/e/Zax28H98mjgbsDawDum7fNw4B7AzsBrktxrOS/5duCO/Xke1ct8SFV9HtidVmO2dlUdfEtlX479gAOATYCtgK8C7wXuDHwPeC1AD7Gfpv2O1gfeCnw6yfpV9SrgP4HDe1kOn+lxjNz/IOAHwAbAW4D3pFmrv+buVbUO8FDg7JU8VknLYVCTNFM/p4WE6a6lBaq7VtW1VfWfdcuLCB9VVVdX1e+Xc//JVXVuVV0N/C3w1PTBBqvo6cBbq+qCqroKOBLYb1pt3t9V1e+r6tvAt4E/C3y9LPsBR1bVlVV1IXAMLVjN1Ma9FnL0stbI/e+tqh9V1W+BzwA/qqrP96biDwH37/s9HvhhVZ1cVddV1SnA94En3FIBZngcP6mqd/c+hCfS3usN+303ANslWbOqLq6q81bg+CXNgEFN0kxtAly+jO1HA+cDn+vNYEfM4Ll+tgL3/wS4Da1GZ1Vt3J9v9LnX4KbgATA6SvN3tFq36TboZZr+XJusQFl+XlV3mna5euT+S0au/34Zt6fKNf2YVqQsMzmOG38fVfW7fnXtXtZ9gecBFyf5dJJ7zuA1Ja0Ag5qkW5TkgbQv7/+afl+viXlpVd0N2At4SZKdp+5ezlPeUo3bZiPXN6fV2v0SuBq4w0i5Vqc1uc70eX8O3HXac1/Hn4agmfhlL9P057poBZ9nNkw/pullubnfySodR1V9tqp2odWyfR9490weJ2nmDGqSlivJukn2BE4F3ldV5yxjnz2T3D1JgN8C19OaxKAFoJWZr+sZSbZNcgfgdcCHe9Pb/wG3T/L4JLcBXg3cbuRxlwBbZGQqkWlOAV6cZMska3NTn7YVGnnay/JB4I1J1klyV+AlwPtu/pFz4gxgmyRPS7JGkn2BbYFP9fuX+x6synEk2TDJ3r259hrgKm563yXNEoOapGX5ZJIraU2Qr6J1UF/e1BxbA5+nfVF/FXhnVX2p3/f3wKt7/6uXrcDrnwycQGt2uz3w19BGoQLPB/6NVutzNW0gw5QP9Z+/SvKtZTzv8f25vwL8GPgD8IIVKNeoF/TXv4BW0/iB/vwzNTUqdPTylytaiKr6FbAnbVDHr4BXAHtW1S/7LscCT+6jNpc1KGNlj2M1Wqj7Oa1J/FHAX61o+SXdvNxyn19JkiSNgzVqkiRJA2VQkyRJGiiDmiRJ0kAZ1CRJkgZqzhZlT7IZcBJtIskCjquqY/tyJ6cBWwAXAk+tql/3of3HAnvQJpk8uKq+1Z/rINowfIA3VNWJt/T6G2ywQW2xxRazekySJElz4ayzzvplVS2avn3ORn0m2QjYqKq+lWQd4CzgibR19i6vqjf3GczXq6q/SbIHbZj4HrS15Y6tqgf1YLcEWEwLfGcBO1TVr2/u9RcvXlxLliyZk2OTJEmaTUnOqqrF07fPWdNnX/ftW/36lbRFhDcB9qatF0f/+cR+fW/gpGq+Btyph71dgTOr6vIezs4EdpurckuSJA3FvPRRS7IFbQHhrwMbVtXF/a5fcNMae5vwp+v7Le3blrddkiRpQZvzoNaXafkI8KKqumL0vmrtrrPW9prk0CRLkiy57LLLZutpJUmSxmJOg1pfi+8jwPur6qN98yW9SXOqH9ulfftF/OlCzJv2bcvb/meq6riqWlxVixct+rP+eJIkSRNlzoJaH8X5HuB7VfXWkbtOBw7q1w8CPjGy/cA0DwZ+25tIPws8Lsl6SdYDHte3SZIkLWhzNj0H8DDgAOCcJGf3ba8E3gx8MMmzgJ8AT+33nUEb8Xk+bXqOQwCq6vIkrwe+2fd7XVVdPoflliRJGoQFuyi703NIkqRJMe/Tc0iSJGnVGNQkSZIGyqAmSZI0UAY1SZKkgTKoSZIkDZRBTZIkaaAMapIkSQM1lxPeDs4OLz9p3EVYYWcdfeC4iyBJksbEGjVJkqSBMqhJkiQNlEFNkiRpoAxqkiRJA2VQkyRJGiiDmiRJ0kAZ1CRJkgbKoCZJkjRQBjVJkqSBulWtTLDQLfSVFybt+FZ0VYmFfHyTdmzgqiCShsEaNUmSpIEyqEmSJA2UQU2SJGmgDGqSJEkDZVCTJEkaKIOaJEnSQBnUJEmSBsqgJkmSNFAGNUmSpIEyqEmSJA2UQU2SJGmgDGqSJEkDZVCTJEkaKIOaJEnSQM1ZUEtyfJJLk5w7su20JGf3y4VJzu7bt0jy+5H7/mXkMTskOSfJ+UneliRzVWZJkqQhWWMOn/sE4B3ASVMbqmrfqetJjgF+O7L/j6pq+2U8z7uA5wBfB84AdgM+M/vFlSRJGpY5q1Grqq8Aly/rvl4r9lTglJt7jiQbAetW1deqqmih74mzXFRJkqRBGlcftUcAl1TVD0e2bZnkf5N8Ockj+rZNgKUj+yzt25YpyaFJliRZctlll81+qSVJkubRuILa/vxpbdrFwOZVdX/gJcAHkqy7ok9aVcdV1eKqWrxo0aJZKqokSdJ4zGUftWVKsgawD7DD1Laquga4pl8/K8mPgG2Ai4BNRx6+ad8mSZK04I2jRu2xwPer6sYmzSSLkqzer98N2Bq4oKouBq5I8uDer+1A4BNjKLMkSdK8m8vpOU4BvgrcI8nSJM/qd+3Hnw8ieCTwnT5dx4eB51XV1ECE5wP/BpwP/AhHfEqSpFuJOWv6rKr9l7P94GVs+wjwkeXsvwTYblYLJ0mSNAFcmUCSJGmgDGqSJEkDZVCTJEkaKIOaJEnSQBnUJEmSBsqgJkmSNFAGNUmSpIEyqEmSJA2UQU2SJGmgDGqSJEkDZVCTJEkaKIOaJEnSQBnUJEmSBsqgJkmSNFAGNUmSpIEyqEmSJA2UQU2SJGmgDGqSJEkDZVCTJEkaKIOaJEnSQBnUJEmSBmqNcRdAkibdDi8/adxFWGFnHX3guIsgaQasUZMkSRoog5okSdJAGdQkSZIGyqAmSZI0UAY1SZKkgTKoSZIkDZRBTZIkaaAMapIkSQNlUJMkSRqoOQtqSY5PcmmSc0e2HZXkoiRn98seI/cdmeT8JD9IsuvI9t36tvOTHDFX5ZUkSRqauaxROwHYbRnb/6mqtu+XMwCSbAvsB9y7P+adSVZPsjrwz8DuwLbA/n1fSZKkBW/O1vqsqq8k2WKGu+8NnFpV1wA/TnI+sGO/7/yqugAgyal93+/OdnklSZKGZhx91A5P8p3eNLpe37YJ8LORfZb2bcvbvkxJDk2yJMmSyy67bLbLLUmSNK/mO6i9C9gK2B64GDhmNp+8qo6rqsVVtXjRokWz+dSSJEnzbs6aPpelqi6Zup7k3cCn+s2LgM1Gdt20b+NmtkuSJC1o81qjlmSjkZtPAqZGhJ4O7Jfkdkm2BLYGvgF8E9g6yZZJbksbcHD6fJZZkiRpXOasRi3JKcBOwAZJlgKvBXZKsj1QwIXAcwGq6rwkH6QNErgOOKyqru/PczjwWWB14PiqOm+uyixJkjQkcznqc/9lbH7Pzez/RuCNy9h+BnDGLBZNkiRpIrgygSRJ0kAZ1CRJkgbKoCZJkjRQBjVJkqSBMqhJkiQNlEFNkiRpoAxqkiRJA2VQkyRJGiiDmiRJ0kAZ1CRJkgbKoCZJkjRQBjVJkqSBMqhJkiQNlEFNkiRpoAxqkiRJA2VQkyRJGiiDmiRJ0kAZ1CRJkgbKoCZJkjRQBjVJkqSBMqhJkiQNlEFNkiRpoAxqkiRJA2VQkyRJGiiDmiRJ0kAZ1CRJkgbKoCZJkjRQBjVJkqSBMqhJkiQNlEFNkiRpoAxqkiRJAzVnQS3J8UkuTXLuyLajk3w/yXeSfCzJnfr2LZL8PsnZ/fIvI4/ZIck5Sc5P8rYkmasyS5IkDclc1qidAOw2bduZwHZVdV/g/4AjR+77UVVt3y/PG9n+LuA5wNb9Mv05JUmSFqQ5C2pV9RXg8mnbPldV1/WbXwM2vbnnSLIRsG5Vfa2qCjgJeOIcFFeSJGlwxtlH7ZnAZ0Zub5nkf5N8Ockj+rZNgKUj+yzt2yRJkha8NcbxokleBVwHvL9vuhjYvKp+lWQH4ONJ7r0Sz3socCjA5ptvPlvFlSRJGot5r1FLcjCwJ/D03pxJVV1TVb/q188CfgRsA1zEnzaPbtq3LVNVHVdVi6tq8aJFi+boCCRJkubHvAa1JLsBrwD2qqrfjWxflGT1fv1utEEDF1TVxcAVSR7cR3seCHxiPsssSZI0LnPW9JnkFGAnYIMkS4HX0kZ53g44s8+y8bU+wvORwOuSXAvcADyvqqYGIjyfNoJ0TVqfttF+bZIkSQvWnAW1qtp/GZvfs5x9PwJ8ZDn3LQG2m8WiSZIkTQRXJpAkSRoog5okSdJAGdQkSZIGyqAmSZI0UAY1SZKkgTKoSZIkDZRBTZIkaaAMapIkSQNlUJMkSRoog5okSdJAGdQkSZIGyqAmSZI0UAY1SZKkgTKoSZIkDZRBTZIkaaAMapIkSQNlUJMkSRoog5okSdJAGdQkSZIGyqAmSZI0UAY1SZKkgTKoSZIkDdSMglqSL8xkmyRJkmbPGjd3Z5LbA3cANkiyHpB+17rAJnNcNkmSpFu1mw1qwHOBFwEbA2dxU1C7AnjH3BVLkiRJNxvUqupY4NgkL6iqt89TmSRJksQt16gBUFVvT/JQYIvRx1TVSXNULkmSpFu9GQW1JCcDWwFnA9f3zQUY1CRJkubIjIIasBjYtqpqLgsjSZKkm8x0HrVzgb+Yy4JIkiTpT820Rm0D4LtJvgFcM7Wxqvaak1JJkiRpxkHtqLkshCRJkv7cjJo+q+rLy7rc0uOSHJ/k0iTnjmy7c5Izk/yw/1yvb0+StyU5P8l3kjxg5DEH9f1/mOSglTlQSZKkSTPTJaSuTHJFv/whyfVJrpjBQ08Adpu27QjgC1W1NfCFfhtgd2DrfjkUeFd/7TsDrwUeBOwIvHYq3EmSJC1kM61RW6eq1q2qdYE1gb8E3jmDx30FuHza5r2BE/v1E4Enjmw/qZqvAXdKshGwK3BmVV1eVb8GzuTPw58kSdKCM9NRnzfqQerjtAC1Mjasqov79V8AG/brmwA/G9lvad+2vO1/JsmhSZYkWXLZZZetZPEkSZKGYaYT3u4zcnM12rxqf1jVF6+qSjJrc7NV1XHAcQCLFy92zjdJkjTRZjrq8wkj168DLqQ1Va6MS5JsVFUX96bNS/v2i4DNRvbbtG+7CNhp2vb/WMnXliRJmhgzXevzkFl8zdOBg4A395+fGNl+eJJTaQMHftvD3GeBN40MIHgccOQslkeSJGmQZjrqc9MkH+tTbVya5CNJNp3B404BvgrcI8nSJM+iBbRdkvwQeGy/DXAGcAFwPvBu4PkAVXU58Hrgm/3yur5NkiRpQZtp0+d7gQ8AT+m3n9G37XJzD6qq/Zdz187L2LeAw5bzPMcDx8+wrJIkSQvCTEd9Lqqq91bVdf1yArBoDsslSZJ0qzfToParJM9Isnq/PAP41VwWTJIk6dZupkHtmcBTafOeXQw8GTh4jsokSZIkZt5H7XXAQX1lgKllnf6RFuAkSZI0B2Zao3bfqZAGN47EvP/cFEmSJEkw86C22uhC6L1Gbaa1cZIkSVoJMw1bxwBfTfKhfvspwBvnpkiSJEmCma9McFKSJcBj+qZ9quq7c1csSZIkzbj5sgczw5kkSdI8mWkfNUmSJM0zg5okSdJAGdQkSZIGyqAmSZI0UAY1SZKkgTKoSZIkDZRBTZIkaaAMapIkSQNlUJMkSRoog5okSdJAGdQkSZIGyqAmSZI0UAY1SZKkgTKoSZIkDZRBTZIkaaAMapIkSQNlUJMkSRoog5okSdJAGdQkSZIGyqAmSZI0UAY1SZKkgTKoSZIkDdS8B7Uk90hy9sjliiQvSnJUkotGtu8x8pgjk5yf5AdJdp3vMkuSJI3DGvP9glX1A2B7gCSrAxcBHwMOAf6pqv5xdP8k2wL7AfcGNgY+n2Sbqrp+PsstSZI038bd9Lkz8KOq+snN7LM3cGpVXVNVPwbOB3acl9JJkiSN0biD2n7AKSO3D0/ynSTHJ1mvb9sE+NnIPkv7tj+T5NAkS5Isueyyy+amxJIkSfNkbEEtyW2BvYAP9U3vAraiNYteDByzos9ZVcdV1eKqWrxo0aLZKqokSdJYjLNGbXfgW1V1CUBVXVJV11fVDcC7ual58yJgs5HHbdq3SZIkLWjjDGr7M9LsmWSjkfueBJzbr58O7Jfkdkm2BLYGvjFvpZQkSRqTeR/1CZBkLWAX4Lkjm9+SZHuggAun7quq85J8EPgucB1wmCM+JUnSrcFYglpVXQ2sP23bATez/xuBN851uSRJkoZk3KM+JUmStBwGNUmSpIEyqEmSJA2UQU2SJGmgDGqSJEkDZVCTJEkaKIOaJEnSQBnUJEmSBsqgJkmSNFAGNUmSpIEyqEmSJA2UQU2SJGmgDGqSJEkDZVCTJEkaKIOaJEnSQBnUJEmSBsqgJkmSNFAGNUmSpIEyqEmSJA2UQU2SJGmgDGqSJEkDZVCTJEkaKIOaJEnSQBnUJEmSBsqgJkmSNFAGNUmSpIEyqEmSJA2UQU2SJGmgDGqSJEkDZVCTJEkaKIOaJEnSQBnUJEmSBmpsQS3JhUnOSXJ2kiV9252TnJnkh/3nen17krwtyflJvpPkAeMqtyRJ0nwZd43ao6tq+6pa3G8fAXyhqrYGvtBvA+wObN0vhwLvmveSSpIkzbNxB7Xp9gZO7NdPBJ44sv2kar4G3CnJRmMonyRJ0rwZZ1Ar4HNJzkpyaN+2YVVd3K//AtiwX98E+NnIY5f2bX8iyaFJliRZctlll81VuSVJkubFGmN87YdX1UVJ7gKcmeT7o3dWVSWpFXnCqjoOOA5g8eLFK/RYSZKkoRlbjVpVXdR/Xgp8DNgRuGSqSbP/vLTvfhGw2cjDN+3bJEmSFqyxBLUkayVZZ+o68DjgXOB04KC+20HAJ/r104ED++jPBwO/HWkilSRJWpDG1fS5IfCxJFNl+EBV/XuSbwIfTPIs4CfAU/v+ZwB7AOcDvwMOmf8iS5Ikza+xBLWqugC43zK2/wrYeRnbCzhsHoomSZI0GEObnkOSJEmdQU2SJGmgDGqSJEkDZVCTJEkaKIOaJEnSQBnUJEmSBsqgJkmSNFAGNUmSpIEyqEmSJA2UQU2SJGmgxrXWpyRpQuzw8pPGXYQVdtbRB467CNKssEZNkiRpoAxqkiRJA2VQkyRJGiiDmiRJ0kAZ1CRJkgbKUZ+SpFu1SRvV6ojWWxdr1CRJkgbKoCZJkjRQBjVJkqSBMqhJkiQNlEFNkiRpoAxqkiRJA2VQkyRJGiiDmiRJ0kAZ1CRJkgbKoCZJkjRQBjVJkqSBMqhJkiQNlEFNkiRpoAxqkiRJAzXvQS3JZkm+lOS7Sc5L8sK+/agkFyU5u1/2GHnMkUnOT/KDJLvOd5klSZLGYY0xvOZ1wEur6ltJ1gHOSnJmv++fquofR3dOsi2wH3BvYGPg80m2qarr57XUkiRJ82zea9Sq6uKq+la/fiXwPWCTm3nI3sCpVXVNVf0YOB/Yce5LKkmSNF7jqFG7UZItgPsDXwceBhye5EBgCa3W7de0EPe1kYctZTnBLsmhwKEAm2+++dwVXJKkCbHDy08adxFWyFlHHzjuIgzK2AYTJFkb+Ajwoqq6AngXsBWwPXAxcMyKPmdVHVdVi6tq8aJFi2azuJIkSfNuLEEtyW1oIe39VfVRgKq6pKqur6obgHdzU/PmRcBmIw/ftG+TJEla0MYx6jPAe4DvVdVbR7ZvNLLbk4Bz+/XTgf2S3C7JlsDWwDfmq7ySJEnjMo4+ag8DDgDOSXJ23/ZKYP8k2wMFXAg8F6CqzkvyQeC7tBGjhzniU5Ik3RrMe1Crqv8Csoy7zriZx7wReOOcFUqSJGmAXJlAkiRpoAxqkiRJA2VQkyRJGiiDmiRJ0kCNdWUCSZKklTVpqy7Aiq+8YI2aJEnSQBnUJEmSBsqgJkmSNFAGNUmSpIEyqEmSJA2UQU2SJGmgDGqSJEkDZVCTJEkaKIOaJEnSQBnUJEmSBsqgJkmSNFAGNUmSpIEyqEmSJA2UQU2SJGmgDGqSJEkDZVCTJEkaKIOaJEnSQBnUJEmSBsqgJkmSNFAGNUmSpIEyqEmSJA2UQU2SJGmgDGqSJEkDZVCTJEkaKIOaJEnSQBnUJEmSBmpiglqS3ZL8IMn5SY4Yd3kkSZLm2kQEtSSrA/8M7A5sC+yfZNvxlkqSJGluTURQA3YEzq+qC6rqj8CpwN5jLpMkSdKcmpSgtgnws5HbS/s2SZKkBStVNe4y3KIkTwZ2q6pn99sHAA+qqsOn7XcocGi/eQ/gB/NUxA2AX87Ta42DxzfZPL7JtZCPDTy+Sefxza67VtWi6RvXmMcCrIqLgM1Gbm/at/2JqjoOOG6+CjUlyZKqWjzfrztfPL7J5vFNroV8bODxTTqPb35MStPnN4Gtk2yZ5LbAfsDpYy6TJEnSnJqIGrWqui7J4cBngdWB46vqvDEXS5IkaU5NRFADqKozgDPGXY7lmPfm1nnm8U02j29yLeRjA49v0nl882AiBhNIkiTdGk1KHzVJkqRbHYOaJE2oJBn9KWnhMajNsiT+TjU4fqEvWNsBVFX53koLk6FiliR5aJIHVNUNt6awluQ24y7DXEly2yR36tfXG3NxVlqS1E2dUbcba2HmWZLNF+Lf6EgoOzXJh2DhhrW+1vPU9QX52brQT6Qm/bjGXf4F+Uc/JouBDya5360lrCXZBji4X1/95veeLP392wnYJclzgdOSrDveUq2cqZCW5EDa3+ja4/7gmQ9JNgReBkxsyF6ekeC9PbBVkpOmti+k97bPm/nsJHdOcj/gtQvp+ODPTqTWH2thZtnIe7XOcrYP3uj7k2TTcZRhwYeJuTYVyKrqbcD7gfckufetJKw9BNgLoKquH3NZZlVV3QBcAPw18HrgxKq6YrylWnlJHgMcBjyhqq6izUe40P0GuCfw3DGXY1aN1L6sUVXXAg8CdliIYa2q/khbwudS4EPA+2oBTVUwLQS8APhskjcl2X3MRZsV/W9xd+DDSd6Q5Kip7eMt2cyNvD+HAx9N8t4kO/STiHmx0IPEnOtf6FNv4l2APwInJbn/Qg1rSe4AUFUnAqv1Y18wRr7kfga8DzgLWKvXIE6E0S/qJGsAdwC2AA6EGyeRXhBf5tMl2SjJllV1DfACWo3T3cddrtkwrfblLknu2sPa/YH7L6SwNlL+02mr02wIXNXvWxDN2SMhYA9a4H4JcA2tJv8p4yzbbEjycODvgSOANYFHTn1/DN3od3f//NiVtirSr4BDgEfM19/hggsR45BkR+BFwBuApwHvBY5Pst1CC2s9rPx1kkP6pnfTQsCCMPVFmORxwFtptaQvBx4G7JPkjknum+SBYy3ozZh2ln5H4HZV9Snah8sDkvwVLIwv8+mSbAAcSavZfjptUu/f077kJ6rJZVlG3teXAsfTmrJf0mueHgDcJ8nHRvedRCP/h3euqmur6iG0EHNeWl/ga5NsM5+1GnOlh4D3AUuq6su0z9QLgIf0v+FJtg6t+8EdgUcAh1TV75JsO95i3bKRSpj9aJ//P6yqC2ih81JgH+Cx8xHWFkyAmE/L6Ph5LfD1qroI+CnwHuCHwMeTbDv1hk+6JHsCb6Md2/OSvAZ4MPCsJA8da+FmSf9y2AV4J3BaVV1VVecCRwHb0s4Ov8K0PhdDMvJl/hLgBFp1/T59dY9/pp2tv3h030k28v+4AfBr4G9pYe1JtA/TpwBvTrJoUo93Wg3pocBeVbUbcC7wuiSvGWkGvUuSjSc5lPb/wz2BjyU5I8n2VfUe4NXAl5I8C/ggcI+xFnQV9RqnNYD/B7w0yTZV9XPasV0MbJdksJ810438L26cZE0gtJPdtwKPraqfJNkZeE4/iRykkePYH3gTcC/a99whVXVdVb2OVru7CzD3tWpV5WUFLvTVHPr1NfvPtWkfmK8aue9vgH8Dthx3mWfpuB8IfAJ4aL+9PrAv8Cra2cU/Abcb/f1M4oXWd+sdwJP67acCHwb+klZz+GjgQeMu5wyO46+ALwFrAacB1wMH9/v2Bj4A3Gnc5ZzF430C8N/Af9GaOzehNbVsArwZ+CiwQ993ov5Gp33m/AWwA7A58ELgI7SatF8Dfz/uss7iMe8AfL5/7ryhH+dj+n1Ppy3ts9u4y7mK7+VawD8A+/XbrwaWAPfstxcB6427zCt6bLR+y58Ctum3/wH4IrAR8Lj+XbnnuMu7nGPYErhNv74rcDLwwH77scDZtFrBqf03mJdyjfsXM6kXWgflk2mdzbcA7gb8L/AuWtXo2cDG4y7nLB3r2rRmlvOXc/8+wGeB9cdd1lU8zk16GHsKrQPzp4E39tBzDnCXafsP8gufdhZ7IK257yXAqbQzvz8CB/R91hp3OWfxeB9AC6XbAXsArwP+bvT96u/jseMu6yoe53N7eLkDbSTrJ4D79PuOB77OAgjfwMb9s/W0kW0vpZ0w7dJv33bc5VzFY9yBdiKxO/BJ4PZ9+xHAj6ZCzqRdgIf378Gpv8s1ga1pXYP+ox/r4/t9g/r8BDagnaQfRTthPxT4av8MXafvszOt1eyA+SybTZ8rIclzaF+EbweeRfti2Ij2ZXgxcHvaG/nzsRVylvSq+KuAfwSWJjl25L7bAlTVR4HraGccEynJX9BGdx4EfJxWQ/PCqnoVLbD9BviTZrPq/7njlGa00+ttqzmJ1rVhd+BvqupM4HO0JsB1qurqMRV5VqVNwfFXwNpVdW615t1P0EYk33Nk1+/TBhXcfgzFXGVJHkmrSdq/qn4HXAmcDzy1N3GvBTy5qn4zvlLOmmtpX5CbJ3kaQFUdQwsAh/d+a38cZwFXRZLFtKbN42ndKH5B6y5DVb2ZFhauHVsBV0CSTZMcM9LMfndarfbUILNTad1FTqTVpj2lqj49bVDMUPyW9hl5J+AFVXUcravIfeiDIKrqC7Tv/v+ez4IZ1GZgWv+QewJ3BR5Pq5b/Le0D84XAParqdVV1VFWdM5bCzqIkWwNnJTm2qr4LPB+4U5K3QBs6n2T1/mW5Pm105ESqql/QamW2p4W1/6uq85M8CfgM8NaqumyMRVyeteqmTq8vAo5JckqSuwFXAxcCOyZ5Pq2D8gOr6spxFXY2TOt79WvaqMCrk7wCoKrOojWv3L/vvwbwB+DIqvrDPBd3pYz230myHa3W8O60pneq6jral/z1tGb511fVz8ZQ1FU20h9oxz5IZ8Oqeiet68ijk+wLUFVvBF5UVZePr7SrJsntq2oJ7eTvYbSa368CWyfZDaCq/qmqfjzGYs5YVS0FTgLu2jvV/w/tpOEDtLD5L7Q+zVtW1R+n/v+GFNKm/v6q9fH8DK116J5JXlxV76OFsn2A3XpY+49qgwrmr4wD+n0N0rQRdM+nhdtP0mrNjq2q3ZJsDHyBVhPzxl4DNdGS7EU7g78QOAD4WFUdluRetBrEpVX14pH9157E406yPbBrVf1Dv70vrWb0q7R+Fg8B/lhVZwztLLC/R3tX1bOSPAN4JrAnrfboA1V1RB80cDfa5L1PWwgnEAB9wMd9aVMZ/ButyXMX2v/l+2hnws+rqv8YVxlXVq+p3gPYiha2N6I1Be5NqyX8YK8hndr/Dr2WbWIleTzwFlrfs0OAV1TV59JGl+8CfKqqPjDOMq6qJI+ineB/hfbl/3Ta98kvaTVqHwMO7CF88NLm8bsuydq0sHYH4IlV9Yc+cOeyJPenhbanV9W3xlrgZZj2/b5hVV3Sr+9M65/8var6f712cFvg5WNpjZjPdtZJvtD6h3wT2Kzf3hH4Lm3ExxNo/2R3GWcZZ/FY16L1J9i7314P+D9arRK0vkD3H3c5V+H4Rjv0Ppp2BvWykW0vo50FPoebOpYOrT/F+rT+SvekdSz/f7TVMQ6jnRXebtr+dxx3mWfx2B9Cqx18Hq3z9dG00X97AN8A/p2bOp6vMe7yruQxbgZ8m9YsNvWZc3faQIl3MdDO2Ct5rNv0z9Ytac1K5wA/pn3p0/8P7zPucq7EcWXa7Q1o0zf9M+1k//nAX468t1uPu8wremy0EP0+Wp+uj9IqK27b79upf28M/m+1f25+rn+WPLNvezRt9P+R/fadxlW+NdAt6sOMd6eNyvldkufROmpvShvNsi6tT9ql4yvlrPoD7YtwKUBV/TrJC4EPJfltVf3dWEu3iqqqkjyWVh3/7iTXAy9M8oqqegstuO0M/He16nCq/6cOyB9p/QJfSxtt+z3aMPKraFM3XJvktbSivw6Y2FUVRiW5D63G5c1VdVySE2jzTr2wqp6f5HbAI2n9Sr5YE1I7sQy/AM6jdSw/NMnfVWuK/yjt/X50ki/VhPY1nFY7vZRWu7QxreP2Q2i1wycnObCq3j2mYq6SqePrU4lsQ/vfPJE2gvXNtKB2zyQPr6qvja2gK6F/hj6M1kf736qtTLNP2hx+709bru7ntD6Vg+sSM60m7WBagH46rVZ3l1679vf982TX3i9ybE3u9lGbgar6PXAG7Z/rvbSmpEuAY2ijPnepqu+Mr4SzI8mWSdbq/3TnAe/LTbNIXwn8K/D43rF54oz0hdkBeDLwr0meU1VfAY4FnpjkE7TRZW+t1i9vkKr1M/sirTb3q7Qatc1pZ7UbpE3S+CTasjtDDJorZKRf2r1pTRAPSrJJtT4vh9KWUNqAFrK/DmyW5M7jKe2qSXIAcExVPY1Wg7YF7QsEWk3qhbQ+aRMd0pLskuTVVfW7qvo/Wq3SqdW6UFwMnELrAzyxepeEF9Jqax7Yr29TrdvIy2hNvb8cXwlXySNozYM3dnmpqifRJrf9AG2C2KGHtMW077Y9+2Vd2nu0d5IjqurfadNujbdf5LirHCflQuv78kDgzv3202mdz9ccd9lm6fh2pQ07PpnWwTW0KQ3Opn1JLKV1aH4L8LBxl3cVjnMn2hfdzrTm7F8Bf93vWx94NvDgcZdzhsdyV9pI2+/TzggfQZsz7VRa8+d24y7jLBzjVBPLpiPbHkP7Ijio/w62ow0e2LjfvyZtFOjYy78ixzhyex3gJ8Db++1taaHlvxjpfjHJF9pcW+fS+odObXsyrZP9y2g1+g9Y1u9nEi7983M1WtPZ0/q2tfrn5wkj+91m3GVdkWPqP9cd2faG/h1x12n77jDu8s7geP6K1mXp7rQ56z5OnxeNdsL7SQYy5ZSDCVZQ2lQIh9Dmhdm/2qz1E62PtHoi7csdWi3NbWkfmDvS+lb8gNbc+3Zgn5rnUS+zpVfJ372qXtNvb0/7AnxZVf3LOMu2snoN4Wm0Gfk/SPuCuENVTXRtxJTe0fyVtPfpl7Taw51ptdlr0s6I311Vn0yyWk3oSiB9lPVVVXVx2mz0ZwFfqqrnJlkLOBg4s1rt08Tqx/KvtPmqfkqbe+vxtBPEvWg1iGdXW/ZsYizrby9t6pTNgLf09/X2tNaZp1UbaT5R0laLeC6t28UJtD6i+9JGHh8wKd8LfSDWG4AnVFstYSPaCgqvpjVT70kbjDSI2k77qK242wM3AE+tqu+NuzCrqrfBfwS4pNqcYST5Pe3s9l3Aa6rqq0nuTetoedCk/DPCnzSzbEWrpfgjbdkrAKrq7CQfAI7q/e9OGVdZV1ZVnZXkL2kjj9erNrXBQglpU4s6P4k26eljaRMTHwH8jt6sVFWfhJvW55skvVl3a1rXio8n+WxVXdID+IVJblNVz6R1Qp94VXV1n8rheFpfvJ/SpsU5njbP1lSz1KBGWd+cXtapaXL2oNWe/RdtTr9XAnsk+Qpt8M/taKN5J0ramtZHAK8AHkqbXmQrWvPt+rR1Zx9ekzEFzsa0Zvaf9P+vi5N8mtbVYHPgsKGENLCP2gqrNgz+hAUS0u5Oa2Z5JG1yySPgxnmoPk6bo2r9vvtS2ozS3x5DUVdKP8OdWjPwncBWVXUqcEOSM5P8Rdri67elhdB7j7O8q6K/LzvR+mhNtCSrj9ycWqpsG9o6lq+l9RE9mlbj9H7a/EZPmfa4QRvpc0c1/0cbFPE44DFJNqrWD/Ed/faGo4+ZJCN9Q7dP8tC06UT2pdX+vrmqXkbrlL46rY8QMFn9KkfC5bNprQ6Ppf19/o5We7gdLWi/EHh+Tdhchr3G6Xm0E/r/qap/pM0M8Bhac+GraC1MkxDSoJ20PzLJPaoPGKO1Gn2Wtibp2WMr2TJYo7YSJukDZHmSPIFW9fsT2h/os4ATktxQVW+pqq8n+V5VXQEwSc1oaZNK/qGqbuidRY+m1YD+AKDa3HfH0BYK3pbWpHQ/4L6T3HQ26c3waSsmXFlV1yd5NK0J7Dxax/Ln0obNfzvJk2kBbtOq+mgPAl+tNghmIox8sR9Oq5VYm9Z0HdoSZpuljTbfhtZn8pJxlXVV9ZOlvWhNm0uANZOcUFXvgBvnLnwlcNQkfc5M1wdZPRzYqap+luQntLD24Kp6cdrqJ3+scXdMX0FpI+QfTVsZ4plJ9q2q06rNLflMWveYC6vqh2Mt6Ir5b1qt4MFJ/pu2GsELaWHz9+Ms2LIY1G6FkjwYeA1tDpxdaFXXv6cFlg8nWb2q/n4qpE2Sfub3+CQfrraczla0Dti/SfJS2lxba9E+UKtf3xF4ObDvpIa0SddHF386ydto84f9M22ewofTwtpDgIvSJoO9F/CskeD9kfGUetUk+Sta39BDaZ2Xj6iqFyUpWg3MA2lzOE1cX6ZRaVOqvIhWW7g3cCRwVdrqCx+jrXv5t1V1+iQ1d47qofrptBO/xUmWVtWb+nt5QZJtJ7FvYZL70mqxn007qb+GVoO9OXAmbdLptyz/GYapqq5I8k7a3+PzaV1FnlVV54+3ZMvmYIJboSSb0mY7X49Wq/Y0WvX8z2nL8fymRmY+nxRJ1gf2o01X8SNajcwFtH4ia9OmVvkU7ZhPrqrPJ1mPNnrwC7VAZu2fVGnLdR0BXE4LLd9OW+txC1qfkkfQ3tdTqupDYyvoShrpLzn187W0QHoQrQlpH1r/19Wq6pred2Yi1ny8Ob2LxdrAnWlrBj+TFk63o02D8/G+38SEtKna3379QNqglo/RQujVwMerLRVF2uogn560oJZkE9pn5WZV9di+bWPagI+X0CYlflNVfbmf3E9Mjfao3LRm9WDXj7WP2q1QVS2tqm8CjwLe388iTqSdDX6tqs6ctP4wvbx70M7w7k8bGXgAsElVPYY2U/27aOH0gcCl0CbzpU2DYEgbs6r6GG3U1YNptS/Q+jH9hBbeTgOeXVUfmsS/z5EQsnXa+qN3o83Z90DaKiDX0Jt400aXT+RkvSN90u6RNrfdb3qfn/vQJkc9mzbX3c9o3S6AyelSkmRL4OjeuR5aP98rqk14/hbaZ8yTkjwEbly7c9JC2pZVdRHwZeD6JAf0E4ef0/5mj6at3rIOwKSGNGgBbcghDWz6vLU7B3huH4G1D20+sZ/B5HxoTunlPTnJXWgj6M6h9e95WpLTgbPTRhCeSFvY+TtTX56T/CGz0PSThEOAN/bmo1OSnEqrKf3WVP+eSfr7HA1pvU/aC2k11z+mTQNwarU1Ew+mNcPsPalN8CO1hXvSQvcXgG2SvBy4iDZr/W1oc1g9ryZzUNbtaf0mD0obIV+0AUlUGz14FDfNcP+/E9TBHmi1hcDbkyypqqP6ScOOwLW9S8kvk3yKVov42CRfrgkbHDFpbPq8FUuyLm3ag72A46vq02Mu0ipJsiutU/JqwGW0s/ZtaF+In+8/N6uqJZPUzHJrlDbFweuBt1XVieMuz2zoHer3BP6BVmO4Lm26hp1oE73eH3hODXhFjOUZHYSTNhXOqbRjPZQ2AvJJVXV5HwjycOAzVTVRI5SnBe570k5u70Jrlr+INp3RurSa0Ctpc+JNxCCQace2Ou1v8ZXAN6rqzf3k6WG0Sd4/0MP4XWiDI34zrnLfWhjURJI1+hn9xIaX/qHxUeDQqvpuksNo/fAuoy1WfiFt0knP/CZEDzZvpn3R/2JSa5ngxv4+XwU+X1XPTJu/8C9pk6GuS1vC7JqawFGP/dgOBN5TVZemTdz7TNrIulfRJkI9P8kj+rZUG9k7MZ8304LMbaqtpbsRLYg+kdb/7gTa6i3r0ia0vWhMxV0pSR5KC5ff6WFtO9rJ0plV9fYkzwH+p6rOG2tBb4XsoyaA62GympOW4VpaU/4G/fZxtGVBnkAbPfghQ9pkqarTgUdV1c8nOaQB9C/tF9FGzO3X+6OdSjuRWI1WMzFxIa27gdY/9LA+OOentKkPjqM1456fZGfa6MGNproaTMrnzbSQ9hLg1CTH05o7j6H1ozyDVtP0BNr0HBMR0kb6E25JG/V/epL79ffoe7TBVy9M8pKqerchbTwMapqYD8yb0wcFfBDYKcl21UbLfZQ24eRpVfWdsRZQK6WqLht3GWZLVX0UeA7wyh7WbqDVwrxpUpuPem38xbQuFPejLeu1Li3AfB54aR/N+0+0QTsTEWBGjYS0R9JO/I6lDXD5FO1k8F206R2em7ZE1MToTZh70Van+Vva+3ZK/wz9I60l4hO0mlCNiU2fWjD6tCPPo3V8/SZtGazDqurzYy2YNCLJ7rTaphdX1YfHXZ5VleRRtNF/69GaAk8FPkercXoxrf/W16rqM5PU3Dkqyd60UeRfqaq39W1H0ga57EOrGb1tDWjZoZlIW+v4BNpEr9/r206mLaP0FVoT9v5V9ZVxlVEGNS0wfcTSQ2j9K86qqi+PuUjSn0myC/CjmqB1c0eNjO58KPAe2gz8F9NOktYEPkDrs3bl9MeMpcCrIG11kwNoU/98j7aCwqX9vtfT+lA+oqombjqVJPcC/obWf3JD2lyFF9NGsn4a+GVVfXF8JRQY1CRJK6HPI/YPtNUTvpY2se3jaQus353WXPa3NWGT9o6E0NWqLUP3TOCuwG1ofe8+A5xYfcWIJOtX1a/GWOSVlmRtWt+0p9EmI/4+LaxdUVWnjLFoGmEfNUnSyrgj8EjaqgrQ+m39GPgFrUnwg5MW0uBP+uxu1X+eSJuY90ralD870wZO3KXvP5EhDaCqrqq25upOvQ/lWsAL6BOCaxgMapKkFVZtmbl9aCsp7N9D2W+BXYGrq+pbYy3gKkhfyzLJAX0E5AdpAXQz2tqz29NHyy8Q1yfZAXgH8Kqq+sK4C6Sb2PQpSVppSZ4AvJ82gOAG4H19apWJ1o/r74Cjp5oBk5wJfJE+Z9w4yzfbkqwF3KWqfjyp/QkXKpeQkiSttKr6ZJJnAK+jrR18+tT8XJP8Zd+P63rgzUnWBH7T7zpxoYU0gKq6mtZ0PdHv20JkUJMkrZIezv4AHJ/kR72/08SrqjOSXE2rWfsd8LJqC5NL88amT0nSrJj0aUeWJ8kdaBVNvx93WXTrY1CTJEkaKEd9SpIkDZRBTZIkaaAMapIkSQNlUJMkSRoog5okSdJAGdQkaQUl2T7JHiO390pyxDjLJGlhcnoOSVpBSQ4GFlfV4eMui6SFzRo1SQtekmck+UaSs5P8a5LVk1yV5Ogk5yX5fJIdk/xHkguS7NUfd/sk701yTpL/TfLoJLelLZe0b3++fZMcnOQd/TFbJPliku8k+UJf4JskJyR5W5L/6a/x5PH9RiRNCoOapAUtyb2AfYGHVdX2wPXA04G1gC9W1b2BK4E3ALsAT6IFMYDDaDPS3wfYHziR9rn5GuC0qtq+qk6b9pJvp60HeV/aYuVvG7lvI+DhwJ7Am2f5UCUtQK71KWmh2xnYAfhmXyt8TeBS4I/Av/d9zgGuqaprk5wDbNG3P5wWvKiq7yf5CbDNLbzeQ4B9+vWTgbeM3PfxqroB+G6SDVfloCTdOhjUJC10odVwHfknG5OX1U2ddG8ArgGoqhuSzNVn4zXTyiVJN8umT0kL3ReAJye5C0CSOye56wwf+5+0ZlKSbANsDvyA1lS6znIe8z/Afv360/tzSNJKMahJWtCq6rvAq4HPJfkOcCatr9hMvBNYrTeHngYcXFXXAF8Ctp0aTDDtMS8ADumvdQDwwtk4Dkm3Tk7PIUmSNFDWqEmSJA2UQU2SJGmgDGqSJEkDZVCTJEkaKIOaJEnSQBnUJEmSBsqgJkmSNFD/H/a60qFp9iLsAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=clean_data, x='emotion', order=clean_data['emotion'].value_counts().index)\n",
    "plt.title('Distribution of Emotions')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# this chart shows some a significant imbalance in the dataset.\n",
    "# lets reduce the higher classes like sad, angry, dusgust and so on to 1500, \n",
    "# then use augmented audio for underrepresented classes, bringing them also to 1500. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5245298",
   "metadata": {},
   "source": [
    "## Harmonizing sample sizes for target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "334a17c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: Counter({'sad': 1544, 'fear': 1502, 'angry': 1498, 'happy': 1495, 'disgust': 1457, 'neutral': 1254, 'pleasant': 331, 'unknown': 281, 'surprise': 214, 'calm': 153})\n",
      "mfccs_mean                    float32\n",
      "mfccs_std                     float32\n",
      "mfccs_skewness                float64\n",
      "mfccs_kurtosis                float64\n",
      "spectral_centroid_mean        float64\n",
      "spectral_centroid_std         float64\n",
      "spectral_centroid_skewness    float64\n",
      "spectral_centroid_kurtosis    float64\n",
      "chroma                        float64\n",
      "zero_crossing_rate            float64\n",
      "rms                           float64\n",
      "pitch                         float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "eval_clean_data = clean_data.copy()\n",
    "\n",
    "# Prepare the data\n",
    "X = eval_clean_data.drop(columns=['emotion', 'filename', 'path'])\n",
    "y = eval_clean_data['emotion']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Verify the original distribution of the training data\n",
    "print(\"Original dataset shape:\", Counter(y_train))\n",
    "\n",
    "# Convert columns with object type (list/array) to their means for old models\n",
    "# Note that 'mfccs_mean' is not used anymore, so we replace it with 'mfccs'\n",
    "for col in ['mfccs', 'spectral_centroid', 'chroma', 'zero_crossing_rate', 'rms']:\n",
    "    if col in X_train.columns:\n",
    "        X_train[col] = X_train[col].apply(lambda x: np.mean(x) if isinstance(x, (list, np.ndarray)) else x)\n",
    "        X_test[col] = X_test[col].apply(lambda x: np.mean(x) if isinstance(x, (list, np.ndarray)) else x)\n",
    "\n",
    "# Check if the columns were converted correctly\n",
    "print(X_train.dtypes)\n",
    "# Should all be floats!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "dfd3fa6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (9729, 12)\n",
      "y_train shape: (9729,)\n",
      "X_test shape: (2433, 12)\n",
      "y_test shape: (2433,)\n",
      "\n",
      "Number of NaN values per column after conversion:\n",
      "mfccs_mean                    0\n",
      "mfccs_std                     0\n",
      "mfccs_skewness                0\n",
      "mfccs_kurtosis                0\n",
      "spectral_centroid_mean        0\n",
      "spectral_centroid_std         0\n",
      "spectral_centroid_skewness    0\n",
      "spectral_centroid_kurtosis    0\n",
      "chroma                        0\n",
      "zero_crossing_rate            0\n",
      "rms                           0\n",
      "pitch                         0\n",
      "path                          0\n",
      "filename                      0\n",
      "emotion                       0\n",
      "dtype: int64\n",
      "\n",
      "Number of NaN values per column after dropping rows with NaNs:\n",
      "mfccs_mean                    0\n",
      "mfccs_std                     0\n",
      "mfccs_skewness                0\n",
      "mfccs_kurtosis                0\n",
      "spectral_centroid_mean        0\n",
      "spectral_centroid_std         0\n",
      "spectral_centroid_skewness    0\n",
      "spectral_centroid_kurtosis    0\n",
      "chroma                        0\n",
      "zero_crossing_rate            0\n",
      "rms                           0\n",
      "pitch                         0\n",
      "path                          0\n",
      "filename                      0\n",
      "emotion                       0\n",
      "dtype: int64\n",
      "\n",
      "Final shape of eval_clean_data: (12162, 15)\n"
     ]
    }
   ],
   "source": [
    "# Handle null values\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "# Convert columns with list/array values to numeric\n",
    "# Now using the updated feature names like 'mfccs_mean', 'spectral_centroid_mean', etc.\n",
    "for col in ['mfccs_mean', 'mfccs_std', 'mfccs_skewness', 'mfccs_kurtosis', \n",
    "            'spectral_centroid_mean', 'spectral_centroid_std', \n",
    "            'spectral_centroid_skewness', 'spectral_centroid_kurtosis', \n",
    "            'chroma', 'zero_crossing_rate', 'rms']:\n",
    "    eval_clean_data[col] = eval_clean_data[col].apply(lambda x: np.mean(x) if isinstance(x, (list, np.ndarray)) else x)\n",
    "    # Convert to numeric, setting errors to 'coerce' which will turn invalid entries to NaN\n",
    "    eval_clean_data[col] = pd.to_numeric(eval_clean_data[col], errors='coerce')\n",
    "\n",
    "# Check for any NaN values after conversion\n",
    "print(\"\\nNumber of NaN values per column after conversion:\")\n",
    "print(eval_clean_data.isnull().sum())\n",
    "\n",
    "# Remove rows with NaN values\n",
    "eval_clean_data = eval_clean_data.dropna()\n",
    "\n",
    "# Verify that there are no more NaN values\n",
    "print(\"\\nNumber of NaN values per column after dropping rows with NaNs:\")\n",
    "print(eval_clean_data.isnull().sum())\n",
    "\n",
    "# Check final shape of the cleaned data\n",
    "print(\"\\nFinal shape of eval_clean_data:\", eval_clean_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4269e5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 135 candidates, totalling 675 fits\n",
      "Best parameters found:  {'max_depth': 10, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best cross-validation score:  0.47846550963415824\n",
      "\n",
      "Decision Tree Accuracy (Best): 0.4722564734895191\n",
      "Confusion Matrix (Best):\n",
      " [[246   0   9  23  63  11   4   1   8   0]\n",
      " [  2   8   3   2   2   8   0  14   0   0]\n",
      " [ 37   1 101  20  86  82  17  54   8   0]\n",
      " [ 53   0  24 105  58  48   1  67   5   0]\n",
      " [ 66   0  15  38 180  52   5   9   3   0]\n",
      " [  7   6  28  17  38 190   0  39   4   0]\n",
      " [  4   0   8   0   4   2  51   0   0   0]\n",
      " [  3   6  36  34  27  72   0 189   5   7]\n",
      " [  7   1   0   4   5   0   0   2  13   6]\n",
      " [  0   0   0   0   0   0   0   8   5  66]]\n",
      "Classification Report (Best):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.58      0.67      0.62       365\n",
      "        calm       0.36      0.21      0.26        39\n",
      "     disgust       0.45      0.25      0.32       406\n",
      "        fear       0.43      0.29      0.35       361\n",
      "       happy       0.39      0.49      0.43       368\n",
      "     neutral       0.41      0.58      0.48       329\n",
      "    pleasant       0.65      0.74      0.69        69\n",
      "         sad       0.49      0.50      0.50       379\n",
      "    surprise       0.25      0.34      0.29        38\n",
      "     unknown       0.84      0.84      0.84        79\n",
      "\n",
      "    accuracy                           0.47      2433\n",
      "   macro avg       0.49      0.49      0.48      2433\n",
      "weighted avg       0.47      0.47      0.46      2433\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid and run grid search\n",
    "param_grid = {\n",
    "    'max_depth': [None, 5, 10, 15, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', None] \n",
    "}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=DecisionTreeClassifier(random_state=42),\n",
    "                           param_grid=param_grid,\n",
    "                           cv=5,\n",
    "                           n_jobs=-1,\n",
    "                           scoring='accuracy',\n",
    "                           verbose=1)\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Review the best parameters and score\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: \", grid_search.best_score_)\n",
    "\n",
    "print() # new line for seperation\n",
    "\n",
    "# evaluate the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_best_tree = best_model.predict(X_test)\n",
    "\n",
    "print(\"Decision Tree Accuracy (Best):\", accuracy_score(y_test, y_pred_best_tree))\n",
    "print(\"Confusion Matrix (Best):\\n\", confusion_matrix(y_test, y_pred_best_tree))\n",
    "print(\"Classification Report (Best):\\n\", classification_report(y_test, y_pred_best_tree))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed32717",
   "metadata": {},
   "source": [
    "#### Evaluation:\n",
    "Accuracy of 46% is not great. \n",
    "\n",
    "Our f1-scores don't look super hot either. Let's address this!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f23a034",
   "metadata": {},
   "source": [
    "## Audio Augmentation for Underrepresented Classes\n",
    "\n",
    "Let's attempt to make the model better by evening the distribution. To do this, we will lower the more represented classes to 1500 each, and create synthetic data for the underrepresented classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a4e6d9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotion\n",
      "sad         1923\n",
      "angry       1863\n",
      "disgust     1863\n",
      "fear        1863\n",
      "happy       1863\n",
      "neutral     1583\n",
      "pleasant     400\n",
      "surprise     252\n",
      "calm         192\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "reduced_data = clean_data.copy()\n",
    "\n",
    "# drop rows with 'unknown' emotion\n",
    "reduced_data = reduced_data[reduced_data['emotion'] != 'unknown']\n",
    "# Define the target count for high emotion classes\n",
    "target_count_high = 1500\n",
    "\n",
    "# Previously, I had randomly removed rows from the higher distributed classes.\n",
    "# I believe this lead to information loss.\n",
    "                                        \n",
    "# Check the new distribution of the reduced data\n",
    "print(reduced_data['emotion'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ac35bc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio augmentation to help with uneven data\n",
    "def augment_audio(data, sr):\n",
    "    # Time Stretching\n",
    "    try:\n",
    "        stretched_data = librosa.effects.time_stretch(data, rate=1.1)\n",
    "    except Exception as e:\n",
    "        stretched_data = data\n",
    "    \n",
    "    # Shifting \n",
    "    shift = np.random.randint(sr)\n",
    "    shifted_data = np.roll(data, shift)\n",
    "    \n",
    "    # Volume adjustment\n",
    "    amplitude_scale = np.random.uniform(low=0.8, high=1.2)\n",
    "    adjusted_volume_data = data * amplitude_scale\n",
    "    \n",
    "    # Randomly choose one of the augmentation methods to apply\n",
    "    augmentation_methods = [stretched_data, shifted_data, adjusted_volume_data]\n",
    "    \n",
    "    # Check for invalid values in augmentation methods\n",
    "    valid_methods = [method for method in augmentation_methods if len(method) > 0 and not np.isnan(method).any() and not np.isinf(method).any()]\n",
    "    \n",
    "    if valid_methods:\n",
    "        augmented_data = random.choice(valid_methods)\n",
    "    else:\n",
    "        augmented_data = data\n",
    "    \n",
    "    return augmented_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2f89de38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values in the augmented DataFrame:\n",
      "mfccs_mean                    0\n",
      "mfccs_std                     0\n",
      "mfccs_skewness                0\n",
      "mfccs_kurtosis                0\n",
      "spectral_centroid_mean        0\n",
      "spectral_centroid_std         0\n",
      "spectral_centroid_skewness    0\n",
      "spectral_centroid_kurtosis    0\n",
      "chroma                        0\n",
      "zero_crossing_rate            0\n",
      "rms                           0\n",
      "pitch                         0\n",
      "emotion                       0\n",
      "dtype: int64\n",
      "emotion\n",
      "sad         1923\n",
      "angry       1863\n",
      "disgust     1863\n",
      "fear        1863\n",
      "happy       1863\n",
      "neutral     1800\n",
      "pleasant    1500\n",
      "surprise    1500\n",
      "calm        1500\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create a new DataFrame for augmented data\n",
    "augmented_data = reduced_data.copy()\n",
    "\n",
    "# Lists to store augmented features\n",
    "augmented_mfccs_mean_list = []\n",
    "augmented_mfccs_std_list = []\n",
    "augmented_mfccs_skewness_list = []\n",
    "augmented_mfccs_kurtosis_list = []\n",
    "\n",
    "augmented_spectral_centroid_mean_list = []\n",
    "augmented_spectral_centroid_std_list = []\n",
    "augmented_spectral_centroid_skewness_list = []\n",
    "augmented_spectral_centroid_kurtosis_list = []\n",
    "\n",
    "augmented_chroma_list = []\n",
    "augmented_zero_crossing_rate_list = []\n",
    "augmented_rms_list = []\n",
    "augmented_pitch_list = []\n",
    "augmented_emotions = []\n",
    "\n",
    "# Define target count for underrepresented classes\n",
    "target_count_underrepresented = 1500\n",
    "target_count_neutral = 1800\n",
    "underrepresented_emotions = ['pleasant', 'surprise', 'calm', 'neutral']\n",
    "\n",
    "# Process and augment underrepresented emotions\n",
    "for emotion in underrepresented_emotions:\n",
    "    current_count = augmented_data[augmented_data['emotion'] == emotion].shape[0]\n",
    "    if emotion == 'neutral':\n",
    "        num_augments_needed = target_count_neutral - current_count\n",
    "    else:\n",
    "        num_augments_needed = target_count_underrepresented - current_count\n",
    "\n",
    "    if num_augments_needed > 0:\n",
    "        # Find all samples of this emotion in the dataset\n",
    "        emotion_samples = augmented_data[augmented_data['emotion'] == emotion]\n",
    "        \n",
    "        # Augment samples until we reach the target count\n",
    "        for _ in range(num_augments_needed):\n",
    "            # Randomly select a sample to augment\n",
    "            random_sample = emotion_samples.sample(n=1).iloc[0]\n",
    "            audio_file = os.path.join(random_sample['path'], random_sample['filename'])\n",
    "            \n",
    "            try:\n",
    "                # Load the audio file\n",
    "                data, sr = librosa.load(audio_file, sr=None)\n",
    "\n",
    "                # Perform augmentation (assuming augment_audio is defined elsewhere)\n",
    "                augmented_data_sample = augment_audio(data, sr)\n",
    "\n",
    "                # Extract features from the augmented audio\n",
    "                augmented_features = extract_features(augmented_data_sample, sr=sr, from_file=False)\n",
    "\n",
    "                # Check if the features are valid\n",
    "                if isinstance(augmented_features, tuple) and len(augmented_features) == 9:\n",
    "                    # Extract the MFCCs statistics (mean, std, skewness, kurtosis)\n",
    "                    augmented_mfccs_mean_list.append(augmented_features[0])\n",
    "                    augmented_mfccs_std_list.append(augmented_features[1])\n",
    "                    augmented_mfccs_skewness_list.append(augmented_features[2])\n",
    "                    augmented_mfccs_kurtosis_list.append(augmented_features[3])\n",
    "\n",
    "                    # Extract Spectral Centroid statistics (mean, std, skewness, kurtosis)\n",
    "                    augmented_spectral_centroid_mean_list.append(augmented_features[4][0])\n",
    "                    augmented_spectral_centroid_std_list.append(augmented_features[4][1])\n",
    "                    augmented_spectral_centroid_skewness_list.append(augmented_features[4][2])\n",
    "                    augmented_spectral_centroid_kurtosis_list.append(augmented_features[4][3])\n",
    "\n",
    "                    # Extract other features\n",
    "                    augmented_chroma_list.append(augmented_features[5])\n",
    "                    augmented_zero_crossing_rate_list.append(augmented_features[6])\n",
    "                    augmented_rms_list.append(augmented_features[7])\n",
    "                    augmented_pitch_list.append(augmented_features[8])\n",
    "                    \n",
    "                    # Append the emotion\n",
    "                    augmented_emotions.append(emotion)\n",
    "                else:\n",
    "                    print(f\"Warning: Invalid number of features returned by extract_features for '{audio_file}'\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {audio_file}: {str(e)}\")\n",
    "\n",
    "# After augmentation, create a DataFrame to store augmented features\n",
    "augmented_df = pd.DataFrame({\n",
    "    'mfccs_mean': augmented_mfccs_mean_list,\n",
    "    'mfccs_std': augmented_mfccs_std_list,\n",
    "    'mfccs_skewness': augmented_mfccs_skewness_list,\n",
    "    'mfccs_kurtosis': augmented_mfccs_kurtosis_list,\n",
    "    'spectral_centroid_mean': augmented_spectral_centroid_mean_list,\n",
    "    'spectral_centroid_std': augmented_spectral_centroid_std_list,\n",
    "    'spectral_centroid_skewness': augmented_spectral_centroid_skewness_list,\n",
    "    'spectral_centroid_kurtosis': augmented_spectral_centroid_kurtosis_list,\n",
    "    'chroma': augmented_chroma_list,\n",
    "    'zero_crossing_rate': augmented_zero_crossing_rate_list,\n",
    "    'rms': augmented_rms_list,\n",
    "    'pitch': augmented_pitch_list,\n",
    "    'emotion': augmented_emotions\n",
    "})\n",
    "\n",
    "# Check for null values in the augmented DataFrame\n",
    "print(\"Null values in the augmented DataFrame:\")\n",
    "print(augmented_df.isnull().sum())\n",
    "\n",
    "# Combine reduced data with augmented data\n",
    "eval_aug_data = pd.concat([reduced_data, augmented_df], ignore_index=True)\n",
    "print()\n",
    "\n",
    "# Check the final distribution\n",
    "print(eval_aug_data['emotion'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b10bbdf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=eval_aug_data, x='emotion', order=eval_aug_data['emotion'].value_counts().index)\n",
    "plt.title('Distribution of Emotions After Augmentation')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# We are no longer dropping values for higher classes - we do not want the data loss.\n",
    "# augmented audio for underrepresented classes, bringing them to 1500. \n",
    "# augmented audio for 'neutral' class, bringing it to 1800 \n",
    "#  (to balance this underrepresented class from the larger class group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "bb8c9be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mfccs_mean</th>\n",
       "      <th>mfccs_std</th>\n",
       "      <th>mfccs_skewness</th>\n",
       "      <th>mfccs_kurtosis</th>\n",
       "      <th>spectral_centroid_mean</th>\n",
       "      <th>spectral_centroid_std</th>\n",
       "      <th>spectral_centroid_skewness</th>\n",
       "      <th>spectral_centroid_kurtosis</th>\n",
       "      <th>chroma</th>\n",
       "      <th>zero_crossing_rate</th>\n",
       "      <th>rms</th>\n",
       "      <th>pitch</th>\n",
       "      <th>path</th>\n",
       "      <th>filename</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-17.963037</td>\n",
       "      <td>26.37207</td>\n",
       "      <td>-0.51548</td>\n",
       "      <td>3.32999</td>\n",
       "      <td>1584.993070</td>\n",
       "      <td>600.410753</td>\n",
       "      <td>1.645968</td>\n",
       "      <td>5.914065</td>\n",
       "      <td>0.411293</td>\n",
       "      <td>0.101868</td>\n",
       "      <td>0.041986</td>\n",
       "      <td>1211.950684</td>\n",
       "      <td>dataset\\Crema</td>\n",
       "      <td>1001_DFA_ANG_XX.wav</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-18.657297</td>\n",
       "      <td>21.019888</td>\n",
       "      <td>-0.498601</td>\n",
       "      <td>3.982956</td>\n",
       "      <td>1531.650487</td>\n",
       "      <td>590.708457</td>\n",
       "      <td>2.221739</td>\n",
       "      <td>8.718056</td>\n",
       "      <td>0.423961</td>\n",
       "      <td>0.093061</td>\n",
       "      <td>0.015996</td>\n",
       "      <td>1256.617188</td>\n",
       "      <td>dataset\\Crema</td>\n",
       "      <td>1001_DFA_DIS_XX.wav</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-18.552622</td>\n",
       "      <td>25.241508</td>\n",
       "      <td>-0.602645</td>\n",
       "      <td>4.156697</td>\n",
       "      <td>1489.088839</td>\n",
       "      <td>521.794373</td>\n",
       "      <td>2.785179</td>\n",
       "      <td>13.443495</td>\n",
       "      <td>0.413398</td>\n",
       "      <td>0.084286</td>\n",
       "      <td>0.045776</td>\n",
       "      <td>992.574402</td>\n",
       "      <td>dataset\\Crema</td>\n",
       "      <td>1001_DFA_FEA_XX.wav</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-18.460817</td>\n",
       "      <td>24.993519</td>\n",
       "      <td>-0.653859</td>\n",
       "      <td>3.327673</td>\n",
       "      <td>1555.376035</td>\n",
       "      <td>476.260688</td>\n",
       "      <td>2.604170</td>\n",
       "      <td>11.342148</td>\n",
       "      <td>0.39482</td>\n",
       "      <td>0.084878</td>\n",
       "      <td>0.0423</td>\n",
       "      <td>1102.953003</td>\n",
       "      <td>dataset\\Crema</td>\n",
       "      <td>1001_DFA_HAP_XX.wav</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-18.111607</td>\n",
       "      <td>20.89341</td>\n",
       "      <td>-0.480883</td>\n",
       "      <td>3.167808</td>\n",
       "      <td>1495.394997</td>\n",
       "      <td>492.130906</td>\n",
       "      <td>1.597144</td>\n",
       "      <td>6.070896</td>\n",
       "      <td>0.401279</td>\n",
       "      <td>0.082031</td>\n",
       "      <td>0.02045</td>\n",
       "      <td>1041.093628</td>\n",
       "      <td>dataset\\Crema</td>\n",
       "      <td>1001_DFA_NEU_XX.wav</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  mfccs_mean  mfccs_std mfccs_skewness mfccs_kurtosis  spectral_centroid_mean  \\\n",
       "0 -17.963037   26.37207       -0.51548        3.32999             1584.993070   \n",
       "1 -18.657297  21.019888      -0.498601       3.982956             1531.650487   \n",
       "2 -18.552622  25.241508      -0.602645       4.156697             1489.088839   \n",
       "3 -18.460817  24.993519      -0.653859       3.327673             1555.376035   \n",
       "4 -18.111607   20.89341      -0.480883       3.167808             1495.394997   \n",
       "\n",
       "   spectral_centroid_std  spectral_centroid_skewness  \\\n",
       "0             600.410753                    1.645968   \n",
       "1             590.708457                    2.221739   \n",
       "2             521.794373                    2.785179   \n",
       "3             476.260688                    2.604170   \n",
       "4             492.130906                    1.597144   \n",
       "\n",
       "   spectral_centroid_kurtosis    chroma zero_crossing_rate       rms  \\\n",
       "0                    5.914065  0.411293           0.101868  0.041986   \n",
       "1                    8.718056  0.423961           0.093061  0.015996   \n",
       "2                   13.443495  0.413398           0.084286  0.045776   \n",
       "3                   11.342148   0.39482           0.084878    0.0423   \n",
       "4                    6.070896  0.401279           0.082031   0.02045   \n",
       "\n",
       "         pitch           path             filename  emotion  \n",
       "0  1211.950684  dataset\\Crema  1001_DFA_ANG_XX.wav    angry  \n",
       "1  1256.617188  dataset\\Crema  1001_DFA_DIS_XX.wav  disgust  \n",
       "2   992.574402  dataset\\Crema  1001_DFA_FEA_XX.wav     fear  \n",
       "3  1102.953003  dataset\\Crema  1001_DFA_HAP_XX.wav    happy  \n",
       "4  1041.093628  dataset\\Crema  1001_DFA_NEU_XX.wav  neutral  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_aug_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712a5abf",
   "metadata": {},
   "source": [
    "# Model Iterations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0394cc8",
   "metadata": {},
   "source": [
    "#### Evaluation v1:\n",
    "\n",
    "Classification Report (grid search)\n",
    "\n",
    "|               | precision | recall | f1-score | support |\n",
    "|---------------|-----------|--------|----------|---------|\n",
    "| accuracy      |           |        |          | 0.46    | 2433    |\n",
    "| macro avg     | 0.43      | 0.43   | 0.43     | 2433    |\n",
    "| weighted avg  | 0.46      | 0.46   | 0.45     | 2433    |\n",
    "\n",
    "#### Evaluation v2:\n",
    "\n",
    "Classification Report (grid search with SMOTE):\n",
    "\n",
    "|               | precision | recall | f1-score | support |\n",
    "|---------------|-----------|--------|----------|---------|\n",
    "| accuracy      |           |        |          | 0.71    | 5962    |\n",
    "| macro avg     | 0.70      | 0.71   | 0.70     | 5962    |\n",
    "| weighted avg  | 0.70      | 0.71   | 0.71     | 5962    |\n",
    "\n",
    "#### Evaluation v3:\n",
    "\n",
    "Classification Report (decision tree w/ augmentation and 1500 samples per category):\n",
    "\n",
    "|               | precision | recall | f1-score | support |\n",
    "|---------------|-----------|--------|----------|---------|\n",
    "| accuracy      |           |        |          | 0.58    | 2700    |\n",
    "| macro avg     | 0.57      | 0.58   | 0.57     | 2700    |\n",
    "| weighted avg  | 0.57      | 0.58   | 0.57     | 2700    |\n",
    "\n",
    "Accuracy of 59%; certainly an imporovement! But nothing substantial. \n",
    "\n",
    "Despite evening the distribution, we are still not seeing the model perform well. This is likely because 7k records\n",
    "is probably not enough to get good predictive capacity over our 7 categories. \n",
    "\n",
    "the f1-scores that indicate weaknesses in our model is: disgust, fear, happy. this tells me that maybe we shouldn't have deleted \n",
    "\n",
    "Let's engineer the categories into pos/neg binary classification and see if that improves our results.\n",
    "\n",
    "#### Evaluation v4:\n",
    "\n",
    "Classification Report (decision tree w/ even distribution, no deleting records):\n",
    "\n",
    "|               | precision | recall | f1-score | support |\n",
    "|---------------|-----------|--------|----------|---------|\n",
    "| accuracy      |           |        |          | 0.56    | 3135    |\n",
    "| macro avg     | 0.57      | 0.59   | 0.57     | 3135    |\n",
    "| weighted avg  | 0.55      | 0.56   | 0.54     | 3135    |\n",
    "\n",
    "Accuracy of 55.34%: While this may seem like a drop, it's important to note that the dataset has been augmented, which can affect the accuracy score. \n",
    "\n",
    "F1-scores: \n",
    "- the f1-scores for underrepresented classes like 'disgust', 'fear', and 'happy' slightly improved compared to previous version.\n",
    "- the f1-score for 'neutral' decreased slightly (0.02), which could be due to the additional augmented samples\n",
    "- the f1-score for the other classes either remained or improved marginally\n",
    "\n",
    "Precision / Recall:\n",
    "- the recall for underrepresented classes has generally improved\n",
    "- however, the precision (ability to not label negative instances as positive) has decreased, which could be due to the introduction of noise in the augmented data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dbc19e",
   "metadata": {},
   "source": [
    "#### Evaluation v5\n",
    "\n",
    "Classification Report (logistic regression for **binary classification**):  \n",
    "\n",
    "| | precision | recall | f1-score | support |\n",
    "|---------------|-----------|--------|----------|---------|\n",
    "| Negative | 0.65 | 0.74 | 0.69 | 1536 |\n",
    "| Positive | 0.36 | 0.27 | 0.31 | 825 |\n",
    "| accuracy | | | | 0.57 | 2361 |\n",
    "| macro avg | 0.51 | 0.51 | 0.50 | 2361 |\n",
    "| weighted avg | 0.55 | 0.57 | 0.56 | 2361 |\n",
    "\n",
    "As suspected, the 'positive' data suffered due to imbalanced classes. \n",
    "\n",
    "Let's augment some of the audio for the 'positive' class, and bring it closer to the negative class balance.\n",
    "\n",
    "#### Evaluation v6\n",
    "Classification Report (logistic regression for **binary classification with augmented data**): \n",
    "\n",
    "| | precision | recall | f1-score | support |\n",
    "|---------------|-----------|--------|----------|---------|\n",
    "| Negative | 0.65 | 0.74 | 0.69 | 1536 |\n",
    "| Positive | 0.36 | 0.27 | 0.31 | 825 |\n",
    "| accuracy | | | | 0.57 | 2361 |\n",
    "| macro avg | 0.51 | 0.51 | 0.50 | 2361 |\n",
    "| weighted avg | 0.55 | 0.57 | 0.56 | 2361 |\n",
    "\n",
    "Having the same values as v5, I believe where we split the data caused data leakage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b14a544",
   "metadata": {},
   "source": [
    "## Latest Model: Multiclassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8573ba04",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15675\n",
      "emotion\n",
      "sad         1923\n",
      "angry       1863\n",
      "disgust     1863\n",
      "fear        1863\n",
      "happy       1863\n",
      "neutral     1800\n",
      "pleasant    1500\n",
      "surprise    1500\n",
      "calm        1500\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mfccs_mean</th>\n",
       "      <th>mfccs_std</th>\n",
       "      <th>mfccs_skewness</th>\n",
       "      <th>mfccs_kurtosis</th>\n",
       "      <th>spectral_centroid_mean</th>\n",
       "      <th>spectral_centroid_std</th>\n",
       "      <th>spectral_centroid_skewness</th>\n",
       "      <th>spectral_centroid_kurtosis</th>\n",
       "      <th>chroma</th>\n",
       "      <th>zero_crossing_rate</th>\n",
       "      <th>rms</th>\n",
       "      <th>pitch</th>\n",
       "      <th>path</th>\n",
       "      <th>filename</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-17.963037</td>\n",
       "      <td>26.37207</td>\n",
       "      <td>-0.51548</td>\n",
       "      <td>3.32999</td>\n",
       "      <td>1584.993070</td>\n",
       "      <td>600.410753</td>\n",
       "      <td>1.645968</td>\n",
       "      <td>5.914065</td>\n",
       "      <td>0.411293</td>\n",
       "      <td>0.101868</td>\n",
       "      <td>0.041986</td>\n",
       "      <td>1211.950684</td>\n",
       "      <td>dataset\\Crema</td>\n",
       "      <td>1001_DFA_ANG_XX.wav</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-18.657297</td>\n",
       "      <td>21.019888</td>\n",
       "      <td>-0.498601</td>\n",
       "      <td>3.982956</td>\n",
       "      <td>1531.650487</td>\n",
       "      <td>590.708457</td>\n",
       "      <td>2.221739</td>\n",
       "      <td>8.718056</td>\n",
       "      <td>0.423961</td>\n",
       "      <td>0.093061</td>\n",
       "      <td>0.015996</td>\n",
       "      <td>1256.617188</td>\n",
       "      <td>dataset\\Crema</td>\n",
       "      <td>1001_DFA_DIS_XX.wav</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-18.552622</td>\n",
       "      <td>25.241508</td>\n",
       "      <td>-0.602645</td>\n",
       "      <td>4.156697</td>\n",
       "      <td>1489.088839</td>\n",
       "      <td>521.794373</td>\n",
       "      <td>2.785179</td>\n",
       "      <td>13.443495</td>\n",
       "      <td>0.413398</td>\n",
       "      <td>0.084286</td>\n",
       "      <td>0.045776</td>\n",
       "      <td>992.574402</td>\n",
       "      <td>dataset\\Crema</td>\n",
       "      <td>1001_DFA_FEA_XX.wav</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-18.460817</td>\n",
       "      <td>24.993519</td>\n",
       "      <td>-0.653859</td>\n",
       "      <td>3.327673</td>\n",
       "      <td>1555.376035</td>\n",
       "      <td>476.260688</td>\n",
       "      <td>2.604170</td>\n",
       "      <td>11.342148</td>\n",
       "      <td>0.39482</td>\n",
       "      <td>0.084878</td>\n",
       "      <td>0.0423</td>\n",
       "      <td>1102.953003</td>\n",
       "      <td>dataset\\Crema</td>\n",
       "      <td>1001_DFA_HAP_XX.wav</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-18.111607</td>\n",
       "      <td>20.89341</td>\n",
       "      <td>-0.480883</td>\n",
       "      <td>3.167808</td>\n",
       "      <td>1495.394997</td>\n",
       "      <td>492.130906</td>\n",
       "      <td>1.597144</td>\n",
       "      <td>6.070896</td>\n",
       "      <td>0.401279</td>\n",
       "      <td>0.082031</td>\n",
       "      <td>0.02045</td>\n",
       "      <td>1041.093628</td>\n",
       "      <td>dataset\\Crema</td>\n",
       "      <td>1001_DFA_NEU_XX.wav</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-19.037416</td>\n",
       "      <td>19.278528</td>\n",
       "      <td>-0.311734</td>\n",
       "      <td>3.857102</td>\n",
       "      <td>1513.748780</td>\n",
       "      <td>612.127986</td>\n",
       "      <td>2.101667</td>\n",
       "      <td>7.437446</td>\n",
       "      <td>0.427224</td>\n",
       "      <td>0.087023</td>\n",
       "      <td>0.012455</td>\n",
       "      <td>1130.106445</td>\n",
       "      <td>dataset\\Crema</td>\n",
       "      <td>1001_DFA_SAD_XX.wav</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-17.17767</td>\n",
       "      <td>27.92971</td>\n",
       "      <td>-0.568144</td>\n",
       "      <td>2.947689</td>\n",
       "      <td>1721.615099</td>\n",
       "      <td>670.983957</td>\n",
       "      <td>1.693535</td>\n",
       "      <td>6.386756</td>\n",
       "      <td>0.384599</td>\n",
       "      <td>0.116883</td>\n",
       "      <td>0.049829</td>\n",
       "      <td>1165.974365</td>\n",
       "      <td>dataset\\Crema</td>\n",
       "      <td>1001_IEO_ANG_HI.wav</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-19.042795</td>\n",
       "      <td>20.650948</td>\n",
       "      <td>-0.859197</td>\n",
       "      <td>3.966737</td>\n",
       "      <td>1382.379410</td>\n",
       "      <td>417.442372</td>\n",
       "      <td>2.030664</td>\n",
       "      <td>7.023072</td>\n",
       "      <td>0.431309</td>\n",
       "      <td>0.077945</td>\n",
       "      <td>0.016672</td>\n",
       "      <td>852.710693</td>\n",
       "      <td>dataset\\Crema</td>\n",
       "      <td>1001_IEO_ANG_LO.wav</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-18.658516</td>\n",
       "      <td>24.008181</td>\n",
       "      <td>-0.445653</td>\n",
       "      <td>3.146925</td>\n",
       "      <td>1519.672019</td>\n",
       "      <td>691.802134</td>\n",
       "      <td>2.833488</td>\n",
       "      <td>12.462970</td>\n",
       "      <td>0.392562</td>\n",
       "      <td>0.100239</td>\n",
       "      <td>0.021257</td>\n",
       "      <td>883.379822</td>\n",
       "      <td>dataset\\Crema</td>\n",
       "      <td>1001_IEO_ANG_MD.wav</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-18.313822</td>\n",
       "      <td>25.082436</td>\n",
       "      <td>-0.444414</td>\n",
       "      <td>3.029579</td>\n",
       "      <td>1653.022971</td>\n",
       "      <td>595.904416</td>\n",
       "      <td>1.571637</td>\n",
       "      <td>4.769554</td>\n",
       "      <td>0.446643</td>\n",
       "      <td>0.107577</td>\n",
       "      <td>0.029184</td>\n",
       "      <td>1174.250610</td>\n",
       "      <td>dataset\\Crema</td>\n",
       "      <td>1001_IEO_DIS_HI.wav</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-21.081461</td>\n",
       "      <td>15.886333</td>\n",
       "      <td>-0.608886</td>\n",
       "      <td>4.178171</td>\n",
       "      <td>1426.451484</td>\n",
       "      <td>555.580316</td>\n",
       "      <td>2.889272</td>\n",
       "      <td>11.448982</td>\n",
       "      <td>0.420022</td>\n",
       "      <td>0.07804</td>\n",
       "      <td>0.006508</td>\n",
       "      <td>871.955811</td>\n",
       "      <td>dataset\\Crema</td>\n",
       "      <td>1001_IEO_DIS_LO.wav</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-19.363337</td>\n",
       "      <td>20.43638</td>\n",
       "      <td>-0.490412</td>\n",
       "      <td>3.093709</td>\n",
       "      <td>1579.157076</td>\n",
       "      <td>726.491503</td>\n",
       "      <td>2.532258</td>\n",
       "      <td>9.763822</td>\n",
       "      <td>0.463131</td>\n",
       "      <td>0.093726</td>\n",
       "      <td>0.013139</td>\n",
       "      <td>923.827820</td>\n",
       "      <td>dataset\\Crema</td>\n",
       "      <td>1001_IEO_DIS_MD.wav</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-17.146267</td>\n",
       "      <td>26.736921</td>\n",
       "      <td>-0.606002</td>\n",
       "      <td>2.798373</td>\n",
       "      <td>1569.891004</td>\n",
       "      <td>515.727033</td>\n",
       "      <td>1.171008</td>\n",
       "      <td>3.443584</td>\n",
       "      <td>0.393127</td>\n",
       "      <td>0.097656</td>\n",
       "      <td>0.058001</td>\n",
       "      <td>1246.348389</td>\n",
       "      <td>dataset\\Crema</td>\n",
       "      <td>1001_IEO_FEA_HI.wav</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-18.153639</td>\n",
       "      <td>21.772373</td>\n",
       "      <td>-0.49463</td>\n",
       "      <td>3.202611</td>\n",
       "      <td>1573.957348</td>\n",
       "      <td>748.661450</td>\n",
       "      <td>2.280335</td>\n",
       "      <td>8.254696</td>\n",
       "      <td>0.418144</td>\n",
       "      <td>0.098755</td>\n",
       "      <td>0.018541</td>\n",
       "      <td>970.944153</td>\n",
       "      <td>dataset\\Crema</td>\n",
       "      <td>1001_IEO_FEA_LO.wav</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-18.206676</td>\n",
       "      <td>24.463205</td>\n",
       "      <td>-0.759182</td>\n",
       "      <td>3.206881</td>\n",
       "      <td>1601.113807</td>\n",
       "      <td>672.821488</td>\n",
       "      <td>2.140469</td>\n",
       "      <td>7.789769</td>\n",
       "      <td>0.385029</td>\n",
       "      <td>0.103621</td>\n",
       "      <td>0.029428</td>\n",
       "      <td>1090.932129</td>\n",
       "      <td>dataset\\Crema</td>\n",
       "      <td>1001_IEO_FEA_MD.wav</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-17.438225</td>\n",
       "      <td>27.935781</td>\n",
       "      <td>-0.470884</td>\n",
       "      <td>2.554761</td>\n",
       "      <td>1798.658469</td>\n",
       "      <td>558.887994</td>\n",
       "      <td>1.432577</td>\n",
       "      <td>5.353043</td>\n",
       "      <td>0.377055</td>\n",
       "      <td>0.131757</td>\n",
       "      <td>0.067256</td>\n",
       "      <td>1315.056519</td>\n",
       "      <td>dataset\\Crema</td>\n",
       "      <td>1001_IEO_HAP_HI.wav</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-18.815228</td>\n",
       "      <td>22.060028</td>\n",
       "      <td>-0.744451</td>\n",
       "      <td>4.03357</td>\n",
       "      <td>1506.382518</td>\n",
       "      <td>548.920108</td>\n",
       "      <td>2.880380</td>\n",
       "      <td>12.398396</td>\n",
       "      <td>0.423209</td>\n",
       "      <td>0.090169</td>\n",
       "      <td>0.017724</td>\n",
       "      <td>836.389587</td>\n",
       "      <td>dataset\\Crema</td>\n",
       "      <td>1001_IEO_HAP_LO.wav</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-19.002438</td>\n",
       "      <td>24.189583</td>\n",
       "      <td>-0.744126</td>\n",
       "      <td>3.554328</td>\n",
       "      <td>1575.538940</td>\n",
       "      <td>678.027745</td>\n",
       "      <td>2.839510</td>\n",
       "      <td>11.896305</td>\n",
       "      <td>0.415429</td>\n",
       "      <td>0.093842</td>\n",
       "      <td>0.026335</td>\n",
       "      <td>943.920166</td>\n",
       "      <td>dataset\\Crema</td>\n",
       "      <td>1001_IEO_HAP_MD.wav</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-18.700005</td>\n",
       "      <td>20.021679</td>\n",
       "      <td>-0.550374</td>\n",
       "      <td>3.291337</td>\n",
       "      <td>1586.260938</td>\n",
       "      <td>706.270510</td>\n",
       "      <td>2.573647</td>\n",
       "      <td>9.742196</td>\n",
       "      <td>0.392644</td>\n",
       "      <td>0.094688</td>\n",
       "      <td>0.012203</td>\n",
       "      <td>861.429565</td>\n",
       "      <td>dataset\\Crema</td>\n",
       "      <td>1001_IEO_NEU_XX.wav</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-19.752665</td>\n",
       "      <td>19.04616</td>\n",
       "      <td>-0.269438</td>\n",
       "      <td>3.909208</td>\n",
       "      <td>1425.160358</td>\n",
       "      <td>700.495555</td>\n",
       "      <td>3.083275</td>\n",
       "      <td>13.074131</td>\n",
       "      <td>0.411476</td>\n",
       "      <td>0.083969</td>\n",
       "      <td>0.012364</td>\n",
       "      <td>827.952759</td>\n",
       "      <td>dataset\\Crema</td>\n",
       "      <td>1001_IEO_SAD_HI.wav</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mfccs_mean  mfccs_std mfccs_skewness mfccs_kurtosis  \\\n",
       "0  -17.963037   26.37207       -0.51548        3.32999   \n",
       "1  -18.657297  21.019888      -0.498601       3.982956   \n",
       "2  -18.552622  25.241508      -0.602645       4.156697   \n",
       "3  -18.460817  24.993519      -0.653859       3.327673   \n",
       "4  -18.111607   20.89341      -0.480883       3.167808   \n",
       "5  -19.037416  19.278528      -0.311734       3.857102   \n",
       "6   -17.17767   27.92971      -0.568144       2.947689   \n",
       "7  -19.042795  20.650948      -0.859197       3.966737   \n",
       "8  -18.658516  24.008181      -0.445653       3.146925   \n",
       "9  -18.313822  25.082436      -0.444414       3.029579   \n",
       "10 -21.081461  15.886333      -0.608886       4.178171   \n",
       "11 -19.363337   20.43638      -0.490412       3.093709   \n",
       "12 -17.146267  26.736921      -0.606002       2.798373   \n",
       "13 -18.153639  21.772373       -0.49463       3.202611   \n",
       "14 -18.206676  24.463205      -0.759182       3.206881   \n",
       "15 -17.438225  27.935781      -0.470884       2.554761   \n",
       "16 -18.815228  22.060028      -0.744451        4.03357   \n",
       "17 -19.002438  24.189583      -0.744126       3.554328   \n",
       "18 -18.700005  20.021679      -0.550374       3.291337   \n",
       "19 -19.752665   19.04616      -0.269438       3.909208   \n",
       "\n",
       "    spectral_centroid_mean  spectral_centroid_std  spectral_centroid_skewness  \\\n",
       "0              1584.993070             600.410753                    1.645968   \n",
       "1              1531.650487             590.708457                    2.221739   \n",
       "2              1489.088839             521.794373                    2.785179   \n",
       "3              1555.376035             476.260688                    2.604170   \n",
       "4              1495.394997             492.130906                    1.597144   \n",
       "5              1513.748780             612.127986                    2.101667   \n",
       "6              1721.615099             670.983957                    1.693535   \n",
       "7              1382.379410             417.442372                    2.030664   \n",
       "8              1519.672019             691.802134                    2.833488   \n",
       "9              1653.022971             595.904416                    1.571637   \n",
       "10             1426.451484             555.580316                    2.889272   \n",
       "11             1579.157076             726.491503                    2.532258   \n",
       "12             1569.891004             515.727033                    1.171008   \n",
       "13             1573.957348             748.661450                    2.280335   \n",
       "14             1601.113807             672.821488                    2.140469   \n",
       "15             1798.658469             558.887994                    1.432577   \n",
       "16             1506.382518             548.920108                    2.880380   \n",
       "17             1575.538940             678.027745                    2.839510   \n",
       "18             1586.260938             706.270510                    2.573647   \n",
       "19             1425.160358             700.495555                    3.083275   \n",
       "\n",
       "    spectral_centroid_kurtosis    chroma zero_crossing_rate       rms  \\\n",
       "0                     5.914065  0.411293           0.101868  0.041986   \n",
       "1                     8.718056  0.423961           0.093061  0.015996   \n",
       "2                    13.443495  0.413398           0.084286  0.045776   \n",
       "3                    11.342148   0.39482           0.084878    0.0423   \n",
       "4                     6.070896  0.401279           0.082031   0.02045   \n",
       "5                     7.437446  0.427224           0.087023  0.012455   \n",
       "6                     6.386756  0.384599           0.116883  0.049829   \n",
       "7                     7.023072  0.431309           0.077945  0.016672   \n",
       "8                    12.462970  0.392562           0.100239  0.021257   \n",
       "9                     4.769554  0.446643           0.107577  0.029184   \n",
       "10                   11.448982  0.420022            0.07804  0.006508   \n",
       "11                    9.763822  0.463131           0.093726  0.013139   \n",
       "12                    3.443584  0.393127           0.097656  0.058001   \n",
       "13                    8.254696  0.418144           0.098755  0.018541   \n",
       "14                    7.789769  0.385029           0.103621  0.029428   \n",
       "15                    5.353043  0.377055           0.131757  0.067256   \n",
       "16                   12.398396  0.423209           0.090169  0.017724   \n",
       "17                   11.896305  0.415429           0.093842  0.026335   \n",
       "18                    9.742196  0.392644           0.094688  0.012203   \n",
       "19                   13.074131  0.411476           0.083969  0.012364   \n",
       "\n",
       "          pitch           path             filename  emotion  \n",
       "0   1211.950684  dataset\\Crema  1001_DFA_ANG_XX.wav    angry  \n",
       "1   1256.617188  dataset\\Crema  1001_DFA_DIS_XX.wav  disgust  \n",
       "2    992.574402  dataset\\Crema  1001_DFA_FEA_XX.wav     fear  \n",
       "3   1102.953003  dataset\\Crema  1001_DFA_HAP_XX.wav    happy  \n",
       "4   1041.093628  dataset\\Crema  1001_DFA_NEU_XX.wav  neutral  \n",
       "5   1130.106445  dataset\\Crema  1001_DFA_SAD_XX.wav      sad  \n",
       "6   1165.974365  dataset\\Crema  1001_IEO_ANG_HI.wav    angry  \n",
       "7    852.710693  dataset\\Crema  1001_IEO_ANG_LO.wav    angry  \n",
       "8    883.379822  dataset\\Crema  1001_IEO_ANG_MD.wav    angry  \n",
       "9   1174.250610  dataset\\Crema  1001_IEO_DIS_HI.wav  disgust  \n",
       "10   871.955811  dataset\\Crema  1001_IEO_DIS_LO.wav  disgust  \n",
       "11   923.827820  dataset\\Crema  1001_IEO_DIS_MD.wav  disgust  \n",
       "12  1246.348389  dataset\\Crema  1001_IEO_FEA_HI.wav     fear  \n",
       "13   970.944153  dataset\\Crema  1001_IEO_FEA_LO.wav     fear  \n",
       "14  1090.932129  dataset\\Crema  1001_IEO_FEA_MD.wav     fear  \n",
       "15  1315.056519  dataset\\Crema  1001_IEO_HAP_HI.wav    happy  \n",
       "16   836.389587  dataset\\Crema  1001_IEO_HAP_LO.wav    happy  \n",
       "17   943.920166  dataset\\Crema  1001_IEO_HAP_MD.wav    happy  \n",
       "18   861.429565  dataset\\Crema  1001_IEO_NEU_XX.wav  neutral  \n",
       "19   827.952759  dataset\\Crema  1001_IEO_SAD_HI.wav      sad  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(eval_aug_data))\n",
    "print(eval_aug_data['emotion'].value_counts())\n",
    "\n",
    "eval_aug_data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ef5b1b",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c3d04fad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (12540, 12)\n",
      "y_train shape: (12540, 9)\n",
      "X_test shape: (3135, 12)\n",
      "y_test shape: (3135, 9)\n"
     ]
    }
   ],
   "source": [
    "# Drop non-numeric columns like 'filename' and 'path' before fitting the model\n",
    "X = eval_aug_data.drop(columns=['emotion', 'filename', 'path'])\n",
    "\n",
    "# Extract the labels (emotions)\n",
    "y = eval_aug_data['emotion']\n",
    "\n",
    "# Convert columns with object type (lists or arrays) to their means\n",
    "# Use correct column names after feature extraction\n",
    "for col in ['mfccs_mean', 'mfccs_std', 'mfccs_skewness', 'mfccs_kurtosis',\n",
    "            'spectral_centroid_mean', 'spectral_centroid_std', \n",
    "            'spectral_centroid_skewness', 'spectral_centroid_kurtosis', \n",
    "            'chroma', 'zero_crossing_rate', 'rms']:\n",
    "    if col in X.columns:\n",
    "        # Just in case, ensure that list/array values are converted to numeric\n",
    "        X[col] = X[col].apply(lambda x: np.mean(x) if isinstance(x, (list, np.ndarray)) else x)\n",
    "\n",
    "# Handle any remaining NaN values\n",
    "X = X.dropna()\n",
    "\n",
    "# Encode the labels (emotions) as integers using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# One-hot encode the labels for multiclass classification\n",
    "y_one_hot = to_categorical(y_encoded)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Print dataset shapes to verify\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454da9b2",
   "metadata": {},
   "source": [
    "### Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "41291b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0427c36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9076f34b",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6ac6720c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "314/314 - 1s - loss: 5.2242 - accuracy: 0.2904 - val_loss: 1.5767 - val_accuracy: 0.3796 - 1s/epoch - 5ms/step\n",
      "Epoch 2/50\n",
      "314/314 - 0s - loss: 4.0412 - accuracy: 0.3690 - val_loss: 1.3963 - val_accuracy: 0.4426 - 429ms/epoch - 1ms/step\n",
      "Epoch 3/50\n",
      "314/314 - 0s - loss: 3.7112 - accuracy: 0.4077 - val_loss: 1.3365 - val_accuracy: 0.4653 - 435ms/epoch - 1ms/step\n",
      "Epoch 4/50\n",
      "314/314 - 0s - loss: 3.5404 - accuracy: 0.4246 - val_loss: 1.3112 - val_accuracy: 0.4717 - 434ms/epoch - 1ms/step\n",
      "Epoch 5/50\n",
      "314/314 - 0s - loss: 3.4341 - accuracy: 0.4424 - val_loss: 1.2632 - val_accuracy: 0.5060 - 433ms/epoch - 1ms/step\n",
      "Epoch 6/50\n",
      "314/314 - 0s - loss: 3.3618 - accuracy: 0.4527 - val_loss: 1.2554 - val_accuracy: 0.4948 - 434ms/epoch - 1ms/step\n",
      "Epoch 7/50\n",
      "314/314 - 0s - loss: 3.3133 - accuracy: 0.4662 - val_loss: 1.2811 - val_accuracy: 0.4801 - 434ms/epoch - 1ms/step\n",
      "Epoch 8/50\n",
      "314/314 - 0s - loss: 3.2622 - accuracy: 0.4722 - val_loss: 1.2334 - val_accuracy: 0.5072 - 452ms/epoch - 1ms/step\n",
      "Epoch 9/50\n",
      "314/314 - 0s - loss: 3.1975 - accuracy: 0.4809 - val_loss: 1.2253 - val_accuracy: 0.5072 - 432ms/epoch - 1ms/step\n",
      "Epoch 10/50\n",
      "314/314 - 0s - loss: 3.1772 - accuracy: 0.4905 - val_loss: 1.2020 - val_accuracy: 0.5227 - 432ms/epoch - 1ms/step\n",
      "Epoch 11/50\n",
      "314/314 - 0s - loss: 3.1412 - accuracy: 0.4955 - val_loss: 1.2073 - val_accuracy: 0.5163 - 468ms/epoch - 1ms/step\n",
      "Epoch 12/50\n",
      "314/314 - 0s - loss: 3.1153 - accuracy: 0.4986 - val_loss: 1.2149 - val_accuracy: 0.5128 - 438ms/epoch - 1ms/step\n",
      "Epoch 13/50\n",
      "314/314 - 0s - loss: 3.1039 - accuracy: 0.4956 - val_loss: 1.2052 - val_accuracy: 0.5199 - 431ms/epoch - 1ms/step\n",
      "Epoch 14/50\n",
      "314/314 - 0s - loss: 3.0800 - accuracy: 0.4999 - val_loss: 1.2008 - val_accuracy: 0.5084 - 430ms/epoch - 1ms/step\n",
      "Epoch 15/50\n",
      "314/314 - 0s - loss: 3.0659 - accuracy: 0.5049 - val_loss: 1.1606 - val_accuracy: 0.5490 - 436ms/epoch - 1ms/step\n",
      "Epoch 16/50\n",
      "314/314 - 0s - loss: 3.0360 - accuracy: 0.5119 - val_loss: 1.1475 - val_accuracy: 0.5490 - 453ms/epoch - 1ms/step\n",
      "Epoch 17/50\n",
      "314/314 - 0s - loss: 3.0182 - accuracy: 0.5152 - val_loss: 1.1315 - val_accuracy: 0.5582 - 449ms/epoch - 1ms/step\n",
      "Epoch 18/50\n",
      "314/314 - 0s - loss: 3.0214 - accuracy: 0.5190 - val_loss: 1.1708 - val_accuracy: 0.5427 - 440ms/epoch - 1ms/step\n",
      "Epoch 19/50\n",
      "314/314 - 0s - loss: 2.9833 - accuracy: 0.5220 - val_loss: 1.1560 - val_accuracy: 0.5455 - 443ms/epoch - 1ms/step\n",
      "Epoch 20/50\n",
      "314/314 - 0s - loss: 2.9810 - accuracy: 0.5251 - val_loss: 1.1233 - val_accuracy: 0.5654 - 439ms/epoch - 1ms/step\n",
      "Epoch 21/50\n",
      "314/314 - 0s - loss: 2.9868 - accuracy: 0.5261 - val_loss: 1.1428 - val_accuracy: 0.5590 - 430ms/epoch - 1ms/step\n",
      "Epoch 22/50\n",
      "314/314 - 0s - loss: 2.9512 - accuracy: 0.5294 - val_loss: 1.1203 - val_accuracy: 0.5522 - 433ms/epoch - 1ms/step\n",
      "Epoch 23/50\n",
      "314/314 - 0s - loss: 2.9350 - accuracy: 0.5279 - val_loss: 1.1521 - val_accuracy: 0.5327 - 461ms/epoch - 1ms/step\n",
      "Epoch 24/50\n",
      "314/314 - 0s - loss: 2.9167 - accuracy: 0.5357 - val_loss: 1.1467 - val_accuracy: 0.5478 - 454ms/epoch - 1ms/step\n",
      "Epoch 25/50\n",
      "314/314 - 0s - loss: 2.9210 - accuracy: 0.5299 - val_loss: 1.1049 - val_accuracy: 0.5678 - 444ms/epoch - 1ms/step\n",
      "Epoch 26/50\n",
      "314/314 - 0s - loss: 2.9240 - accuracy: 0.5370 - val_loss: 1.1554 - val_accuracy: 0.5355 - 439ms/epoch - 1ms/step\n",
      "Epoch 27/50\n",
      "314/314 - 0s - loss: 2.8965 - accuracy: 0.5421 - val_loss: 1.1085 - val_accuracy: 0.5702 - 446ms/epoch - 1ms/step\n",
      "Epoch 28/50\n",
      "314/314 - 0s - loss: 2.8640 - accuracy: 0.5400 - val_loss: 1.1027 - val_accuracy: 0.5542 - 436ms/epoch - 1ms/step\n",
      "Epoch 29/50\n",
      "314/314 - 0s - loss: 2.8536 - accuracy: 0.5478 - val_loss: 1.1244 - val_accuracy: 0.5602 - 435ms/epoch - 1ms/step\n",
      "Epoch 30/50\n",
      "314/314 - 0s - loss: 2.8882 - accuracy: 0.5401 - val_loss: 1.1007 - val_accuracy: 0.5662 - 465ms/epoch - 1ms/step\n",
      "Epoch 31/50\n",
      "314/314 - 0s - loss: 2.8665 - accuracy: 0.5478 - val_loss: 1.1024 - val_accuracy: 0.5702 - 447ms/epoch - 1ms/step\n",
      "Epoch 32/50\n",
      "314/314 - 0s - loss: 2.8347 - accuracy: 0.5470 - val_loss: 1.0975 - val_accuracy: 0.5702 - 461ms/epoch - 1ms/step\n",
      "Epoch 33/50\n",
      "314/314 - 0s - loss: 2.8574 - accuracy: 0.5473 - val_loss: 1.1038 - val_accuracy: 0.5662 - 447ms/epoch - 1ms/step\n",
      "Epoch 34/50\n",
      "314/314 - 0s - loss: 2.8493 - accuracy: 0.5439 - val_loss: 1.1251 - val_accuracy: 0.5554 - 441ms/epoch - 1ms/step\n",
      "Epoch 35/50\n",
      "314/314 - 0s - loss: 2.8212 - accuracy: 0.5511 - val_loss: 1.1120 - val_accuracy: 0.5518 - 436ms/epoch - 1ms/step\n",
      "Epoch 36/50\n",
      "314/314 - 0s - loss: 2.8266 - accuracy: 0.5486 - val_loss: 1.0881 - val_accuracy: 0.5642 - 440ms/epoch - 1ms/step\n",
      "Epoch 37/50\n",
      "314/314 - 0s - loss: 2.8184 - accuracy: 0.5478 - val_loss: 1.0838 - val_accuracy: 0.5558 - 442ms/epoch - 1ms/step\n",
      "Epoch 38/50\n",
      "314/314 - 0s - loss: 2.7984 - accuracy: 0.5562 - val_loss: 1.0960 - val_accuracy: 0.5550 - 442ms/epoch - 1ms/step\n",
      "Epoch 39/50\n",
      "314/314 - 0s - loss: 2.8381 - accuracy: 0.5479 - val_loss: 1.0931 - val_accuracy: 0.5662 - 439ms/epoch - 1ms/step\n",
      "Epoch 40/50\n",
      "314/314 - 0s - loss: 2.8009 - accuracy: 0.5558 - val_loss: 1.0578 - val_accuracy: 0.5885 - 444ms/epoch - 1ms/step\n",
      "Epoch 41/50\n",
      "314/314 - 0s - loss: 2.7808 - accuracy: 0.5602 - val_loss: 1.1167 - val_accuracy: 0.5570 - 439ms/epoch - 1ms/step\n",
      "Epoch 42/50\n",
      "314/314 - 0s - loss: 2.7764 - accuracy: 0.5563 - val_loss: 1.0841 - val_accuracy: 0.5785 - 436ms/epoch - 1ms/step\n",
      "Epoch 43/50\n",
      "314/314 - 0s - loss: 2.7622 - accuracy: 0.5665 - val_loss: 1.0836 - val_accuracy: 0.5742 - 433ms/epoch - 1ms/step\n",
      "Epoch 44/50\n",
      "314/314 - 0s - loss: 2.7436 - accuracy: 0.5707 - val_loss: 1.0838 - val_accuracy: 0.5606 - 435ms/epoch - 1ms/step\n",
      "Epoch 45/50\n",
      "314/314 - 0s - loss: 2.7651 - accuracy: 0.5601 - val_loss: 1.1222 - val_accuracy: 0.5494 - 439ms/epoch - 1ms/step\n",
      "Epoch 46/50\n",
      "314/314 - 0s - loss: 2.7401 - accuracy: 0.5612 - val_loss: 1.0707 - val_accuracy: 0.5829 - 457ms/epoch - 1ms/step\n",
      "Epoch 47/50\n",
      "314/314 - 0s - loss: 2.7675 - accuracy: 0.5602 - val_loss: 1.0747 - val_accuracy: 0.5698 - 434ms/epoch - 1ms/step\n",
      "Epoch 48/50\n",
      "314/314 - 0s - loss: 2.7715 - accuracy: 0.5581 - val_loss: 1.0663 - val_accuracy: 0.5762 - 433ms/epoch - 1ms/step\n",
      "Epoch 49/50\n",
      "314/314 - 0s - loss: 2.7368 - accuracy: 0.5741 - val_loss: 1.0422 - val_accuracy: 0.5945 - 433ms/epoch - 1ms/step\n",
      "Epoch 50/50\n",
      "314/314 - 0s - loss: 2.7539 - accuracy: 0.5637 - val_loss: 1.0885 - val_accuracy: 0.5586 - 432ms/epoch - 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Compute class weights based on the training labels\n",
    "y_train_labels = np.argmax(y_train, axis=1)  # Convert one-hot encoded labels back to class integers\n",
    "\n",
    "# Updated function call with keyword arguments\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight={0: 1.0, 1: 2.0, 2: 4.0, 3: 5.0, 4: 3.0, 5: 2.5, 6: 1.0, 7: 2.0, 8: 1.0}, \n",
    "    classes=np.unique(y_train_labels), \n",
    "    y=y_train_labels\n",
    ")\n",
    "\n",
    "# Convert to dictionary format for Keras\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "# Train the model using class weights\n",
    "history = model.fit(X_train, y_train, epochs=50, class_weight=class_weights, batch_size=32, validation_split=0.2, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235b0fdb",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "133c5909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.5375\n",
      "98/98 [==============================] - 0s 631us/step\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.83      0.33      0.47       405\n",
      "        calm       0.68      0.99      0.80       291\n",
      "     disgust       0.37      0.58      0.45       383\n",
      "        fear       0.37      0.41      0.39       388\n",
      "       happy       0.40      0.48      0.43       364\n",
      "     neutral       0.47      0.53      0.50       367\n",
      "    pleasant       0.92      0.66      0.77       283\n",
      "         sad       0.64      0.39      0.49       374\n",
      "    surprise       0.76      0.64      0.69       280\n",
      "\n",
      "    accuracy                           0.54      3135\n",
      "   macro avg       0.60      0.56      0.56      3135\n",
      "weighted avg       0.59      0.54      0.54      3135\n",
      "\n",
      "Confusion Matrix:\n",
      " [[132   6  33 109  99   6  10   0  10]\n",
      " [  0 288   2   1   0   0   0   0   0]\n",
      " [  8  17 222  11  43  41   4  27  10]\n",
      " [ 12   9  63 160  58  43   0  33  10]\n",
      " [  6   7  54  78 175  30   2   2  10]\n",
      " [  0  15  85  11  37 196   0  20   3]\n",
      " [  1   0  50  16  20   9 187   0   0]\n",
      " [  0  24  78  12  10  90   0 147  13]\n",
      " [  0  60  10  30   1   0   0   1 178]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_proba = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test_classes, y_pred, target_names=label_encoder.classes_))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_classes, y_pred))\n",
    "\n",
    "# Save the model if needed\n",
    "# model.save('emotion_classification_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4baebc44",
   "metadata": {},
   "source": [
    "#### Evaluation v7\n",
    "\n",
    "Classification Report (neural network for multiclassification):\n",
    "\n",
    "| Emotion   | Precision | Recall | F1-Score | Support |\n",
    "|-----------|-----------|--------|----------|---------|\n",
    "| angry     | 0.66      | 0.60   | 0.63     | 405     |\n",
    "| calm      | 0.74      | 0.86   | 0.79     | 291     |\n",
    "| disgust   | 0.52      | 0.30   | 0.38     | 383     |\n",
    "| fear      | 0.71      | 0.22   | 0.34     | 388     |\n",
    "| happy     | 0.39      | 0.40   | 0.39     | 364     |\n",
    "| neutral   | 0.42      | 0.57   | 0.49     | 367     |\n",
    "| pleasant  | 0.75      | 0.94   | 0.84     | 283     |\n",
    "| sad       | 0.49      | 0.59   | 0.53     | 374     |\n",
    "| surprise  | 0.58      | 0.89   | 0.70     | 280     |\n",
    "| **accuracy** |           |        | 0.57     | 3135    |\n",
    "| **macro avg** | 0.59      | 0.60   | 0.57     | 3135    |\n",
    "| **weighted avg** | 0.58      | 0.57   | 0.55     | 3135    |\n",
    "\n",
    "Not much better. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c231310",
   "metadata": {},
   "source": [
    "## Binary Classification\n",
    "\n",
    "In the most recent report, the model's performance isn't satisfactory for reliably predicting specific emotions. The weighted average precision of 0.55 and F-score of 0.54 indicate that the model struggles to accurately classify the different categories. Having a relatively small dataset of 11,802 records can limit the model's ability to learn and generalize the complex patterns  of emotional recognition in voice. \n",
    "\n",
    "Simplifying the problem into positive/negative sentiments may improve metrics. With reduced complexity, the model could better grasp underlying patterns. Larger class sizes could mitigate data scarcity issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222e45cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(clean_data))\n",
    "clean_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82779ffc",
   "metadata": {},
   "source": [
    "I'm going to consider 'neutral' as positive,\n",
    "\n",
    "    1. because we need more 'positive' emotion\n",
    "    2. because in our business problem, 'neutral' is a good thing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204a5f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a binary classification dataset\n",
    "positive_emotions = ['happy', 'pleasant', 'surprise', 'calm', 'neutral']\n",
    "negative_emotions = ['sad', 'angry', 'disgust', 'fear']\n",
    "\n",
    "eval_bin_data = clean_data.copy()\n",
    "eval_bin_data['binary_emotion'] = eval_bin_data['emotion'].apply(\n",
    "    lambda x: 1 if x in positive_emotions else 0 if x in negative_emotions else None\n",
    ")\n",
    "\n",
    "# Drop rows with 'None' binary_emotion (neutral/other emotions)\n",
    "eval_bin_data.dropna(subset=['binary_emotion'], inplace=True)\n",
    "\n",
    "# Convert 'binary_emotion' to int\n",
    "eval_bin_data['binary_emotion'] = eval_bin_data['binary_emotion'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4d4c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "eval_bin_data['emotion'] = le.fit_transform(eval_bin_data['emotion'])\n",
    "\n",
    "# Keep 'path' and 'filename' for augmentation purposes\n",
    "X = eval_bin_data.drop(['binary_emotion', 'emotion'], axis=1)\n",
    "y = eval_bin_data['binary_emotion']\n",
    "\n",
    "# Split data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f091d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augment positive samples\n",
    "positive_train_data = X_train[y_train == 1]\n",
    "current_positive_count = len(positive_train_data)\n",
    "target_positive_count = 7500\n",
    "num_augments_needed = target_positive_count - current_positive_count\n",
    "\n",
    "augmented_data = []\n",
    "for _ in range(num_augments_needed):\n",
    "    random_sample = positive_train_data.sample(n=1, random_state=42).iloc[0]\n",
    "    audio_file = os.path.join(random_sample['path'], random_sample['filename'])\n",
    "    \n",
    "    try:\n",
    "        data, sr = librosa.load(audio_file, sr=None)\n",
    "        augmented_data_sample = augment_audio(data, sr)\n",
    "\n",
    "        # Extract features and append\n",
    "        augmented_features = extract_features(augmented_data_sample, sr=sr, from_file=False)\n",
    "        if isinstance(augmented_features, (tuple, list)) and len(augmented_features) == 6:\n",
    "            augmented_data.append(augmented_features)\n",
    "        else:\n",
    "            print(f\"Invalid features for {audio_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {audio_file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01447b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for augmented features with scalar values\n",
    "augmented_df = pd.DataFrame(augmented_data, columns=[\n",
    "    'mfccs_mean', 'spectral_centroid', 'chroma', 'zero_crossing_rate', 'rms', 'pitch'\n",
    "])\n",
    "\n",
    "# Concatenate augmented data with the original positive data\n",
    "X_train_positive = X_train[y_train == 1].reset_index(drop=True).drop(['path', 'filename'], axis=1)\n",
    "X_train_aug = pd.concat([X_train_positive, augmented_df], ignore_index=True)\n",
    "\n",
    "# Combine with negative data\n",
    "X_train_negative = X_train[y_train == 0].reset_index(drop=True).drop(['path', 'filename'], axis=1)\n",
    "X_train_aug = pd.concat([X_train_negative, X_train_aug], ignore_index=True)\n",
    "y_train_aug = pd.concat([y_train[y_train == 0], pd.Series([1] * len(augmented_df))], ignore_index=True)\n",
    "\n",
    "# Make sure no sequences remain in the DataFrame (check types)\n",
    "print(X_train_aug.dtypes)\n",
    "\n",
    "# Train the model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_aug, y_train_aug)\n",
    "\n",
    "# Drop 'path' and 'filename' columns from the test set\n",
    "X_test = X_test.drop(['path', 'filename'], axis=1)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f913041",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_data['binary_emotion'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed731c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "920cba94",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Let's re-approach, and build a neural network model (which should me more appropriate for audio data!)\n",
    "\n",
    "##"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
