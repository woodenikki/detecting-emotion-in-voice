{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "632e1bdf",
   "metadata": {},
   "source": [
    "# MoodWave: Voice-Driven Emotion Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb8c87a",
   "metadata": {},
   "source": [
    "## Data Guidelines\n",
    "\n",
    "Your dataset must be:\n",
    "\n",
    "- Appropriate for classification. It should have a categorical outcome or the data needed to engineer one.\n",
    "\n",
    "- Usable to solve a specific business problem. This solution must rely on your classification model.\n",
    "\n",
    "- Somewhat complex. It should contain a minimum of 1000 rows and 10 features.\n",
    "\n",
    "- Unfamiliar. It can't be one we've already worked with during the course or that is commonly used for demonstration purposes (e.g. Titanic).\n",
    "\n",
    "- Manageable. Stick to datasets that you can model using the techniques introduced in Phase 3.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf988b2c",
   "metadata": {},
   "source": [
    "### Phase 3 Concepts used in this project:\n",
    "\n",
    "- Logistic Regression:\n",
    "\n",
    "> Logistic regression is a fundamental classification algorithm that's well-suited for binary and multiclass classification tasks. It's a good choice if your dataset has clear decision boundaries.\n",
    "\n",
    "- Decision Trees:\n",
    "\n",
    "> Decision trees are versatile and interpretable models that can handle both categorical and continuous data. They are particularly useful when you want to understand the decision-making process of your model.\n",
    "\n",
    "- Evaluation Metrics (Confusion Matrices, ROC Curves, AUC):\n",
    "\n",
    "> These metrics are essential for assessing the performance of your classification model. They will help you understand how well your model distinguishes between different emotional states.\n",
    "\n",
    "- Hyperparameter Tuning and Pruning:\n",
    "\n",
    "> When using decision trees, tuning hyperparameters and pruning are important to avoid overfitting and to ensure your model generalizes well to new data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fc11ce",
   "metadata": {},
   "source": [
    "## Creating a Dataframe\n",
    "\n",
    "Here 4 most popular datasets in English: Crema, Ravdess, Savee and Tess. Each of them contains audio in .wav format with some main labels.\n",
    "\n",
    "Because our data isn't inherinantly in a csv / dataframe format, we will have to create it from scratch!\n",
    "\n",
    "We will need to pull features from these files and store them in our own dataset:\n",
    "\n",
    "- Mel-frequency cepstral coefficients (MFCCs)\n",
    "- Spectral centroid\n",
    "- Chroma features\n",
    "- Zero-crossing rate\n",
    "- RMS energy\n",
    "- Pitch\n",
    "\n",
    "And then of course, our target feature: **Emotion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0e71dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f94a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data is zipped, and stored in folders for which dataset they came from:\n",
    "\n",
    "# Define the path to the zipped dataset\n",
    "zip_file_path = 'dataset.zip'\n",
    "extracted_folder_path = 'dataset'\n",
    "\n",
    "# Unzip the dataset\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extracted_folder_path)\n",
    "\n",
    "# Crema\n",
    "# Ravdess\n",
    "# Savee\n",
    "# Tess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf8dd542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              filename  emotion           path\n",
      "0  1001_DFA_ANG_XX.wav    angry  dataset\\Crema\n",
      "1  1001_DFA_DIS_XX.wav  disgust  dataset\\Crema\n",
      "2  1001_DFA_FEA_XX.wav     fear  dataset\\Crema\n",
      "3  1001_DFA_HAP_XX.wav    happy  dataset\\Crema\n",
      "4  1001_DFA_NEU_XX.wav  neutral  dataset\\Crema\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the Crema folder\n",
    "crema_folder_path = os.path.join(extracted_folder_path, 'Crema')\n",
    "\n",
    "# Verify that we can access the files and extract emotion labels\n",
    "data = []\n",
    "\n",
    "# Loop through each file in the Crema folder\n",
    "for file_name in os.listdir(crema_folder_path):\n",
    "    if file_name.endswith('.wav'):\n",
    "        # Extract the emotion label from the filename\n",
    "        parts = file_name.split('_')\n",
    "        emotion_code = parts[2]\n",
    "        \n",
    "        # Map the emotion code to the actual emotion label\n",
    "        emotion_map = {\n",
    "            'SAD': 'sadness',\n",
    "            'ANG': 'angry',\n",
    "            'DIS': 'disgust',\n",
    "            'FEA': 'fear',\n",
    "            'HAP': 'happy',\n",
    "            'NEU': 'neutral'\n",
    "        }\n",
    "        emotion_label = emotion_map.get(emotion_code, 'unknown')\n",
    "        \n",
    "        # Store the data with the directory path minus the filename\n",
    "        data.append({'filename': file_name, 'emotion': emotion_label, 'path': crema_folder_path})\n",
    "\n",
    "# Convert the data into a DataFrame for easy access\n",
    "df_crema = pd.DataFrame(data)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(df_crema.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9bc42fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             filename emotion                    path\n",
      "0  OAF_back_angry.wav   angry  dataset\\Tess\\OAF_angry\n",
      "1   OAF_bar_angry.wav   angry  dataset\\Tess\\OAF_angry\n",
      "2  OAF_base_angry.wav   angry  dataset\\Tess\\OAF_angry\n",
      "3  OAF_bath_angry.wav   angry  dataset\\Tess\\OAF_angry\n",
      "4  OAF_bean_angry.wav   angry  dataset\\Tess\\OAF_angry\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the Tess folder\n",
    "tess_folder_path = os.path.join(extracted_folder_path, 'Tess')\n",
    "\n",
    "# Prepare to store the data\n",
    "data = []\n",
    "\n",
    "# Loop through each emotion folder in the Tess directory\n",
    "for emotion_folder in os.listdir(tess_folder_path):\n",
    "    # Get the full path to the emotion folder\n",
    "    emotion_folder_path = os.path.join(tess_folder_path, emotion_folder)\n",
    "    \n",
    "    # Extract the emotion from the folder name (e.g., \"OAF_angry\" -> \"angry\")\n",
    "    emotion_label = emotion_folder.split('_')[1]\n",
    "    \n",
    "    # Loop through each file in the emotion folder\n",
    "    for file_name in os.listdir(emotion_folder_path):\n",
    "        if file_name.endswith('.wav'):\n",
    "            # Store the data with the directory path minus the filename\n",
    "            data.append({\n",
    "                'filename': file_name, \n",
    "                'emotion': emotion_label, \n",
    "                'path': emotion_folder_path\n",
    "            })\n",
    "\n",
    "# Convert the data into a DataFrame for easy access\n",
    "df_tess = pd.DataFrame(data)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(df_tess.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "461d863e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     filename  emotion           path\n",
      "0  DC_a01.wav  unknown  dataset\\Savee\n",
      "1  DC_a02.wav  unknown  dataset\\Savee\n",
      "2  DC_a03.wav  unknown  dataset\\Savee\n",
      "3  DC_a04.wav  unknown  dataset\\Savee\n",
      "4  DC_a05.wav  unknown  dataset\\Savee\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the Savee folder\n",
    "savee_folder_path = os.path.join(extracted_folder_path, 'Savee')\n",
    "\n",
    "# Prepare to store the data\n",
    "data = []\n",
    "\n",
    "# Define the emotion mapping based on the prefixes\n",
    "emotion_map = {\n",
    "    'a': 'anger',\n",
    "    'd': 'disgust',\n",
    "    'f': 'fear',\n",
    "    'h': 'happiness',\n",
    "    'n': 'neutral',\n",
    "    'sa': 'sadness',\n",
    "    'su': 'surprise'\n",
    "}\n",
    "\n",
    "# Loop through each file in the Savee folder\n",
    "for file_name in os.listdir(savee_folder_path):\n",
    "    if file_name.endswith('.wav'):\n",
    "        # Extract the prefix from the filename to determine the emotion\n",
    "        prefix = file_name.split('_')[1][:2]\n",
    "        \n",
    "        # Map the prefix to the corresponding emotion\n",
    "        emotion_label = emotion_map.get(prefix, 'unknown')\n",
    "        \n",
    "        # Store the data with the directory path minus the filename\n",
    "        data.append({\n",
    "            'filename': file_name, \n",
    "            'emotion': emotion_label, \n",
    "            'path': savee_folder_path\n",
    "        })\n",
    "\n",
    "# Convert the data into a DataFrame for easy access\n",
    "df_savee = pd.DataFrame(data)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(df_savee.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12fa923d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   filename  emotion  \\\n",
      "0  03-01-01-01-01-01-01.wav  neutral   \n",
      "1  03-01-01-01-01-02-01.wav  neutral   \n",
      "2  03-01-01-01-02-01-01.wav  neutral   \n",
      "3  03-01-01-01-02-02-01.wav  neutral   \n",
      "4  03-01-02-01-01-01-01.wav     calm   \n",
      "\n",
      "                                                path  \n",
      "0  dataset\\Ravdess\\audio_speech_actors_01-24\\Acto...  \n",
      "1  dataset\\Ravdess\\audio_speech_actors_01-24\\Acto...  \n",
      "2  dataset\\Ravdess\\audio_speech_actors_01-24\\Acto...  \n",
      "3  dataset\\Ravdess\\audio_speech_actors_01-24\\Acto...  \n",
      "4  dataset\\Ravdess\\audio_speech_actors_01-24\\Acto...  \n"
     ]
    }
   ],
   "source": [
    "# Define the path to the Ravdess folder\n",
    "ravdess_folder_path = os.path.join(extracted_folder_path, 'Ravdess', 'audio_speech_actors_01-24')\n",
    "\n",
    "# Prepare to store the data\n",
    "data = []\n",
    "\n",
    "# Define the emotion mapping based on the third component in the filename\n",
    "emotion_map = {\n",
    "    '01': 'neutral',\n",
    "    '02': 'calm',\n",
    "    '03': 'happy',\n",
    "    '04': 'sad',\n",
    "    '05': 'angry',\n",
    "    '06': 'fearful',\n",
    "    '07': 'disgust',\n",
    "    '08': 'surprised'\n",
    "}\n",
    "\n",
    "# Loop through each actor's folder in the Ravdess directory\n",
    "for actor_folder in os.listdir(ravdess_folder_path):\n",
    "    actor_folder_path = os.path.join(ravdess_folder_path, actor_folder)\n",
    "    \n",
    "    # Loop through each file in the actor's folder\n",
    "    for file_name in os.listdir(actor_folder_path):\n",
    "        if file_name.endswith('.wav'):\n",
    "            # Extract the third component from the filename to determine the emotion\n",
    "            emotion_code = file_name.split('-')[2]\n",
    "            \n",
    "            # Map the emotion code to the corresponding emotion label\n",
    "            emotion_label = emotion_map.get(emotion_code, 'unknown')\n",
    "            \n",
    "            # Store the data with the directory path minus the filename\n",
    "            data.append({\n",
    "                'filename': file_name, \n",
    "                'emotion': emotion_label, \n",
    "                'path': actor_folder_path\n",
    "            })\n",
    "\n",
    "# Convert the data into a DataFrame for easy access\n",
    "df_ravdess = pd.DataFrame(data)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(df_ravdess.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887a3a67",
   "metadata": {},
   "source": [
    "### combining datasets \n",
    "\n",
    "We will merge the datsets into one dataframe, and assign unique identifiers\n",
    "- Concatenate the DataFrames for each dataset.\n",
    "- Assign a unique ID to each entry based on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b25525ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id             filename  emotion           path\n",
      "0  c_0001  1001_DFA_ANG_XX.wav    angry  dataset\\Crema\n",
      "1  c_0002  1001_DFA_DIS_XX.wav  disgust  dataset\\Crema\n",
      "2  c_0003  1001_DFA_FEA_XX.wav     fear  dataset\\Crema\n",
      "3  c_0004  1001_DFA_HAP_XX.wav    happy  dataset\\Crema\n",
      "4  c_0005  1001_DFA_NEU_XX.wav  neutral  dataset\\Crema\n"
     ]
    }
   ],
   "source": [
    "# Add a unique ID column to each dataset\n",
    "df_crema['id'] = ['c_{:04d}'.format(i + 1) for i in range(len(df_crema))]\n",
    "df_tess['id'] = ['t_{:04d}'.format(i + 1) for i in range(len(df_tess))]\n",
    "df_savee['id'] = ['s_{:04d}'.format(i + 1) for i in range(len(df_savee))]\n",
    "df_ravdess['id'] = ['r_{:04d}'.format(i + 1) for i in range(len(df_ravdess))]\n",
    "\n",
    "# Merge the datasets into a single DataFrame\n",
    "merged_data = pd.concat([df_crema, df_tess, df_savee, df_ravdess], ignore_index=True)\n",
    "\n",
    "# Reorder columns to have 'id' as the first column\n",
    "merged_data = combined_df[['id', 'filename', 'emotion', 'path']]\n",
    "\n",
    "# Display the first few rows of the combined DataFrame\n",
    "print(merged_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36e2d5a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12162"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ea4649",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
