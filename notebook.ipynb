{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee8e963c",
   "metadata": {},
   "source": [
    "# MoodWave: Voice-Driven Emotion Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273d2960",
   "metadata": {},
   "source": [
    "## Data Guidelines\n",
    "\n",
    "Your dataset must be:\n",
    "\n",
    "- Appropriate for classification. It should have a categorical outcome or the data needed to engineer one.\n",
    "\n",
    "- Usable to solve a specific business problem. This solution must rely on your classification model.\n",
    "\n",
    "- Somewhat complex. It should contain a minimum of 1000 rows and 10 features.\n",
    "\n",
    "- Unfamiliar. It can't be one we've already worked with during the course or that is commonly used for demonstration purposes (e.g. Titanic).\n",
    "\n",
    "- Manageable. Stick to datasets that you can model using the techniques introduced in Phase 3.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fe5cff",
   "metadata": {},
   "source": [
    "### Phase 3 Concepts used in this project:\n",
    "\n",
    "- Logistic Regression:\n",
    "\n",
    "> Logistic regression is a fundamental classification algorithm that's well-suited for binary and multiclass classification tasks. It's a good choice if your dataset has clear decision boundaries.\n",
    "\n",
    "- Decision Trees:\n",
    "\n",
    "> Decision trees are versatile and interpretable models that can handle both categorical and continuous data. They are particularly useful when you want to understand the decision-making process of your model.\n",
    "\n",
    "- Evaluation Metrics (Confusion Matrices, ROC Curves, AUC):\n",
    "\n",
    "> These metrics are essential for assessing the performance of your classification model. They will help you understand how well your model distinguishes between different emotional states.\n",
    "\n",
    "- Hyperparameter Tuning and Pruning:\n",
    "\n",
    "> When using decision trees, tuning hyperparameters and pruning are important to avoid overfitting and to ensure your model generalizes well to new data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16019831",
   "metadata": {},
   "source": [
    "## Data Preperation\n",
    "\n",
    "Here 4 most popular datasets in English: Crema, Ravdess, Savee and Tess. Each of them contains audio in .wav format with some main labels.\n",
    "\n",
    "Because our data isn't inherinantly in a csv / dataframe format, we will have to create it from scratch!\n",
    "\n",
    "First, we will pull all data into their own dataframe, making note of *where* the file is, so we can pull our features from each audio file:\n",
    "\n",
    "- Mel-frequency cepstral coefficients (MFCCs)\n",
    "- Spectral centroid\n",
    "- Chroma features\n",
    "- Zero-crossing rate\n",
    "- RMS energy\n",
    "- Pitch\n",
    "\n",
    "And then of course, our target feature: **Emotion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ead1716",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import zipfile\n",
    "import librosa\n",
    "import random\n",
    "import os\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import resample\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b6f9ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data is zipped, and stored in folders for which dataset they came from:\n",
    "\n",
    "# Define the path to the zipped dataset\n",
    "zip_file_path = 'dataset.zip'\n",
    "extracted_folder_path = 'dataset'\n",
    "\n",
    "# Unzip the dataset\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extracted_folder_path)\n",
    "\n",
    "# Crema\n",
    "# Ravdess\n",
    "# Savee\n",
    "# Tess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "977b7a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              filename  emotion           path\n",
      "0  1001_DFA_ANG_XX.wav    angry  dataset\\Crema\n",
      "1  1001_DFA_DIS_XX.wav  disgust  dataset\\Crema\n",
      "2  1001_DFA_FEA_XX.wav     fear  dataset\\Crema\n",
      "3  1001_DFA_HAP_XX.wav    happy  dataset\\Crema\n",
      "4  1001_DFA_NEU_XX.wav  neutral  dataset\\Crema\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the Crema folder\n",
    "crema_folder_path = os.path.join(extracted_folder_path, 'Crema')\n",
    "\n",
    "# Verify that we can access the files and extract emotion labels\n",
    "data = []\n",
    "\n",
    "# Loop through each file in the Crema folder\n",
    "for file_name in os.listdir(crema_folder_path):\n",
    "    if file_name.endswith('.wav'):\n",
    "        # Extract the emotion label from the filename\n",
    "        parts = file_name.split('_')\n",
    "        emotion_code = parts[2]\n",
    "        \n",
    "        # Map the emotion code to the actual emotion label\n",
    "        emotion_map = {\n",
    "            'SAD': 'sadness',\n",
    "            'ANG': 'angry',\n",
    "            'DIS': 'disgust',\n",
    "            'FEA': 'fear',\n",
    "            'HAP': 'happy',\n",
    "            'NEU': 'neutral'\n",
    "        }\n",
    "        emotion_label = emotion_map.get(emotion_code, 'unknown')\n",
    "        \n",
    "        # Store the data with the directory path minus the filename\n",
    "        data.append({'filename': file_name, 'emotion': emotion_label, 'path': crema_folder_path})\n",
    "\n",
    "# Convert the data into a DataFrame for easy access\n",
    "df_crema = pd.DataFrame(data)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(df_crema.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f312be8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             filename emotion                    path\n",
      "0  OAF_back_angry.wav   angry  dataset\\Tess\\OAF_angry\n",
      "1   OAF_bar_angry.wav   angry  dataset\\Tess\\OAF_angry\n",
      "2  OAF_base_angry.wav   angry  dataset\\Tess\\OAF_angry\n",
      "3  OAF_bath_angry.wav   angry  dataset\\Tess\\OAF_angry\n",
      "4  OAF_bean_angry.wav   angry  dataset\\Tess\\OAF_angry\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the Tess folder\n",
    "tess_folder_path = os.path.join(extracted_folder_path, 'Tess')\n",
    "\n",
    "# Prepare to store the data\n",
    "data = []\n",
    "\n",
    "# Loop through each emotion folder in the Tess directory\n",
    "for emotion_folder in os.listdir(tess_folder_path):\n",
    "    # Get the full path to the emotion folder\n",
    "    emotion_folder_path = os.path.join(tess_folder_path, emotion_folder)\n",
    "    \n",
    "    # Extract the emotion from the folder name (e.g., \"OAF_angry\" -> \"angry\")\n",
    "    emotion_label = emotion_folder.split('_')[1]\n",
    "    \n",
    "    # Loop through each file in the emotion folder\n",
    "    for file_name in os.listdir(emotion_folder_path):\n",
    "        if file_name.endswith('.wav'):\n",
    "            # Store the data with the directory path minus the filename\n",
    "            data.append({\n",
    "                'filename': file_name, \n",
    "                'emotion': emotion_label, \n",
    "                'path': emotion_folder_path\n",
    "            })\n",
    "\n",
    "# Convert the data into a DataFrame for easy access\n",
    "df_tess = pd.DataFrame(data)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(df_tess.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28fbe0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     filename  emotion           path\n",
      "0  DC_a01.wav  unknown  dataset\\Savee\n",
      "1  DC_a02.wav  unknown  dataset\\Savee\n",
      "2  DC_a03.wav  unknown  dataset\\Savee\n",
      "3  DC_a04.wav  unknown  dataset\\Savee\n",
      "4  DC_a05.wav  unknown  dataset\\Savee\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the Savee folder\n",
    "savee_folder_path = os.path.join(extracted_folder_path, 'Savee')\n",
    "\n",
    "# Prepare to store the data\n",
    "data = []\n",
    "\n",
    "# Define the emotion mapping based on the prefixes\n",
    "emotion_map = {\n",
    "    'a': 'anger',\n",
    "    'd': 'disgust',\n",
    "    'f': 'fear',\n",
    "    'h': 'happiness',\n",
    "    'n': 'neutral',\n",
    "    'sa': 'sadness',\n",
    "    'su': 'surprise'\n",
    "}\n",
    "\n",
    "# Loop through each file in the Savee folder\n",
    "for file_name in os.listdir(savee_folder_path):\n",
    "    if file_name.endswith('.wav'):\n",
    "        # Extract the prefix from the filename to determine the emotion\n",
    "        prefix = file_name.split('_')[1][:2]\n",
    "        \n",
    "        # Map the prefix to the corresponding emotion\n",
    "        emotion_label = emotion_map.get(prefix, 'unknown')\n",
    "        \n",
    "        # Store the data with the directory path minus the filename\n",
    "        data.append({\n",
    "            'filename': file_name, \n",
    "            'emotion': emotion_label, \n",
    "            'path': savee_folder_path\n",
    "        })\n",
    "\n",
    "# Convert the data into a DataFrame for easy access\n",
    "df_savee = pd.DataFrame(data)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(df_savee.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47d8e747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   filename  emotion  \\\n",
      "0  03-01-01-01-01-01-01.wav  neutral   \n",
      "1  03-01-01-01-01-02-01.wav  neutral   \n",
      "2  03-01-01-01-02-01-01.wav  neutral   \n",
      "3  03-01-01-01-02-02-01.wav  neutral   \n",
      "4  03-01-02-01-01-01-01.wav     calm   \n",
      "\n",
      "                                                path  \n",
      "0  dataset\\Ravdess\\audio_speech_actors_01-24\\Acto...  \n",
      "1  dataset\\Ravdess\\audio_speech_actors_01-24\\Acto...  \n",
      "2  dataset\\Ravdess\\audio_speech_actors_01-24\\Acto...  \n",
      "3  dataset\\Ravdess\\audio_speech_actors_01-24\\Acto...  \n",
      "4  dataset\\Ravdess\\audio_speech_actors_01-24\\Acto...  \n"
     ]
    }
   ],
   "source": [
    "# Define the path to the Ravdess folder\n",
    "ravdess_folder_path = os.path.join(extracted_folder_path, 'Ravdess', 'audio_speech_actors_01-24')\n",
    "\n",
    "# Prepare to store the data\n",
    "data = []\n",
    "\n",
    "# Define the emotion mapping based on the third component in the filename\n",
    "emotion_map = {\n",
    "    '01': 'neutral',\n",
    "    '02': 'calm',\n",
    "    '03': 'happy',\n",
    "    '04': 'sad',\n",
    "    '05': 'angry',\n",
    "    '06': 'fearful',\n",
    "    '07': 'disgust',\n",
    "    '08': 'surprised'\n",
    "}\n",
    "\n",
    "# Loop through each actor's folder in the Ravdess directory\n",
    "for actor_folder in os.listdir(ravdess_folder_path):\n",
    "    actor_folder_path = os.path.join(ravdess_folder_path, actor_folder)\n",
    "    \n",
    "    # Loop through each file in the actor's folder\n",
    "    for file_name in os.listdir(actor_folder_path):\n",
    "        if file_name.endswith('.wav'):\n",
    "            # Extract the third component from the filename to determine the emotion\n",
    "            emotion_code = file_name.split('-')[2]\n",
    "            \n",
    "            # Map the emotion code to the corresponding emotion label\n",
    "            emotion_label = emotion_map.get(emotion_code, 'unknown')\n",
    "            \n",
    "            # Store the data with the directory path minus the filename\n",
    "            data.append({\n",
    "                'filename': file_name, \n",
    "                'emotion': emotion_label, \n",
    "                'path': actor_folder_path\n",
    "            })\n",
    "\n",
    "# Convert the data into a DataFrame for easy access\n",
    "df_ravdess = pd.DataFrame(data)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(df_ravdess.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dccdb8c",
   "metadata": {},
   "source": [
    "### Combining datasets \n",
    "\n",
    "We will merge the datsets into one dataframe, and assign unique identifiers\n",
    "- Concatenate the DataFrames for each dataset.\n",
    "- Assign a unique ID to each entry based on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1f9600c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id             filename  emotion           path\n",
      "0  c_0001  1001_DFA_ANG_XX.wav    angry  dataset\\Crema\n",
      "1  c_0002  1001_DFA_DIS_XX.wav  disgust  dataset\\Crema\n",
      "2  c_0003  1001_DFA_FEA_XX.wav     fear  dataset\\Crema\n",
      "3  c_0004  1001_DFA_HAP_XX.wav    happy  dataset\\Crema\n",
      "4  c_0005  1001_DFA_NEU_XX.wav  neutral  dataset\\Crema\n"
     ]
    }
   ],
   "source": [
    "# Add a unique ID column to each dataset\n",
    "df_crema['id'] = ['c_{:04d}'.format(i + 1) for i in range(len(df_crema))]\n",
    "df_tess['id'] = ['t_{:04d}'.format(i + 1) for i in range(len(df_tess))]\n",
    "df_savee['id'] = ['s_{:04d}'.format(i + 1) for i in range(len(df_savee))]\n",
    "df_ravdess['id'] = ['r_{:04d}'.format(i + 1) for i in range(len(df_ravdess))]\n",
    "\n",
    "# Merge the datasets into a single DataFrame\n",
    "merged_data = pd.concat([df_crema, df_tess, df_savee, df_ravdess], ignore_index=True)\n",
    "\n",
    "# Reorder columns to have 'id' as the first column\n",
    "merged_data = merged_data[['id', 'filename', 'emotion', 'path']]\n",
    "\n",
    "# Display the first few rows of the combined DataFrame\n",
    "print(merged_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "083504fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in dataset: 12162\n"
     ]
    }
   ],
   "source": [
    "# remember, we need at least 1000 rows to meet our requirements. \n",
    "print(f\"Total rows in dataset: {merged_data.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ec3b5d",
   "metadata": {},
   "source": [
    "### Extracting Features\n",
    "\n",
    "Again, these are the features we will extract:\n",
    "\n",
    "- **Mel-frequency cepstral coefficients (MFCCs):** Represents the short-term power spectrum of sound, commonly used in speech and audio processing to capture the timbral texture of audio.\n",
    "- **Spectral centroid:** Indicates the \"center of mass\" of the spectrum and is often associated with the perceived brightness of a sound.\n",
    "- **Chroma features:** Represents the 12 different pitch classes and captures harmonic and melodic characteristics of music / voice.\n",
    "- **Zero-crossing rate:** Measures the rate at which the signal changes sign, giving insight into the noisiness or percussiveness of the sound.\n",
    "- **RMS energy:** Reflects the root mean square of the audio signal and indicates the energy or loudness of the sound.\n",
    "- **Pitch:** Refers to the perceived frequency of a sound, determining how high or low a sound is.\n",
    "\n",
    "We will be using the `librosa` package to process these audio features. [Here](https://librosa.org/doc/latest/index.html) is a link to the librosa documentation.\n",
    "\n",
    "**Note**: adding suppression for *UserWarning: Trying to estimate tuning from empty frequency set*. This is likely do to either:* **silence / low energy** (too quiet to perform reliable pitch estimation), or the file had **too short of a duration**. This warning shows up even when setting the pitch to 0 in this case.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ab7d18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(data, sr=None, from_file=True):\n",
    "    if from_file:\n",
    "        # If data is a file path, load the audio file\n",
    "        y, sr = librosa.load(data, sr=sr)\n",
    "    else:\n",
    "        # If data is already an audio array\n",
    "        y = data\n",
    "\n",
    "    # Check if the audio is empty\n",
    "    if len(y) == 0:\n",
    "        print(f\"Warning: The file {data} is empty.\")\n",
    "        return (np.nan, np.nan, np.nan, np.nan, np.nan, np.nan)\n",
    "\n",
    "    # Extract features\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    mfccs_mean = np.mean(mfccs.T, axis=0)\n",
    "\n",
    "    spectral_centroid = np.mean(librosa.feature.spectral_centroid(y=y, sr=sr).T, axis=0)\n",
    "    chroma = np.mean(librosa.feature.chroma_stft(y=y, sr=sr).T, axis=0)\n",
    "    zero_crossing_rate = np.mean(librosa.feature.zero_crossing_rate(y).T, axis=0)\n",
    "    rms = np.mean(librosa.feature.rms(y=y).T, axis=0)\n",
    "\n",
    "    pitches, magnitudes = librosa.piptrack(y=y, sr=sr)\n",
    "    pitch = np.mean(pitches[pitches > 0]) if np.any(pitches > 0) else np.nan\n",
    "\n",
    "    # Return the features\n",
    "    return (mfccs_mean, spectral_centroid, chroma, zero_crossing_rate, rms, pitch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13eeb6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCCs Mean: [-306.0274       92.670235      8.491312     23.965403      7.4779935\n",
      "   -5.759455    -11.883088     -9.676736     -3.9967465   -13.352565\n",
      "    0.40819725   -9.709486     -6.1271243 ]\n",
      "Spectral Centroid: [1584.99307033]\n",
      "Chroma Features: [0.37491405 0.37949282 0.41722107 0.39018238 0.4148401  0.2977837\n",
      " 0.28898865 0.3575554  0.35190624 0.42918485 0.6879576  0.5454907 ]\n",
      "Zero-Crossing Rate: [0.10186768]\n",
      "RMS Energy: [0.04198619]\n",
      "Pitch: 1211.9507\n"
     ]
    }
   ],
   "source": [
    "# testing our extract_features function:\n",
    "first_row = merged_data.iloc[0]\n",
    "file_path = os.path.join(first_row['path'], first_row['filename'])\n",
    "\n",
    "# Extract features directly from the file path\n",
    "features = extract_features(file_path)\n",
    "\n",
    "# Print out each feature with its corresponding values\n",
    "print(\"MFCCs Mean:\", features[0])\n",
    "print(\"Spectral Centroid:\", features[1])\n",
    "print(\"Chroma Features:\", features[2])\n",
    "print(\"Zero-Crossing Rate:\", features[3])\n",
    "print(\"RMS Energy:\", features[4])\n",
    "print(\"Pitch:\", features[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f041f20",
   "metadata": {},
   "source": [
    "### Validating the Values:\n",
    "\n",
    "- **MFCCs:** Typically, MFCC values range from -400 to 400, depending on the scale of the input signal.\n",
    "> All values: **pass**\n",
    "\n",
    "- **Spectral Centroid:** This value represents the \"center of mass\" of the spectrum and typically ranges between 0 and the - Nyquist frequency (half the sampling rate).\n",
    "> 1584.99: **pass**\n",
    "\n",
    "- **Chroma Features:** These represent the energy distribution across 12 pitch classes. They are normalized, so values between 0 and 1 are expected.\n",
    "> All values: **pass**\n",
    "\n",
    "- **Zero-Crossing Rate:** This rate indicates how frequently the signal changes sign. It ranges from 0 to 1. \n",
    "> 0.1018: **pass**\n",
    "\n",
    "- **RMS Energy:** This value should be within the range of 0 to 1 for normalized signals.\n",
    "> 0.0419: **pass**\n",
    "\n",
    "- **Pitch:** Pitch values are measured in Hz, and depends on the type of audio.\n",
    "> 1211.95: **pass**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee2b878",
   "metadata": {},
   "source": [
    "Now that we've validated our extract_features function, we can apply it to the rest of our dataframe.\n",
    "\n",
    "**Notes**: \n",
    "- This cell can take a while to run! About 5 minutes\n",
    "- suppressed UserWarning: Trying to estimate tuning from empty frequency set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "603617a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\Anaconda\\envs\\learn-env\\lib\\site-packages\\librosa\\core\\pitch.py:101: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return pitch_tuning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                    0\n",
      "filename              0\n",
      "emotion               0\n",
      "path                  0\n",
      "mfccs                 0\n",
      "spectral_centroid     0\n",
      "chroma                0\n",
      "zero_crossing_rate    0\n",
      "rms                   0\n",
      "pitch                 1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Empty lists to store features\n",
    "mfccs_mean_list = []\n",
    "spectral_centroid_list = []\n",
    "chroma_list = []\n",
    "zero_crossing_rate_list = []\n",
    "rms_list = []\n",
    "pitch_list = []\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for index, row in merged_data.iterrows():\n",
    "    file_path = os.path.join(row['path'], row['filename'])  # Construct the file path\n",
    "    \n",
    "    # Extract features directly from the file path\n",
    "    features = extract_features(file_path)\n",
    "    \n",
    "    # Append the features to their respective lists\n",
    "    mfccs_mean_list.append(features[0])\n",
    "    spectral_centroid_list.append(features[1])\n",
    "    chroma_list.append(features[2])\n",
    "    zero_crossing_rate_list.append(features[3])\n",
    "    rms_list.append(features[4])\n",
    "    pitch_list.append(features[5])\n",
    "\n",
    "# Add the features to the DataFrame\n",
    "merged_data['mfccs'] = mfccs_mean_list\n",
    "merged_data['spectral_centroid'] = spectral_centroid_list\n",
    "merged_data['chroma'] = chroma_list\n",
    "merged_data['zero_crossing_rate'] = zero_crossing_rate_list\n",
    "merged_data['rms'] = rms_list\n",
    "merged_data['pitch'] = pitch_list\n",
    "\n",
    "# Check for any NaN values in the DataFrame\n",
    "print(merged_data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bf6504e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>filename</th>\n",
       "      <th>emotion</th>\n",
       "      <th>path</th>\n",
       "      <th>mfccs</th>\n",
       "      <th>spectral_centroid</th>\n",
       "      <th>chroma</th>\n",
       "      <th>zero_crossing_rate</th>\n",
       "      <th>rms</th>\n",
       "      <th>pitch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c_0001</td>\n",
       "      <td>1001_DFA_ANG_XX.wav</td>\n",
       "      <td>angry</td>\n",
       "      <td>dataset\\Crema</td>\n",
       "      <td>[-306.0274, 92.670235, 8.491312, 23.965403, 7....</td>\n",
       "      <td>[1584.9930703294388]</td>\n",
       "      <td>[0.37491405, 0.37949282, 0.41722107, 0.3901823...</td>\n",
       "      <td>[0.10186767578125]</td>\n",
       "      <td>[0.041986194]</td>\n",
       "      <td>1211.950684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c_0002</td>\n",
       "      <td>1001_DFA_DIS_XX.wav</td>\n",
       "      <td>disgust</td>\n",
       "      <td>dataset\\Crema</td>\n",
       "      <td>[-346.39963, 95.83912, 10.516282, 31.619215, 1...</td>\n",
       "      <td>[1531.650486749737]</td>\n",
       "      <td>[0.47289878, 0.4768195, 0.33598945, 0.34610763...</td>\n",
       "      <td>[0.09306105522260275]</td>\n",
       "      <td>[0.015996357]</td>\n",
       "      <td>1256.617188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c_0003</td>\n",
       "      <td>1001_DFA_FEA_XX.wav</td>\n",
       "      <td>fear</td>\n",
       "      <td>dataset\\Crema</td>\n",
       "      <td>[-321.42026, 94.76091, 8.155397, 23.323242, 11...</td>\n",
       "      <td>[1489.0888388536061]</td>\n",
       "      <td>[0.3272673, 0.39935032, 0.35215598, 0.38248017...</td>\n",
       "      <td>[0.08428596047794118]</td>\n",
       "      <td>[0.045776337]</td>\n",
       "      <td>992.574402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c_0004</td>\n",
       "      <td>1001_DFA_HAP_XX.wav</td>\n",
       "      <td>happy</td>\n",
       "      <td>dataset\\Crema</td>\n",
       "      <td>[-303.30374, 92.52889, 4.231231, 27.970133, 10...</td>\n",
       "      <td>[1555.37603547111]</td>\n",
       "      <td>[0.3150873, 0.31478375, 0.30918238, 0.3423785,...</td>\n",
       "      <td>[0.0848781779661017]</td>\n",
       "      <td>[0.042300183]</td>\n",
       "      <td>1102.953003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c_0005</td>\n",
       "      <td>1001_DFA_NEU_XX.wav</td>\n",
       "      <td>neutral</td>\n",
       "      <td>dataset\\Crema</td>\n",
       "      <td>[-335.4959, 100.39331, 9.384935, 30.160904, 11...</td>\n",
       "      <td>[1495.3949968411737]</td>\n",
       "      <td>[0.4112704, 0.36269408, 0.3349767, 0.32547352,...</td>\n",
       "      <td>[0.08203125]</td>\n",
       "      <td>[0.020449637]</td>\n",
       "      <td>1041.093628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id             filename  emotion           path  \\\n",
       "0  c_0001  1001_DFA_ANG_XX.wav    angry  dataset\\Crema   \n",
       "1  c_0002  1001_DFA_DIS_XX.wav  disgust  dataset\\Crema   \n",
       "2  c_0003  1001_DFA_FEA_XX.wav     fear  dataset\\Crema   \n",
       "3  c_0004  1001_DFA_HAP_XX.wav    happy  dataset\\Crema   \n",
       "4  c_0005  1001_DFA_NEU_XX.wav  neutral  dataset\\Crema   \n",
       "\n",
       "                                               mfccs     spectral_centroid  \\\n",
       "0  [-306.0274, 92.670235, 8.491312, 23.965403, 7....  [1584.9930703294388]   \n",
       "1  [-346.39963, 95.83912, 10.516282, 31.619215, 1...   [1531.650486749737]   \n",
       "2  [-321.42026, 94.76091, 8.155397, 23.323242, 11...  [1489.0888388536061]   \n",
       "3  [-303.30374, 92.52889, 4.231231, 27.970133, 10...    [1555.37603547111]   \n",
       "4  [-335.4959, 100.39331, 9.384935, 30.160904, 11...  [1495.3949968411737]   \n",
       "\n",
       "                                              chroma     zero_crossing_rate  \\\n",
       "0  [0.37491405, 0.37949282, 0.41722107, 0.3901823...     [0.10186767578125]   \n",
       "1  [0.47289878, 0.4768195, 0.33598945, 0.34610763...  [0.09306105522260275]   \n",
       "2  [0.3272673, 0.39935032, 0.35215598, 0.38248017...  [0.08428596047794118]   \n",
       "3  [0.3150873, 0.31478375, 0.30918238, 0.3423785,...   [0.0848781779661017]   \n",
       "4  [0.4112704, 0.36269408, 0.3349767, 0.32547352,...           [0.08203125]   \n",
       "\n",
       "             rms        pitch  \n",
       "0  [0.041986194]  1211.950684  \n",
       "1  [0.015996357]  1256.617188  \n",
       "2  [0.045776337]   992.574402  \n",
       "3  [0.042300183]  1102.953003  \n",
       "4  [0.020449637]  1041.093628  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data['pitch'] = merged_data['pitch'].fillna(0)\n",
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b7c712",
   "metadata": {},
   "source": [
    "We won't be able to work with arrays - we will need to extract a meaningful metric and save them in a new column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66860056",
   "metadata": {},
   "source": [
    "### Cleaning the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e845995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mfccs_mean  spectral_centroid    chroma  zero_crossing_rate       rms  \\\n",
      "0  -17.963037        1584.993070  0.411293            0.101868  0.041986   \n",
      "1  -18.657297        1531.650487  0.423961            0.093061  0.015996   \n",
      "2  -18.552622        1489.088839  0.413398            0.084286  0.045776   \n",
      "3  -18.460817        1555.376035  0.394820            0.084878  0.042300   \n",
      "4  -18.111607        1495.394997  0.401279            0.082031  0.020450   \n",
      "\n",
      "         pitch           path             filename  emotion  \n",
      "0  1211.950684  dataset\\Crema  1001_DFA_ANG_XX.wav    angry  \n",
      "1  1256.617188  dataset\\Crema  1001_DFA_DIS_XX.wav  disgust  \n",
      "2   992.574402  dataset\\Crema  1001_DFA_FEA_XX.wav     fear  \n",
      "3  1102.953003  dataset\\Crema  1001_DFA_HAP_XX.wav    happy  \n",
      "4  1041.093628  dataset\\Crema  1001_DFA_NEU_XX.wav  neutral  \n"
     ]
    }
   ],
   "source": [
    "# Create a new DataFrame for the cleaned features\n",
    "clean_data = pd.DataFrame()\n",
    "\n",
    "# Store the mean of array values and existing values for non-array columns\n",
    "clean_data['mfccs_mean'] = merged_data['mfccs'].apply(lambda x: np.mean(x) if isinstance(x, (list, np.ndarray)) and len(x) > 0 else np.nan)\n",
    "clean_data['spectral_centroid'] = merged_data['spectral_centroid'].apply(lambda x: np.mean(x) if isinstance(x, (list, np.ndarray)) and len(x) > 0 else np.nan)\n",
    "clean_data['chroma'] = merged_data['chroma'].apply(lambda x: np.mean(x) if isinstance(x, (list, np.ndarray)) and len(x) > 0 else np.nan)\n",
    "clean_data['zero_crossing_rate'] = merged_data['zero_crossing_rate'].apply(lambda x: x[0] if isinstance(x, (list, np.ndarray)) and len(x) > 0 else np.nan)\n",
    "clean_data['rms'] = merged_data['rms'].apply(lambda x: x[0] if isinstance(x, (list, np.ndarray)) and len(x) > 0 else np.nan)\n",
    "clean_data['pitch'] = merged_data['pitch']  # Directly store the existing value\n",
    "clean_data['path'] = merged_data['path']\n",
    "clean_data['filename'] = merged_data['filename']\n",
    "\n",
    "# Add the emotion column\n",
    "clean_data['emotion'] = merged_data['emotion']\n",
    "\n",
    "# Display the new DataFrame\n",
    "print(clean_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77238a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mfccs_mean            0\n",
      "spectral_centroid     0\n",
      "chroma                0\n",
      "zero_crossing_rate    0\n",
      "rms                   0\n",
      "pitch                 0\n",
      "path                  0\n",
      "filename              0\n",
      "emotion               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for any NaN values in the DataFrame\n",
    "print(clean_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f273bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# distribution of emotions\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=clean_data, x='emotion', order=clean_data['emotion'].value_counts().index)\n",
    "plt.title('Distribution of Emotions')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# this chart shows some a significant imbalance in the dataset. lets do some resampling\n",
    "# Lets try using the SMOTE technique (Synthetic Minority Over-sampling):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c859e453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['angry' 'disgust' 'fear' 'happy' 'neutral' 'sad' 'pleasant' 'unknown'\n",
      " 'surprise' 'calm']\n"
     ]
    }
   ],
   "source": [
    "# Lets combine columns that should be the same, such as 'Sad', 'sad', and 'sadness':\n",
    "\n",
    "clean_data['emotion'] = clean_data['emotion'].str.lower()  # Convert to lowercase\n",
    "\n",
    "# Replace specific values\n",
    "clean_data['emotion'] = clean_data['emotion'].replace({\n",
    "    'surprised': 'surprise',  # Change 'surprised' to 'surprise'\n",
    "    'sadness': 'sad',          # Combine 'sadness', 'sad', 'Sad' to 'sad'\n",
    "    'sad': 'sad',\n",
    "    'sadness': 'sad',\n",
    "    'pleasant': 'pleasant',\n",
    "    'fear': 'fear',\n",
    "    'fearful': 'fear',\n",
    "})\n",
    "\n",
    "# Check unique values after standardization\n",
    "unique_emotions = clean_data['emotion'].unique()\n",
    "print(unique_emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b21af37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=clean_data, x='emotion', order=clean_data['emotion'].value_counts().index)\n",
    "plt.title('Distribution of Emotions')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# this chart shows some a significant imbalance in the dataset.\n",
    "# lets reduce the higher classes like sad, angry, dusgust and so on to 1500, \n",
    "# then use augmented audio for underrepresented classes, bringing them also to 1500. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5b4d91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b41a2d8a",
   "metadata": {},
   "source": [
    "## Harmonizing sample sizes for target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fd5c68",
   "metadata": {},
   "source": [
    "### Building a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "42c784f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: Counter({'sad': 1544, 'fear': 1502, 'angry': 1498, 'happy': 1495, 'disgust': 1457, 'neutral': 1254, 'pleasant': 331, 'unknown': 281, 'surprise': 214, 'calm': 153})\n",
      "mfccs_mean            float64\n",
      "spectral_centroid     float64\n",
      "chroma                float64\n",
      "zero_crossing_rate    float64\n",
      "rms                   float64\n",
      "pitch                 float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "eval_clean_data = clean_data.copy()\n",
    "\n",
    "# Prepare the data\n",
    "X = eval_clean_data.drop(columns=['emotion', 'filename', 'path'])\n",
    "y = eval_clean_data['emotion']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Verify the original distribution of the training data\n",
    "print(\"Original dataset shape:\", Counter(y_train))\n",
    "\n",
    "# Convert columns with object type to their means\n",
    "for col in ['mfccs_mean', 'spectral_centroid', 'chroma', 'zero_crossing_rate', 'rms']:\n",
    "    X_train[col] = X_train[col].apply(lambda x: np.mean(x) if isinstance(x, (list, np.ndarray)) else x)\n",
    "    X_test[col] = X_test[col].apply(lambda x: np.mean(x) if isinstance(x, (list, np.ndarray)) else x)\n",
    "\n",
    "# Check if the columns were converted correctly\n",
    "print(X_train.dtypes)\n",
    "# Should all be floats!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3cfee1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (9729, 6)\n",
      "y_train shape: (9729,)\n",
      "X_test shape: (2433, 6)\n",
      "y_test shape: (2433,)\n",
      "mfccs_mean            0\n",
      "spectral_centroid     0\n",
      "chroma                0\n",
      "zero_crossing_rate    0\n",
      "rms                   0\n",
      "pitch                 0\n",
      "path                  0\n",
      "filename              0\n",
      "emotion               0\n",
      "dtype: int64\n",
      "\n",
      "mfccs_mean            0\n",
      "spectral_centroid     0\n",
      "chroma                0\n",
      "zero_crossing_rate    0\n",
      "rms                   0\n",
      "pitch                 0\n",
      "path                  0\n",
      "filename              0\n",
      "emotion               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# handle null values\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "# Convert object columns to float\n",
    "for col in ['mfccs_mean', 'spectral_centroid', 'chroma', 'zero_crossing_rate', 'rms']:\n",
    "    eval_clean_data[col] = pd.to_numeric(eval_clean_data[col], errors='coerce')\n",
    "\n",
    "# Check for any NaN values after conversion\n",
    "print(eval_clean_data.isnull().sum())\n",
    "\n",
    "eval_clean_data = eval_clean_data.dropna()\n",
    "\n",
    "print()\n",
    "\n",
    "# Verify that there are no more NaN values\n",
    "print(eval_clean_data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "94606609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 135 candidates, totalling 675 fits\n",
      "Best parameters found:  {'max_depth': 10, 'max_features': None, 'min_samples_leaf': 4, 'min_samples_split': 10}\n",
      "Best cross-validation score:  0.4478363633001054\n",
      "\n",
      "Decision Tree Accuracy (Best): 0.4619810933004521\n",
      "Confusion Matrix (Best):\n",
      " [[242   0  20  28  50  12   2   8   3   0]\n",
      " [  0  21   6   1   1   3   0   6   1   0]\n",
      " [ 49   1 142  13  53  79   7  57   5   0]\n",
      " [ 71   0  38  74  47  56   3  69   3   0]\n",
      " [ 99   2  28  31 139  45   2  11  11   0]\n",
      " [ 13   8  28  12  20 169   2  76   1   0]\n",
      " [  4   0  10   4   3   2  46   0   0   0]\n",
      " [  3   5  37  23  18  70   1 215   2   5]\n",
      " [  3   2   7   1   8   0   0   2  10   5]\n",
      " [  0   0   0   0   0   0   0   9   4  66]]\n",
      "Classification Report (Best):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.50      0.66      0.57       365\n",
      "        calm       0.54      0.54      0.54        39\n",
      "     disgust       0.45      0.35      0.39       406\n",
      "        fear       0.40      0.20      0.27       361\n",
      "       happy       0.41      0.38      0.39       368\n",
      "     neutral       0.39      0.51      0.44       329\n",
      "    pleasant       0.73      0.67      0.70        69\n",
      "         sad       0.47      0.57      0.52       379\n",
      "    surprise       0.25      0.26      0.26        38\n",
      "     unknown       0.87      0.84      0.85        79\n",
      "\n",
      "    accuracy                           0.46      2433\n",
      "   macro avg       0.50      0.50      0.49      2433\n",
      "weighted avg       0.46      0.46      0.45      2433\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid and run grid search\n",
    "param_grid = {\n",
    "    'max_depth': [None, 5, 10, 15, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', None] \n",
    "}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=DecisionTreeClassifier(random_state=42),\n",
    "                           param_grid=param_grid,\n",
    "                           cv=5,\n",
    "                           n_jobs=-1,\n",
    "                           scoring='accuracy',\n",
    "                           verbose=1)\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Review the best parameters and score\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: \", grid_search.best_score_)\n",
    "\n",
    "print() # new line for seperation\n",
    "\n",
    "# evaluate the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_best_tree = best_model.predict(X_test)\n",
    "\n",
    "print(\"Decision Tree Accuracy (Best):\", accuracy_score(y_test, y_pred_best_tree))\n",
    "print(\"Confusion Matrix (Best):\\n\", confusion_matrix(y_test, y_pred_best_tree))\n",
    "print(\"Classification Report (Best):\\n\", classification_report(y_test, y_pred_best_tree))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b3937e",
   "metadata": {},
   "source": [
    "#### Evaluation:\n",
    "Accuracy of 46% is not great. \n",
    "\n",
    "Additionally, our f1-scores don't look super hot either. Let's address this!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edfee8d",
   "metadata": {},
   "source": [
    "## Audio Augmentation for Underrepresented Classes\n",
    "\n",
    "Let's attempt to make the model better by evening the distribution. To do this, we will lower the more represented classes to 1500 each, and create synthetic data for the underrepresented classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "92ac3187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotion\n",
      "sad         1500\n",
      "angry       1500\n",
      "disgust     1500\n",
      "fear        1500\n",
      "happy       1500\n",
      "neutral     1500\n",
      "pleasant     400\n",
      "surprise     252\n",
      "calm         192\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "reduced_data = clean_data.copy()\n",
    "\n",
    "# drop rows with 'unknown' emotion\n",
    "reduced_data = reduced_data[reduced_data['emotion'] != 'unknown']\n",
    "# Define the target count for high emotion classes\n",
    "target_count_high = 1500\n",
    "\n",
    "# Loop through each emotion class and reduce to target count if above it\n",
    "for emotion in reduced_data['emotion'].value_counts().index:\n",
    "    current_count = reduced_data[reduced_data['emotion'] == emotion].shape[0]\n",
    "    \n",
    "    if current_count > target_count_high:\n",
    "        # Randomly sample to reduce to the target count\n",
    "        emotion_samples = reduced_data[reduced_data['emotion'] == emotion]\n",
    "        reduced_samples = emotion_samples.sample(n=target_count_high, random_state=42)\n",
    "        reduced_data = reduced_data[reduced_data['emotion'] != emotion]  # Remove excess samples\n",
    "        reduced_data = pd.concat([reduced_data, reduced_samples], ignore_index=True)\n",
    "\n",
    "# Check the new distribution of the reduced data\n",
    "print(reduced_data['emotion'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cf2997b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio augmentation to help with uneven data\n",
    "def augment_audio(data, sr):\n",
    "    # Add noise\n",
    "    noise = np.random.randn(len(data))\n",
    "    data_with_noise = data + 0.005 * noise\n",
    "    \n",
    "    # Time Stretching (without altering the pitch)\n",
    "    stretched_data = librosa.effects.time_stretch(data, rate=1.1)  # Slightly faster\n",
    "    \n",
    "    # Shifting (without altering the pitch)\n",
    "    shift = np.random.randint(sr)\n",
    "    shifted_data = np.roll(data, shift)\n",
    "    \n",
    "    # Volume adjustment\n",
    "    amplitude_scale = np.random.uniform(low=0.8, high=1.2)\n",
    "    adjusted_volume_data = data * amplitude_scale\n",
    "\n",
    "    # Randomly choose one of the augmentation methods to apply\n",
    "    augmentation_methods = [data_with_noise, stretched_data, shifted_data, adjusted_volume_data]\n",
    "    \n",
    "    augmented_data = random.choice(augmentation_methods)\n",
    "    \n",
    "    return augmented_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "008687a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotion\n",
      "pleasant    1500\n",
      "surprise    1500\n",
      "calm        1500\n",
      "sad         1500\n",
      "angry       1500\n",
      "disgust     1500\n",
      "fear        1500\n",
      "happy       1500\n",
      "neutral     1500\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create a new DataFrame for augmented data\n",
    "augmented_data = reduced_data.copy()\n",
    "\n",
    "# Lists to store augmented features\n",
    "augmented_mfccs_mean_list = []\n",
    "augmented_spectral_centroid_list = []\n",
    "augmented_chroma_list = []\n",
    "augmented_zero_crossing_rate_list = []\n",
    "augmented_rms_list = []\n",
    "augmented_pitch_list = []\n",
    "augmented_emotions = []\n",
    "\n",
    "# Define target count for underrepresented classes\n",
    "target_count = 1500\n",
    "underrepresented_emotions = ['pleasant', 'surprise', 'calm']\n",
    "\n",
    "# Process and augment underrepresented emotions\n",
    "for emotion in underrepresented_emotions:\n",
    "    current_count = augmented_data[augmented_data['emotion'] == emotion].shape[0]\n",
    "    num_augments_needed = target_count - current_count\n",
    "\n",
    "    if num_augments_needed > 0:\n",
    "        # Find all samples of this emotion in the dataset\n",
    "        emotion_samples = augmented_data[augmented_data['emotion'] == emotion]\n",
    "        \n",
    "        # Augment samples until we reach the target count\n",
    "        for _ in range(num_augments_needed):\n",
    "            # Randomly select a sample to augment\n",
    "            random_sample = emotion_samples.sample(n=1).iloc[0]\n",
    "            audio_file = os.path.join(random_sample['path'], random_sample['filename'])\n",
    "            \n",
    "            try:\n",
    "                # Load the audio file\n",
    "                data, sr = librosa.load(audio_file, sr=None)\n",
    "\n",
    "                # Perform augmentation\n",
    "                augmented_data_sample = augment_audio(data, sr)\n",
    "\n",
    "                # Extract features from the augmented audio\n",
    "                augmented_features = extract_features(augmented_data_sample, sr=sr, from_file=False)\n",
    "\n",
    "                # Append augmented features to lists\n",
    "                augmented_mfccs_mean_list.append(augmented_features[0])\n",
    "                augmented_spectral_centroid_list.append(augmented_features[1])\n",
    "                augmented_chroma_list.append(augmented_features[2])\n",
    "                augmented_zero_crossing_rate_list.append(augmented_features[3])\n",
    "                augmented_rms_list.append(augmented_features[4])\n",
    "                augmented_pitch_list.append(augmented_features[5])\n",
    "                augmented_emotions.append(emotion)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {audio_file}: {str(e)}\")\n",
    "\n",
    "# After augmentation, create a DataFrame to store augmented features\n",
    "augmented_df = pd.DataFrame({\n",
    "    'mfccs_mean': augmented_mfccs_mean_list,\n",
    "    'spectral_centroid': augmented_spectral_centroid_list,\n",
    "    'chroma': augmented_chroma_list,\n",
    "    'zero_crossing_rate': augmented_zero_crossing_rate_list,\n",
    "    'rms': augmented_rms_list,\n",
    "    'pitch': augmented_pitch_list,\n",
    "    'emotion': augmented_emotions\n",
    "})\n",
    "\n",
    "# Combine reduced data with augmented data\n",
    "eval_aug_data = pd.concat([reduced_data, augmented_df], ignore_index=True)\n",
    "\n",
    "# Check the final distribution\n",
    "print(eval_aug_data['emotion'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31df079",
   "metadata": {},
   "source": [
    "### New Model for the New Data\n",
    "\n",
    "Now, lets do build another model and evaulate it's accuracy, given our now-evenly-distributed data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7e964528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mfccs_mean            float64\n",
      "spectral_centroid     float64\n",
      "chroma                float64\n",
      "zero_crossing_rate    float64\n",
      "rms                   float64\n",
      "pitch                 float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Drop non-numeric columns like 'id', 'filename', 'path' before fitting the model\n",
    "X = eval_aug_data.drop(columns=['emotion', 'filename', 'path'])  # drop any non-numeric columns\n",
    "y = eval_aug_data['emotion']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert columns with object type to their means (if they're lists or arrays)\n",
    "for col in ['mfccs_mean', 'spectral_centroid', 'chroma', 'zero_crossing_rate', 'rms']:\n",
    "    X_train[col] = X_train[col].apply(lambda x: np.mean(x) if isinstance(x, (list, np.ndarray)) else x)\n",
    "    X_test[col] = X_test[col].apply(lambda x: np.mean(x) if isinstance(x, (list, np.ndarray)) else x)\n",
    "\n",
    "\n",
    "# Check if the columns were converted correctly\n",
    "print(X_train.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2ce669c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (10800, 6)\n",
      "y_train shape: (10800,)\n",
      "X_test shape: (2700, 6)\n",
      "y_test shape: (2700,)\n",
      "mfccs_mean            3656\n",
      "spectral_centroid     3656\n",
      "chroma                3656\n",
      "zero_crossing_rate    3656\n",
      "rms                   3656\n",
      "pitch                    0\n",
      "path                  3656\n",
      "filename              3656\n",
      "emotion                  0\n",
      "dtype: int64\n",
      "\n",
      "mfccs_mean            0\n",
      "spectral_centroid     0\n",
      "chroma                0\n",
      "zero_crossing_rate    0\n",
      "rms                   0\n",
      "pitch                 0\n",
      "path                  0\n",
      "filename              0\n",
      "emotion               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# handle null values\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "# Convert object columns to float\n",
    "for col in ['mfccs_mean', 'spectral_centroid', 'chroma', 'zero_crossing_rate', 'rms']:\n",
    "    eval_aug_data[col] = pd.to_numeric(eval_aug_data[col], errors='coerce')\n",
    "\n",
    "# Check for any NaN values after conversion\n",
    "print(eval_aug_data.isnull().sum())\n",
    "\n",
    "eval_aug_data = eval_aug_data.dropna()\n",
    "\n",
    "print()\n",
    "\n",
    "# Verify that there are no more NaN values\n",
    "print(eval_aug_data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d2b22b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 135 candidates, totalling 675 fits\n",
      "Best parameters found:  {'max_depth': 10, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best cross-validation score:  0.564537037037037\n",
      "\n",
      "Decision Tree Accuracy (Best): 0.575925925925926\n",
      "Confusion Matrix (Best):\n",
      " [[192   4  13  18  54  12   6   2   9]\n",
      " [  0 289   0   3   0   1   0   0  18]\n",
      " [ 16  13  89   9  27  60  23  28  20]\n",
      " [ 39   4  36  51  38  50   6  57  18]\n",
      " [ 54   2  15   7  90  65  21  11  19]\n",
      " [  7  15  45   5  16 185   3  49   6]\n",
      " [  3   0  24   1   3   1 264   3   0]\n",
      " [  7  14  37  14  11  63   3 140   8]\n",
      " [  1  21   1   0   2   3   1   0 255]]\n",
      "Classification Report (Best):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.60      0.62      0.61       310\n",
      "        calm       0.80      0.93      0.86       311\n",
      "     disgust       0.34      0.31      0.33       285\n",
      "        fear       0.47      0.17      0.25       299\n",
      "       happy       0.37      0.32      0.34       284\n",
      "     neutral       0.42      0.56      0.48       331\n",
      "    pleasant       0.81      0.88      0.84       299\n",
      "         sad       0.48      0.47      0.48       297\n",
      "    surprise       0.72      0.90      0.80       284\n",
      "\n",
      "    accuracy                           0.58      2700\n",
      "   macro avg       0.56      0.57      0.55      2700\n",
      "weighted avg       0.56      0.58      0.56      2700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid and run grid search\n",
    "param_grid = {\n",
    "    'max_depth': [None, 5, 10, 15, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', None] \n",
    "}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=DecisionTreeClassifier(random_state=42),\n",
    "                           param_grid=param_grid,\n",
    "                           cv=5,\n",
    "                           n_jobs=-1,\n",
    "                           scoring='accuracy',\n",
    "                           verbose=1)\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Review the best parameters and score\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: \", grid_search.best_score_)\n",
    "\n",
    "print() # new line for seperation\n",
    "\n",
    "# evaluate the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_best_tree = best_model.predict(X_test)\n",
    "\n",
    "print(\"Decision Tree Accuracy (Best):\", accuracy_score(y_test, y_pred_best_tree))\n",
    "print(\"Confusion Matrix (Best):\\n\", confusion_matrix(y_test, y_pred_best_tree))\n",
    "print(\"Classification Report (Best):\\n\", classification_report(y_test, y_pred_best_tree))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c570410",
   "metadata": {},
   "source": [
    "#### Evaluation:\n",
    "Accuracy of 58%; certainly an imporovement! But nothing substantial. \n",
    "\n",
    "Despite evening the distribution, we are still not seeing the model perform well. This is likely because 7k records\n",
    "is probably not enough to get good predictive capacity over our 7 categories. \n",
    "\n",
    "Let's engineer the categories into pos/neg binary classification and see if that improves our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce8bb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "Merge Datasets: done!\n",
    "Extract Features: done!\n",
    "Scale Data: done\n",
    "Clean Data: done!\n",
    "SMOTE for underrepresentation: no improvement \n",
    "Augment Data: no improvement\n",
    "Feature Selection: no improvement\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
